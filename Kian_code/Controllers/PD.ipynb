{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "print(sys.path)\n",
    "\n",
    "import Models.autoencoders as autoencoders\n",
    "import Double_Pendulum.Lumped_Mass.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.Lumped_Mass.transforms as transforms\n",
    "import Double_Pendulum.Lumped_Mass.dynamics as dynamics\n",
    "import Plotting.pendulum_plot as pendulum_plot\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "plotter = pendulum_plot.Anim_plotter(rp)\n",
    "neural_net = False\n",
    "\n",
    "if neural_net:\n",
    "    model = autoencoders.Autoencoder_double(rp).to(device)\n",
    "    model_location = '../Models/Split_AEs/ana_theta_loss.pth'\n",
    "    model.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "else:\n",
    "    model = autoencoders.Analytic_transformer(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clockwise(q):\n",
    "    if (q[0,1] >= q[0,0] and q[0,1] <= q[0,0] + torch.pi) or (q[0,1] >= q[0,0] - 2 * torch.pi and q[0,1] <= q[0,0] - torch.pi):\n",
    "        clockwise = False\n",
    "    else:\n",
    "        clockwise = True\n",
    "    return clockwise\n",
    "\n",
    "\n",
    "def wrap_to_pi(tensor):\n",
    "    return (tensor + torch.pi) % (2 * torch.pi) - torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kp = torch.tensor([[100., 0.], [0., 0.]]).to(device)\n",
    "Kd = torch.tensor([[40., 0.], [0., 0.]]).to(device)\n",
    "Kp_old = 50.\n",
    "Kd_old = 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_start = torch.tensor([[-torch.pi/2, -torch.pi/2+0.1]]).requires_grad_().to(device)\n",
    "#q_start = torch.tensor([[-1.5244, -3.0952]]).requires_grad_().to(device)\n",
    "q_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "#q_d_start = torch.tensor([[0.5, 0.5]]).requires_grad_().to(device)\n",
    "q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "is_clockwise_start = check_clockwise(q_start)\n",
    "\n",
    "xy_des_real = torch.tensor([0., 0.5]).requires_grad_().to(device)\n",
    "q_des = transforms.inverse_kinematics(rp, xy_des_real, is_clockwise=False).unsqueeze(0)\n",
    "#q_des = torch.tensor([[-torch.pi/2, -torch.pi/4]]).requires_grad_().to(device)\n",
    "q_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "th_start = model.encoder(q_start)\n",
    "th_d_start = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "th_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Obtain accelerations in thetas\n",
    "\n",
    "is_clockwise_des = check_clockwise(q_des)\n",
    "\n",
    "th_des = model.encoder(q_des)\n",
    "th_d_des = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "q_des_est = model.decoder(th_des, is_clockwise_des)\n",
    "q_d_des_est = (model.jacobian_dec(th_des, clockwise=is_clockwise_des) @ th_d_des.T).T\n",
    "xy_des_est, _ = transforms.forward_kinematics(rp, q_des_est[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_series = th_start.clone().detach()\n",
    "th_d_series = th_d_start.clone().detach()\n",
    "th_dd_series = th_dd_start.clone().detach()\n",
    "\n",
    "\n",
    "q_est_series = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "q_d_est_series = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "q_dd_est_series = torch.zeros((1,2)).to(device)\n",
    "\n",
    "\n",
    "q_real_series = q_start\n",
    "q_d_real_series = q_d_start\n",
    "q_dd_real_series = q_dd_start\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 15\n",
    "\n",
    "th = th_start\n",
    "th_d = th_d_start\n",
    "th_dd = th_dd_start\n",
    "\n",
    "q_est = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "q_d_est = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "q_dd_est = torch.zeros((1,2))\n",
    "\n",
    "q_real = q_start\n",
    "q_d_real = q_d_start\n",
    "q_dd_real = q_dd_start\n",
    "\n",
    "is_clockwise = check_clockwise(q_start)\n",
    "\n",
    "feedforward = True\n",
    "gravity = False\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    print(\"Time:\", t.item().__round__(3))\n",
    "\n",
    "    if feedforward:\n",
    "        q = model.decoder(th, is_clockwise)\n",
    "        q_d = (model.jacobian_dec(th, is_clockwise) @ th_d.T).T\n",
    "    else:\n",
    "        q = q_real\n",
    "        q_d = q_d_real\n",
    "\n",
    "        th = model.encoder(q)\n",
    "        th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "    J_h = model.jacobian_enc(q)\n",
    "    J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "    is_clockwise = check_clockwise(q)\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q, C_q, G_q = dynamics.dynamical_matrices(rp, q, q_d)\n",
    "    A_q = dynamics.input_matrix(rp , q)\n",
    "\n",
    "\n",
    "    \"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q, J_h_inv_trans, device)\n",
    "    \n",
    "    u = torch.pinverse(A_th) @ ((Kp @ (th_des - th).T + Kd @ (th_d_des - th_d).T))\n",
    "    \n",
    "    if feedforward:\n",
    "        M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q, C_q, G_q, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "\n",
    "        if gravity:\n",
    "            u = u + torch.pinverse(A_th) @ G_th\n",
    "        tau_th = A_th * u\n",
    "\n",
    "        print(\"u at th:\", u)\n",
    "\n",
    "        if gravity:\n",
    "            th_dd = (torch.pinverse(M_th) @ (tau_th - C_th @ th_d.T - G_th)).T \n",
    "        else:\n",
    "            th_dd = (torch.pinverse(M_th) @ (tau_th - C_th @ th_d.T)).T\n",
    "\n",
    "        th = th.detach().requires_grad_()\n",
    "        th_d = th_d.detach().requires_grad_()\n",
    "        th_dd = th_dd.detach().requires_grad_()\n",
    "\n",
    "        th_d = th_d + th_dd * dt\n",
    "        th = th + th_d * dt\n",
    "\n",
    "        q = q.detach().requires_grad_()\n",
    "        q_d = q_d.detach().requires_grad_()\n",
    "        #q_dd = q_dd.detach().requires_grad_()\n",
    "        \n",
    "        J_h_inv_new = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\n",
    "        q_d_old = q_d\n",
    "        q_d = (J_h_inv_new @ th_d.T).T\n",
    "        q_dd = (q_d - q_d_old)/dt\n",
    "        q = model.decoder(th, is_clockwise)\n",
    "        q = wrap_to_pi(q)\n",
    "    \n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    M_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real, q_d_real)\n",
    "    A_q_real = dynamics.input_matrix(rp, q_real)\n",
    "\n",
    "    if gravity and not feedforward:\n",
    "        u = u + torch.pinverse(A_q) @ G_q_real\n",
    "\n",
    "    tau_q_real = A_q_real * u\n",
    "\n",
    "    if gravity:\n",
    "        q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T) - G_q_real)).T \n",
    "    else:\n",
    "        q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T))).T\n",
    "    \n",
    "    q_d_real = q_d_real + q_dd_real * dt\n",
    "    q_real = q_real + q_d_real * dt\n",
    "    q_real = wrap_to_pi(q_real)\n",
    "    \n",
    "    if feedforward:\n",
    "        q_est = q\n",
    "        q_d_est = q_d\n",
    "        q_dd_est = q_dd\n",
    "    else:\n",
    "        th_est = model.encoder(q_real)\n",
    "        q_est = model.decoder(th_est, is_clockwise)\n",
    "        th_d_est = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "        q_d_est = (model.jacobian_dec(th_est, clockwise=is_clockwise) @ th_d_est.T).T\n",
    "        q_dd_est = q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Implement with Jacobian derivative\n",
    "\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series = torch.cat((th_series, th.detach()), dim=0)\n",
    "    th_d_series = torch.cat((th_d_series, th_d.detach()), dim=0)\n",
    "    th_dd_series = torch.cat((th_dd_series, th_dd.detach()), dim=0)\n",
    "    \n",
    "    q_real_series = torch.cat((q_real_series, q_real.detach()), dim=0)\n",
    "    q_d_real_series = torch.cat((q_d_real_series, q_d_real.detach()), dim=0)\n",
    "    q_dd_real_series = torch.cat((q_dd_real_series, q_dd_real.detach()), dim=0)\n",
    "\n",
    "    q_est_series = torch.cat((q_est_series, q_est.detach()), dim=0)\n",
    "    q_d_est_series = torch.cat((q_d_est_series, q_d_est.detach()), dim=0)\n",
    "    q_dd_est_series = torch.cat((q_dd_est_series, q_dd_est.detach()), dim=0) \n",
    "\n",
    "    #print(is_clockwise)\n",
    "    print(\"\")\n",
    "\n",
    "    \n",
    "    \n",
    "#print(q_real_series)\n",
    "#print(q_d_real_series)\n",
    "#print(q_dd_real_series)\n",
    "#print(q_est_series)\n",
    "#print(q_d_est_series)\n",
    "#print(q_dd_est_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_end_q_real, pos_elbow_q_real = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_real_series)\n",
    "pos_end_q_est, pos_elbow_q_est = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_est_series)\n",
    "colors_q_real = cm.rainbow(np.linspace(0, 1, pos_end_q_real.size(0)))\n",
    "colors_q_est = cm.rainbow(np.linspace(0, 1, pos_end_q_est.size(0)))\n",
    "frames_q_real = plotter.frame_pendulum(pos_end_q_real, pos_elbow_q_real, colors = colors_q_real, height=5, width=5)\n",
    "frames_q_est = plotter.frame_pendulum(pos_end_q_est, pos_elbow_q_est, colors = colors_q_est, height=5, width=5)\n",
    "\n",
    "frames_data = [(frames_q_est, \"q_est\", \"tab:orange\", \"tab:red\"), (frames_q_real, \"q_real\", \"tab:blue\", \"tab:cyan\")]\n",
    "#frames_data = [(frames_q_real, \"q_real\", \"tab:blue\", \"tab:cyan\")]\n",
    "#frames_data = [(frames_q_est, \"q_est\", \"tab:orange\", \"tab:red\")]\n",
    "file_name = \"yahooooo\" \n",
    "file_name_gif = file_name + \".gif\"\n",
    "file_name_mp4 = file_name + \".mp4\"\n",
    "\n",
    "\n",
    "\n",
    "plotter.animate_pendulum(frames_data, ref_pos=xy_des, actuator=True, file_name=file_name_mp4, fps = 100)\n",
    "#plotter.animate_pendulum(frames_data, ref_pos=None, actuator=False, file_name=file_name_mp4, fps = 100)\n",
    "print(len(frames_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "q = torch.tensor([[torch.pi/4, 0.0]])\n",
    "q1_in = q[0,0]\n",
    "q2_in = q[0,1]\n",
    "\n",
    "q_in_list = []\n",
    "q_out_cw_list = []\n",
    "q_out_ccw_list = []\n",
    "\n",
    "q_in_tensors = torch.empty((0,2))\n",
    "\n",
    "\n",
    "\n",
    "def theta_from_q(q1_in, q2_in):\n",
    "\n",
    "    theta1 = torch.sqrt((rp[\"xa\"] - rp[\"l1\"]*torch.cos(q1_in) - rp[\"l2\"]*torch.cos(q2_in))**2 + \n",
    "                        (rp[\"ya\"] - rp[\"l1\"]*torch.sin(q1_in) - rp[\"l2\"]*torch.sin(q2_in))**2)\n",
    "\n",
    "    theta2 = torch.atan2((rp[\"ya\"] - rp[\"l1\"]*torch.sin(q1_in) - rp[\"l2\"]*torch.sin(q2_in)),\n",
    "                        (rp[\"xa\"] - rp[\"l1\"]*torch.cos(q1_in) - rp[\"l2\"]*torch.cos(q2_in)))\n",
    "    #print(\"theta1:\", theta1, \"   theta2:\", theta2)\n",
    "    return(theta1, theta2)\n",
    "\n",
    "def q_from_theta(theta1, theta2):\n",
    "    xend = rp[\"xa\"] - theta1*torch.cos(theta2)\n",
    "    yend = rp[\"ya\"] - theta1*torch.sin(theta2)\n",
    "\n",
    "\n",
    "    numerator = (xend**2 + yend**2 - rp[\"l1\"]**2 - rp[\"l2\"]**2)\n",
    "    denominator = torch.tensor(2*rp[\"l1\"]*rp[\"l2\"])\n",
    "\n",
    "    beta = torch.arccos(numerator/(denominator+epsilon))\n",
    "    q1 = torch.atan2(yend, xend + epsilon) - torch.atan2(rp[\"l2\"]*torch.sin(beta), epsilon + rp[\"l1\"] + rp[\"l2\"]*torch.cos(beta))\n",
    "    q2 = q1 + beta\n",
    "\n",
    "    q1_alt = torch.atan2(yend, xend) + torch.atan2(rp[\"l2\"]*torch.sin(beta), rp[\"l1\"] + rp[\"l2\"]*torch.cos(beta))\n",
    "    q2_alt = q1_alt - beta \n",
    "\n",
    "    return ((q1, q2), (q1_alt, q2_alt))\n",
    "\n",
    "def plot_coordinates(q_in_tensors, q_cw, q_ccw):\n",
    "    \"\"\"\n",
    "    Plots three lists of (x, y) coordinates in separate subplots, side by side, with the same limits.\n",
    "\n",
    "    Parameters:\n",
    "    - q_in_list: List of (x, y) tuples to be plotted in the first subplot.\n",
    "    - q_out_list: List of (x, y) tuples to be plotted in the second subplot.\n",
    "    - q_alt_out_list: List of (x, y) tuples to be plotted in the third subplot.\n",
    "    \"\"\"\n",
    "    # Unpack each list into x and y coordinates\n",
    "    #x_in, y_in = zip(*q_in_list) if q_in_list else ([], [])\n",
    "    #x_out, y_out = zip(*q_out_list) if q_out_list else ([], [])\n",
    "    #x_alt_out, y_alt_out = zip(*q_alt_out_list) if q_alt_out_list else ([], [])\n",
    "\n",
    "    x_in = q_in_tensors[:, 0].numpy()\n",
    "    y_in = q_in_tensors[:, 1].numpy()\n",
    "    x_out = q_cw[:, 0].numpy()\n",
    "    y_out = q_cw[:, 1].numpy()\n",
    "    x_alt_out = q_ccw[:, 0].numpy()\n",
    "    y_alt_out = q_ccw[:, 1].numpy()\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(x_in)))\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "    # Define axis limits\n",
    "    x_limits = (-1.1*np.pi, 1.1*np.pi)\n",
    "    y_limits = (-1.1*np.pi, 1.1*np.pi)\n",
    "\n",
    "    # Plot q_in_list\n",
    "    axes[0].scatter(x_in, y_in, color=colors, label='q_in_list', alpha=0.7)\n",
    "    axes[0].set_xlim(x_limits)\n",
    "    axes[0].set_ylim(y_limits)\n",
    "    axes[0].set_title('q_in_list')\n",
    "    axes[0].set_xlabel('q1')\n",
    "    axes[0].set_ylabel('q2')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot q_out_list\n",
    "    axes[1].scatter(x_out, y_out, color=colors, label='q_out_list', alpha=0.7)\n",
    "    axes[1].set_xlim(x_limits)\n",
    "    axes[1].set_ylim(y_limits)\n",
    "    axes[1].set_title('q_alt_out_list')\n",
    "    axes[1].set_xlabel('X Coordinate')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plot q_alt_out_list\n",
    "    axes[2].scatter(x_alt_out, y_alt_out, color=colors, label='q_alt_out_list', alpha=0.7)\n",
    "    axes[2].set_xlim(x_limits)\n",
    "    axes[2].set_ylim(y_limits)\n",
    "    axes[2].set_title('q_alt_out_list')\n",
    "    axes[2].set_xlabel('q1')\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epsilon = 0.0001\n",
    "\n",
    "for j in range(0,1):\n",
    "    for i in range(0,120):\n",
    "        q1_in = torch.tensor(i*torch.pi/60 + j*torch.pi/40)\n",
    "        q2_in = torch.tensor(j*torch.pi/5) - q1_in\n",
    "        q_in_tensors = torch.cat((q_in_tensors, torch.tensor([[q1_in, q2_in]])), dim=0)\n",
    "\n",
    "th = torch.vmap(transforms.analytic_theta, in_dims=(None, 0))(rp, q_in_tensors)\n",
    "q_cw, q_ccw = torch.vmap(transforms.analytic_inverse, in_dims=(None, 0))(rp, th)\n",
    "\n",
    "plot_coordinates(q_in_tensors, q_cw, q_ccw)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot_coordinates(q_in_list, q_out_cw_list, q_out_ccw_list)\n",
    "\n",
    "\n",
    "\n",
    "for q_in, q_out_cw, q_out_ccw in zip(q_in_tensors, q_cw, q_ccw):\n",
    "\n",
    "    pos_end, pos_elbow = transforms.forward_kinematics(rp, q_in)\n",
    "    \n",
    "\n",
    "    #plotter.plot_double_pendulum([pos_end], [pos_elbow])\n",
    "\n",
    "\n",
    "pos_end_tensor, pos_elbow_tensor = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_in_tensors)\n",
    "pos_end_tensor_cw, pos_elbow_tensor_cw = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_cw)\n",
    "pos_end_tensor_ccw, pos_elbow_tensor_ccw = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_ccw)\n",
    "colors = cm.rainbow(np.linspace(0, 1, pos_end_tensor.size(0)))\n",
    "frames_input = plotter.frame_pendulum(pos_end_tensor, pos_elbow_tensor, colors = colors, height=5, width=5)\n",
    "frames_cw = plotter.frame_pendulum(pos_end_tensor_cw, pos_elbow_tensor_cw, colors = colors, height=5, width=5)\n",
    "frames_ccw = plotter.frame_pendulum(pos_end_tensor_ccw, pos_elbow_tensor_ccw, colors = colors, height=5, width=5)\n",
    "\n",
    "print(pos_end_tensor)\n",
    "print(pos_elbow_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up q_est and q_real to be the same\n",
    "q_est = torch.tensor([[-torch.pi/4, -torch.pi/2]]).requires_grad_(True)\n",
    "q_d_est = torch.tensor([[torch.pi+0.1, -torch.pi/2]]).requires_grad_(True)\n",
    "\n",
    "# Calculate th\n",
    "th = model.encoder(q_est)\n",
    "th_d = (model.jacobian_enc(q_est) @ q_d_est.T).T\n",
    "\n",
    "# Calculate Jacobians\n",
    "J_h = model.jacobian_enc(q_est)\n",
    "J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "J_h_inv = model.jacobian_dec(th)\n",
    "J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "J_h = model.jacobian_enc(q_est)\n",
    "J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "J_h_inv = model.jacobian_dec(th)\n",
    "J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "# Obtain dynamic matrices in q-space\n",
    "M_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_est.squeeze(0), q_d_est.squeeze(0))\n",
    "A_q_est = dynamics.input_matrix(rp , q_est.squeeze(0))\n",
    "\n",
    "# Obtain dynamic matrices in theta-space\n",
    "M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "A_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans, device)\n",
    "\n",
    "# Reconstruct dynamical matrices from theta-space to q-space\n",
    "M_recon = J_h_trans @ M_th @ J_h\n",
    "C_recon = torch.zeros(M_recon.size()).to(M_recon.device)\n",
    "\n",
    "for i in range(C_recon.size(0)):\n",
    "    for j in range(C_recon.size(1)):\n",
    "        for k in range(C_recon.size(1)):\n",
    "            M_recon_dot_ijk = torch.autograd.grad(M_recon[i,j], q_est, create_graph=True)[0][0,k]\n",
    "            M_recon_dot_ikj = torch.autograd.grad(M_recon[i,k], q_est, create_graph=True)[0][0,j]\n",
    "            M_recon_dot_jki = torch.autograd.grad(M_recon[j,k], q_est, create_graph=True)[0][0,i]\n",
    "\n",
    "            C_recon[i, j] += 0.5 * (M_recon_dot_ijk + M_recon_dot_ikj - M_recon_dot_jki) * q_d_est[0, k]\n",
    "\n",
    "G_recon = J_h_trans @ G_th\n",
    "\n",
    "\n",
    "print(\"Mqest:\\n\", M_q_est)  \n",
    "print(\"Mrecon:\\n\", M_recon)\n",
    "\n",
    "print(\"Cqest:\\n\", C_q_est)\n",
    "print(\"Crecon:\\n\", C_recon)\n",
    "\n",
    "print(\"Gqest:\\n\", G_q_est)\n",
    "print(\"Grecon:\\n\", G_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Give setpoint in q-space\n",
    "2. Give current position in q\n",
    "3. Map both to theta\n",
    "4. Calculate distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
