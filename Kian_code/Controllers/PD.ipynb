{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "print(sys.path)\n",
    "\n",
    "import Models.autoencoders as autoencoders\n",
    "import Double_Pendulum.Lumped_Mass.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.Lumped_Mass.transforms as transforms\n",
    "import Double_Pendulum.Lumped_Mass.dynamics as dynamics\n",
    "import Plotting.pendulum_plot as pendulum_plot\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "plotter = pendulum_plot.Anim_plotter(rp)\n",
    "neural_net = True\n",
    "\n",
    "if neural_net:\n",
    "    model = autoencoders.Autoencoder_double(rp).to(device)\n",
    "    model_location = '../Models/Split_AEs/Lumped_Mass_ccw_(2,5).pth'\n",
    "    model.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "else:\n",
    "    model = autoencoders.Analytic_transformer(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kp = torch.tensor([[100., 0.], [0., 0.]]).to(device)\n",
    "Kd = torch.tensor([[40., 0.], [0., 0.]]).to(device)\n",
    "Kp_old = 50.\n",
    "Kd_old = 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_start = torch.tensor([[-torch.pi/2, -torch.pi/2+0.1]]).requires_grad_().to(device)\n",
    "#q_start = torch.tensor([[-1.5244, -3.0952]]).requires_grad_().to(device)\n",
    "q_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "#q_d_start = torch.tensor([[0.5, 0.5]]).requires_grad_().to(device)\n",
    "q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "is_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "xy_des_real = torch.tensor([2., -2.]).requires_grad_().to(device)\n",
    "q_des = transforms.inverse_kinematics(rp, xy_des_real, is_clockwise=False).unsqueeze(0)\n",
    "#q_des = torch.tensor([[-torch.pi/2, -torch.pi/4]]).requires_grad_().to(device)\n",
    "q_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "th_start = model.encoder(q_start)\n",
    "th_d_start = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "th_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Obtain accelerations in thetas\n",
    "\n",
    "is_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "th_des = model.encoder(q_des)\n",
    "th_d_des = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "q_des_est = model.decoder(th_des, is_clockwise_des)\n",
    "q_d_des_est = (model.jacobian_dec(th_des, clockwise=is_clockwise_des) @ th_d_des.T).T\n",
    "xy_des_est, _ = transforms.forward_kinematics(rp, q_des_est[0])\n",
    "\n",
    "print(xy_des_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th_series = th_start.clone().detach()\n",
    "#th_d_series = th_d_start.clone().detach()\n",
    "#th_dd_series = th_dd_start.clone().detach()\n",
    "\n",
    "#q_est_series = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "#q_d_est_series = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "#q_dd_est_series = torch.zeros((1,2)).to(device)\n",
    "\n",
    "#q_real_series = q_start\n",
    "#q_d_real_series = q_d_start\n",
    "#q_dd_real_series = q_dd_start\n",
    "\n",
    "#q_base_series = q_start\n",
    "#q_d_base_series = q_d_start\n",
    "#q_dd_base_series = q_dd_start\n",
    "\n",
    "th_series, th_d_series, th_dd_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_est_series, q_d_est_series, q_dd_est_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_real_series, q_d_real_series, q_dd_real_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_base_series, q_d_base_series, q_dd_base_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 15\n",
    "t_series = torch.arange(0, 15, 0.01)\n",
    "\n",
    "th = th_start\n",
    "th_d = th_d_start\n",
    "th_dd = th_dd_start\n",
    "\n",
    "q_est = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "q_d_est = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "q_dd_est = torch.zeros((1,2))\n",
    "\n",
    "q_real, q_d_real, q_dd_real = q_start, q_d_start, q_dd_start\n",
    "q_base, q_d_base, q_dd_base = q_start, q_d_start, q_dd_start\n",
    "\n",
    "is_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "feedforward = False\n",
    "gravity = True\n",
    "fix_q = True\n",
    "model_cw = False\n",
    "model_shifting = True\n",
    "\n",
    "if neural_net and fix_q:\n",
    "    note_string = \"NOTE: The controller expects the NN to be trained on \" + (\"COUNTER\" if not model_cw else \"\") + \"CLOCKWISE data.\"\n",
    "    print(note_string)\n",
    "if model_shifting:\n",
    "    print(\"NOTE: The controller expects points in q to be shifted (to make q-space unimodal).\")\n",
    "\n",
    "\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    print(\"Time:\", t.item().__round__(3))\n",
    "\n",
    "    if feedforward:\n",
    "        q = model.decoder(th, is_clockwise)\n",
    "        q_d = (model.jacobian_dec(th, is_clockwise) @ th_d.T).T\n",
    "    else:\n",
    "        is_clockwise = transforms.check_clockwise(q_real.squeeze(0))\n",
    "        if fix_q and model_cw != is_clockwise:\n",
    "            print(\"fixing value to cw\")\n",
    "            q = transforms.flip_q(rp, q_real.squeeze(0), model_cw).unsqueeze(0)\n",
    "            q_d = transforms.flip_q_d(rp, q_real, q_d_real, model_cw)\n",
    "        else:\n",
    "            q = q_real\n",
    "            q_d = q_d_real\n",
    "\n",
    "        if model_shifting:\n",
    "            q = transforms.shift_q(q, clockwise=model_cw)\n",
    "        th = model.encoder(q)\n",
    "        th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "    \n",
    "\n",
    "    J_h = model.jacobian_enc(q)\n",
    "    J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "    is_clockwise = transforms.check_clockwise(q.squeeze(0))\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q, C_q, G_q = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "    A_q = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "\n",
    "    \"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q, J_h_inv_trans, device)\n",
    "    \n",
    "    u = torch.pinverse(A_th) @ ((Kp @ (th_des - th).T + Kd @ (th_d_des - th_d).T))\n",
    "    \n",
    "    if feedforward:\n",
    "        M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q, C_q, G_q, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "\n",
    "        if gravity:\n",
    "            u = u + torch.pinverse(A_th) @ G_th\n",
    "        tau_th = A_th * u\n",
    "\n",
    "        print(\"u at th:\", u)\n",
    "\n",
    "        if gravity:\n",
    "            th_dd = (torch.pinverse(M_th) @ (tau_th - C_th @ th_d.T - G_th)).T \n",
    "        else:\n",
    "            th_dd = (torch.pinverse(M_th) @ (tau_th - C_th @ th_d.T)).T\n",
    "\n",
    "        th = th.detach().requires_grad_()\n",
    "        th_d = th_d.detach().requires_grad_()\n",
    "        th_dd = th_dd.detach().requires_grad_()\n",
    "\n",
    "        th_d = th_d + th_dd * dt\n",
    "        th = th + th_d * dt\n",
    "\n",
    "        q = q.detach().requires_grad_()\n",
    "        q_d = q_d.detach().requires_grad_()\n",
    "        #q_dd = q_dd.detach().requires_grad_()\n",
    "        \n",
    "        J_h_inv_new = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\n",
    "        q_d_old = q_d\n",
    "        q_d = (J_h_inv_new @ th_d.T).T\n",
    "        q_dd = (q_d - q_d_old)/dt\n",
    "        q = model.decoder(th, is_clockwise)\n",
    "        q = wrap_to_pi(q)\n",
    "    \n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    M_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real, q_d_real)\n",
    "    A_q_real = dynamics.input_matrix(rp, q_real)\n",
    "\n",
    "    if gravity and not feedforward:\n",
    "        u = u + torch.pinverse(A_q) @ G_q_real\n",
    "\n",
    "    tau_q_real = A_q_real * u\n",
    "\n",
    "    if gravity:\n",
    "        q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T) - G_q_real)).T \n",
    "    else:\n",
    "        q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T))).T\n",
    "    \n",
    "    q_d_real = q_d_real + q_dd_real * dt\n",
    "    q_real = q_real + q_d_real * dt\n",
    "    q_real = wrap_to_pi(q_real)\n",
    "    \n",
    "    if feedforward:\n",
    "        q_est = q\n",
    "        q_d_est = q_d\n",
    "        q_dd_est = q_dd\n",
    "    else:\n",
    "        th_est = model.encoder(q_real)\n",
    "        q_est = model.decoder(th_est, is_clockwise)\n",
    "        th_d_est = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "        q_d_est = (model.jacobian_dec(th_est, clockwise=is_clockwise) @ th_d_est.T).T\n",
    "        q_dd_est = q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Implement with Jacobian derivative\n",
    "\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series = torch.cat((th_series, th.detach()), dim=0)\n",
    "    th_d_series = torch.cat((th_d_series, th_d.detach()), dim=0)\n",
    "    th_dd_series = torch.cat((th_dd_series, th_dd.detach()), dim=0)\n",
    "    \n",
    "    q_real_series = torch.cat((q_real_series, q_real.detach()), dim=0)\n",
    "    q_d_real_series = torch.cat((q_d_real_series, q_d_real.detach()), dim=0)\n",
    "    q_dd_real_series = torch.cat((q_dd_real_series, q_dd_real.detach()), dim=0)\n",
    "\n",
    "    q_est_series = torch.cat((q_est_series, q_est.detach()), dim=0)\n",
    "    q_d_est_series = torch.cat((q_d_est_series, q_d_est.detach()), dim=0)\n",
    "    q_dd_est_series = torch.cat((q_dd_est_series, q_dd_est.detach()), dim=0) \n",
    "\n",
    "    #print(is_clockwise)\n",
    "    print(\"\")\n",
    "\n",
    "    \n",
    "    \n",
    "#print(q_real_series)\n",
    "#print(q_d_real_series)\n",
    "#print(q_dd_real_series)\n",
    "#print(q_est_series)\n",
    "#print(q_d_est_series)\n",
    "#print(q_dd_est_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 5\n",
    "pos_end_q_real, pos_elbow_q_real = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_real_series[::stride])\n",
    "pos_end_q_est, pos_elbow_q_est = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_est_series[::stride])\n",
    "\n",
    "frames_q_real = plotter.frame_pendulum(pos_end_q_real, pos_elbow_q_real)\n",
    "frames_q_est = plotter.frame_pendulum(pos_end_q_est, pos_elbow_q_est)\n",
    "\n",
    "data_real = {\n",
    "    \"frames\": frames_q_real,\n",
    "    \"times\": dt,\n",
    "    \"name\": \"q_real\", \n",
    "    \"arm_color\": \"tab:blue\",\n",
    "    \"act_color\": \"tab:cyan\"\n",
    "}\n",
    "\n",
    "data_est = {\n",
    "    \"frames\": frames_q_est,\n",
    "    \"times\": dt,\n",
    "    \"name\": \"q_est\",\n",
    "    \"arm_color\": \"tab:orange\", \n",
    "    \"act_color\": \"tab:red\"\n",
    "}\n",
    "\n",
    "ref_pos_real = {\n",
    "    \"pos\": xy_des_real,\n",
    "    \"name\": \"real\",\n",
    "    \"color\": \"tab:blue\"\n",
    "}\n",
    "\n",
    "ref_pos_est = {\n",
    "    \"pos\": xy_des_est,\n",
    "    \"name\": \"est\",\n",
    "    \"color\": \"tab:orange\"\n",
    "}\n",
    "\n",
    "ref_poss = [ref_pos_real, ref_pos_est]\n",
    "\n",
    "frames_data = [data_real, data_est]\n",
    "#frames_data = [data_est]\n",
    "#frames_data = [data_real]\n",
    "\n",
    "name_base = \"(\" + str(rp[\"xa\"]) + \",\" + str(rp[\"ya\"]) + \")_\"\n",
    "\n",
    "if neural_net:\n",
    "    model_type = \"NN\"\n",
    "else:\n",
    "    model_type = \"AL\"\n",
    "\n",
    "if feedforward:\n",
    "    controller_type = \"feedforward\" \n",
    "else:\n",
    "    controller_type = \"feedback\"\n",
    "\n",
    "\n",
    "\n",
    "file_name = name_base + model_type + \"_\" + controller_type\n",
    "if not gravity:\n",
    "    file_name = file_name + \"_no_G\"\n",
    "file_name_gif = file_name + \".gif\"\n",
    "file_name_mp4 = file_name + \".mp4\"\n",
    "\n",
    "\n",
    "\n",
    "plotter.animate_pendulum(frames_data, ref_poss=ref_poss, plot_actuator=True, file_name=file_name_mp4, fps = 1/(dt*stride), dt = dt*stride)\n",
    "#plotter.animate_pendulum(frames_data, ref_pos=None, plot_actuator=False, file_name=file_name_mp4, fps = 1/(dt*stride), dt = dt*stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_q = [\n",
    "    {\n",
    "        \"name\": \"est\",\n",
    "        \"values\": q_est_series.cpu().detach().numpy(),\n",
    "        \"color\": \"tab:orange\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"real\",\n",
    "        \"values\": q_real_series.cpu().detach().numpy(),\n",
    "        \"color\": \"tab:blue\"\n",
    "    }#,\n",
    "    #{\n",
    "    #    \"name\": \"naive_series\",\n",
    "    #    \"values\": np.column_stack((np.sin(t_series + 1.0), np.cos(t_series + 1.0))),\n",
    "    #    \"color\": \"red\"\n",
    "    #}\n",
    "]\n",
    "datasets_th = [\n",
    "    {\n",
    "        \"name\": \"est\",\n",
    "        \"values\": th_series.cpu().detach().numpy(),\n",
    "        \"color\": \"tab:orange\"\n",
    "    }#,56\n",
    "    #{\n",
    "    #    \"name\": \"ana\",\n",
    "    #    \"values\": th_\n",
    "    #    \"color\": \"tab:blue\"\n",
    "    #}\n",
    "]\n",
    "\n",
    "# Common labels for the plots.\n",
    "name_q = \"q trajectory\"\n",
    "name_th = \"th trajectory\"\n",
    "t_series = torch.arange(0, 15, 0.01)\n",
    "# Ensure the results directory exists.\n",
    "result_path = \"./results\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "# Create an instance of ErrorPlotter.\n",
    "ep = pendulum_plot.Error_plotter(rp)\n",
    "\n",
    "# Prepare plot datasets for each column.\n",
    "# Each call groups a set of datasets to be drawn in one subplot column.\n",
    "column1 = ep.create_plot_dataset(datasets_q, t_series, name_q)\n",
    "column2 = ep.create_plot_dataset(datasets_th, t_series, name_th)\n",
    "\n",
    "# Pass the list of columns (plot_dataset objects) to plot_multi.\n",
    "ep.plot_multi([column1, column2], file_name=\"Trajectory_plots\", axes_names = [\"q\", \"th\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "class FeedbackODE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        print(\"t:\", t.item())\n",
    "        q, q_d = y[0], y[1]\n",
    "\n",
    "        print(\"q:\", q[0,0].item(), q[0,1].item())\n",
    "\n",
    "        th = model.encoder(q)\n",
    "        th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "        J_h = model.jacobian_enc(q)\n",
    "        J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "        is_clockwise = transforms.check_clockwise(q.squeeze(0))\n",
    "        J_h_inv = model.jacobian_dec(th, is_clockwise)\n",
    "        J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "        M_q, C_q, G_q = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "        A_q = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "        #print(\"M_q:\\n\", M_q)\n",
    "        #print(\"C_q:\\n\", C_q)\n",
    "        #print(\"G_q:\\n\", G_q)\n",
    "        A_th = transforms.transform_input_matrix_from_inverse_trans(A_q, J_h_inv_trans, device)\n",
    "        #print(\"A_th:\\n\", A_th)\n",
    "        u = torch.pinverse(A_th) @ ((Kp @ (th_des - th).T + Kd @ (th_d_des - th_d).T))\n",
    "\n",
    "        tau_q = A_q @ u\n",
    "        q_dd = (torch.pinverse(M_q) @ (tau_q - C_q @ q_d.T - G_q)).T\n",
    "        print(\"q_dd:\", q_dd)\n",
    "        print(\"\\n\")\n",
    "        return torch.stack([q_d, q_dd])  # Return (dq/dt, dq_d/dt)\n",
    "\n",
    "# Initial conditions\n",
    "y0 = torch.stack([q_start, q_d_start])\n",
    "\n",
    "# Time span for integration\n",
    "t_span = torch.linspace(0., 1, 10)  # Adjust as needed\n",
    "\n",
    "# Solve the system\n",
    "sol = odeint(FeedbackODE(), y0, t_span, method='rk4')  # Use 'bdf' for stiff problems\n",
    "\n",
    "q_sol, q_d_sol = sol[:, 0, :], sol[:, 1, :]\n",
    "\n",
    "#print(q_sol)\n",
    "#print(q_d_sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model_ana = autoencoders.Analytic_transformer(rp)\n",
    "\n",
    "model_NN = autoencoders.Autoencoder_double(rp).to(device)\n",
    "model_location = '../Models/Split_AEs/ana_theta_0_loss_quart.pth'\n",
    "model_NN.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "models = [model_ana, model_NN]\n",
    "\n",
    "def check_clockwise_vectorized(q):\n",
    "    \"\"\"\n",
    "    Expects q to be a tensor of shape (N,2) where each row is [q1, q2].\n",
    "    Returns two boolean masks: (cw_mask, ccw_mask), where:\n",
    "      - cw_mask[i] is True if the i-th configuration is elbow clockwise.\n",
    "      - ccw_mask[i] is True if the i-th configuration is elbow counterclockwise.\n",
    "    \n",
    "    The logic is as follows (from your original function):\n",
    "      If q2 lies between q1 and q1+π, or between q1-2π and q1-π, then the configuration\n",
    "      is considered counterclockwise. Otherwise it is clockwise.\n",
    "    \"\"\"\n",
    "    q1 = q[:, 0]\n",
    "    q2 = q[:, 1]\n",
    "    cond_ccw = ((q2 >= q1) & (q2 <= q1 + torch.pi)) | ((q2 >= q1 - 2 * torch.pi) & (q2 <= q1 - torch.pi))\n",
    "    cw_mask = ~cond_ccw\n",
    "    ccw_mask = cond_ccw\n",
    "    return cw_mask, ccw_mask\n",
    "\n",
    "\n",
    "print(\"xy_des_real\", xy_des_real)\n",
    "print(\"xy_des_est\", xy_des_est)\n",
    "\n",
    "# Define the number of grid points along each dimension.\n",
    "n_points = 200\n",
    "\n",
    "# Create 1D tensors for q1 and q2 in the range [-pi, 0]\n",
    "q1_vals = torch.linspace(-np.pi, 0, n_points)\n",
    "q2_vals = torch.linspace(-np.pi/2, np.pi/2, n_points)\n",
    "\n",
    "# Create a 2D grid (meshgrid) of q values.\n",
    "# (Note: using indexing='ij' so that the first axis corresponds to q1 and the second to q2)\n",
    "q1_grid, q2_grid = torch.meshgrid(q1_vals, q2_vals, indexing='ij')\n",
    "\n",
    "# Stack the grid to get a tensor of shape (n_points*n_points, 2)\n",
    "q_grid = torch.stack([q1_grid.flatten(), q2_grid.flatten()], dim=1).to(device)\n",
    "\n",
    "# === Compute theta1 and theta2 using the analytic encoder functions ===\n",
    "# We use torch.vmap to evaluate the functions over the batch of q values.\n",
    "# Note: encoder_theta_1_ana and encoder_theta_2_ana each return a tuple (theta, theta).\n",
    "\n",
    "for model in models:\n",
    "  theta_out = model.encoder(q_grid)\n",
    "  #theta_out = torch.vmap(model.encoder)(q_grid)\n",
    "\n",
    "  theta1 = theta_out[:, 0]\n",
    "  theta2 = theta_out[:, 1]\n",
    "\n",
    "  # Since q1_grid and q2_grid are already on a mesh, we can compute x_end and y_end elementwise.\n",
    "  x_end = rp[\"l1\"] * torch.cos(q_grid[:, 0]) + rp[\"l2\"] * torch.cos(q_grid[:, 1])\n",
    "  y_end = rp[\"l1\"] * torch.sin(q_grid[:, 0]) + rp[\"l2\"] * torch.sin(q_grid[:, 1])\n",
    "\n",
    "  # --- Determine configuration (clockwise vs. counterclockwise) for each q ---\n",
    "  cw_mask, ccw_mask = check_clockwise_vectorized(q_grid)\n",
    "\n",
    "  # --- Filter data for each configuration ---\n",
    "  # Clockwise points\n",
    "  x_end_cw    = x_end[cw_mask].detach().cpu().numpy()\n",
    "  y_end_cw    = y_end[cw_mask].detach().cpu().numpy()\n",
    "  theta1_cw   = theta1[cw_mask].detach().cpu().numpy()\n",
    "  theta2_cw   = theta2[cw_mask].detach().cpu().numpy()\n",
    "\n",
    "  # Counterclockwise points\n",
    "  x_end_ccw   = x_end[ccw_mask].detach().cpu().numpy()\n",
    "  y_end_ccw   = y_end[ccw_mask].detach().cpu().numpy()\n",
    "  theta1_ccw  = theta1[ccw_mask].detach().cpu().numpy()\n",
    "  theta2_ccw  = theta2[ccw_mask].detach().cpu().numpy()\n",
    "\n",
    "  fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "  # --- Top row: Clockwise ---\n",
    "  sc1 = axes[0, 0].scatter(x_end_cw, y_end_cw, c=theta1_cw, cmap='viridis', s=5)\n",
    "  axes[0, 0].set_title(\"Theta1 - Clockwise\")\n",
    "  axes[0, 0].set_xlabel(\"x\")\n",
    "  axes[0, 0].set_ylabel(\"y\")\n",
    "  plt.colorbar(sc1, ax=axes[0, 0])\n",
    "\n",
    "  sc2 = axes[0, 1].scatter(x_end_cw, y_end_cw, c=theta2_cw, cmap='viridis', s=5)\n",
    "  axes[0, 1].set_title(\"Theta2 - Clockwise\")\n",
    "  axes[0, 1].set_xlabel(\"x\")\n",
    "  axes[0, 1].set_ylabel(\"y\")\n",
    "  plt.colorbar(sc2, ax=axes[0, 1])\n",
    "\n",
    "  # --- Bottom row: Counterclockwise ---\n",
    "  sc3 = axes[1, 0].scatter(x_end_ccw, y_end_ccw, c=theta1_ccw, cmap='viridis', s=5)\n",
    "  axes[1, 0].set_title(\"Theta1 - Counterclockwise\")\n",
    "  axes[1, 0].set_xlabel(\"x\")\n",
    "  axes[1, 0].set_ylabel(\"y\")\n",
    "  plt.colorbar(sc3, ax=axes[1, 0])\n",
    "\n",
    "  sc4 = axes[1, 1].scatter(x_end_ccw, y_end_ccw, c=theta2_ccw, cmap='viridis', s=5)\n",
    "  axes[1, 1].set_title(\"Theta2 - Counterclockwise\")\n",
    "  axes[1, 1].set_xlabel(\"x\")\n",
    "  axes[1, 1].set_ylabel(\"y\")\n",
    "  plt.colorbar(sc4, ax=axes[1, 1])\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "q = torch.tensor([[torch.pi/4, 0.0]])\n",
    "q1_in = q[0,0]\n",
    "q2_in = q[0,1]\n",
    "\n",
    "q_in_list = []\n",
    "q_out_cw_list = []\n",
    "q_out_ccw_list = []\n",
    "\n",
    "q_in_tensors = torch.empty((0,2))\n",
    "\n",
    "\n",
    "\n",
    "def theta_from_q(q1_in, q2_in):\n",
    "\n",
    "    theta1 = torch.sqrt((rp[\"xa\"] - rp[\"l1\"]*torch.cos(q1_in) - rp[\"l2\"]*torch.cos(q2_in))**2 + \n",
    "                        (rp[\"ya\"] - rp[\"l1\"]*torch.sin(q1_in) - rp[\"l2\"]*torch.sin(q2_in))**2)\n",
    "\n",
    "    theta2 = torch.atan2((rp[\"ya\"] - rp[\"l1\"]*torch.sin(q1_in) - rp[\"l2\"]*torch.sin(q2_in)),\n",
    "                        (rp[\"xa\"] - rp[\"l1\"]*torch.cos(q1_in) - rp[\"l2\"]*torch.cos(q2_in)))\n",
    "    #print(\"theta1:\", theta1, \"   theta2:\", theta2)\n",
    "    return(theta1, theta2)\n",
    "\n",
    "def q_from_theta(theta1, theta2):\n",
    "    xend = rp[\"xa\"] - theta1*torch.cos(theta2)\n",
    "    yend = rp[\"ya\"] - theta1*torch.sin(theta2)\n",
    "\n",
    "\n",
    "    numerator = (xend**2 + yend**2 - rp[\"l1\"]**2 - rp[\"l2\"]**2)\n",
    "    denominator = torch.tensor(2*rp[\"l1\"]*rp[\"l2\"])\n",
    "\n",
    "    beta = torch.arccos(numerator/(denominator+epsilon))\n",
    "    q1 = torch.atan2(yend, xend + epsilon) - torch.atan2(rp[\"l2\"]*torch.sin(beta), epsilon + rp[\"l1\"] + rp[\"l2\"]*torch.cos(beta))\n",
    "    q2 = q1 + beta\n",
    "\n",
    "    q1_alt = torch.atan2(yend, xend) + torch.atan2(rp[\"l2\"]*torch.sin(beta), rp[\"l1\"] + rp[\"l2\"]*torch.cos(beta))\n",
    "    q2_alt = q1_alt - beta \n",
    "\n",
    "    return ((q1, q2), (q1_alt, q2_alt))\n",
    "\n",
    "def plot_coordinates(q_in_tensors, q_cw, q_ccw):\n",
    "    \"\"\"\n",
    "    Plots three lists of (x, y) coordinates in separate subplots, side by side, with the same limits.\n",
    "\n",
    "    Parameters:\n",
    "    - q_in_list: List of (x, y) tuples to be plotted in the first subplot.\n",
    "    - q_out_list: List of (x, y) tuples to be plotted in the second subplot.\n",
    "    - q_alt_out_list: List of (x, y) tuples to be plotted in the third subplot.\n",
    "    \"\"\"\n",
    "    # Unpack each list into x and y coordinates\n",
    "    #x_in, y_in = zip(*q_in_list) if q_in_list else ([], [])\n",
    "    #x_out, y_out = zip(*q_out_list) if q_out_list else ([], [])\n",
    "    #x_alt_out, y_alt_out = zip(*q_alt_out_list) if q_alt_out_list else ([], [])\n",
    "\n",
    "    x_in = q_in_tensors[:, 0].numpy()\n",
    "    y_in = q_in_tensors[:, 1].numpy()\n",
    "    x_out = q_cw[:, 0].numpy()\n",
    "    y_out = q_cw[:, 1].numpy()\n",
    "    x_alt_out = q_ccw[:, 0].numpy()\n",
    "    y_alt_out = q_ccw[:, 1].numpy()\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(x_in)))\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "    # Define axis limits\n",
    "    x_limits = (-1.1*np.pi, 1.1*np.pi)\n",
    "    y_limits = (-1.1*np.pi, 1.1*np.pi)\n",
    "\n",
    "    # Plot q_in_list\n",
    "    axes[0].scatter(x_in, y_in, color=colors, label='q_in_list', alpha=0.7)\n",
    "    axes[0].set_xlim(x_limits)\n",
    "    axes[0].set_ylim(y_limits)\n",
    "    axes[0].set_title('q_in_list')\n",
    "    axes[0].set_xlabel('q1')\n",
    "    axes[0].set_ylabel('q2')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot q_out_list\n",
    "    axes[1].scatter(x_out, y_out, color=colors, label='q_out_list', alpha=0.7)\n",
    "    axes[1].set_xlim(x_limits)\n",
    "    axes[1].set_ylim(y_limits)\n",
    "    axes[1].set_title('q_alt_out_list')\n",
    "    axes[1].set_xlabel('X Coordinate')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plot q_alt_out_list\n",
    "    axes[2].scatter(x_alt_out, y_alt_out, color=colors, label='q_alt_out_list', alpha=0.7)\n",
    "    axes[2].set_xlim(x_limits)\n",
    "    axes[2].set_ylim(y_limits)\n",
    "    axes[2].set_title('q_alt_out_list')\n",
    "    axes[2].set_xlabel('q1')\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epsilon = 0.0001\n",
    "\n",
    "for j in range(0,1):\n",
    "    for i in range(0,120):\n",
    "        q1_in = torch.tensor(i*torch.pi/60 + j*torch.pi/40)\n",
    "        q2_in = torch.tensor(j*torch.pi/5) - q1_in\n",
    "        q_in_tensors = torch.cat((q_in_tensors, torch.tensor([[q1_in, q2_in]])), dim=0)\n",
    "\n",
    "th = torch.vmap(transforms.analytic_theta, in_dims=(None, 0))(rp, q_in_tensors)\n",
    "q_cw, q_ccw = torch.vmap(transforms.analytic_inverse, in_dims=(None, 0))(rp, th)\n",
    "\n",
    "plot_coordinates(q_in_tensors, q_cw, q_ccw)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot_coordinates(q_in_list, q_out_cw_list, q_out_ccw_list)\n",
    "\n",
    "\n",
    "\n",
    "for q_in, q_out_cw, q_out_ccw in zip(q_in_tensors, q_cw, q_ccw):\n",
    "\n",
    "    pos_end, pos_elbow = transforms.forward_kinematics(rp, q_in)\n",
    "    \n",
    "\n",
    "    #plotter.plot_double_pendulum([pos_end], [pos_elbow])\n",
    "\n",
    "\n",
    "pos_end_tensor, pos_elbow_tensor = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_in_tensors)\n",
    "pos_end_tensor_cw, pos_elbow_tensor_cw = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_cw)\n",
    "pos_end_tensor_ccw, pos_elbow_tensor_ccw = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_ccw)\n",
    "colors = cm.rainbow(np.linspace(0, 1, pos_end_tensor.size(0)))\n",
    "frames_input = plotter.frame_pendulum(pos_end_tensor, pos_elbow_tensor, colors = colors, height=5, width=5)\n",
    "frames_cw = plotter.frame_pendulum(pos_end_tensor_cw, pos_elbow_tensor_cw, colors = colors, height=5, width=5)\n",
    "frames_ccw = plotter.frame_pendulum(pos_end_tensor_ccw, pos_elbow_tensor_ccw, colors = colors, height=5, width=5)\n",
    "\n",
    "print(pos_end_tensor)\n",
    "print(pos_elbow_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Give setpoint in q-space\n",
    "2. Give current position in q\n",
    "3. Map both to theta\n",
    "4. Calculate distance "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
