{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "\tsys.path.insert(0, module_path)\n",
    "\n",
    "import Double_Pendulum.Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.transforms as transforms\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Plotting.pendulum_plot as pendulum_plot\n",
    "\n",
    "\n",
    "import plot_collocated as plt_col\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family']   = 'serif'\n",
    "matplotlib.rcParams['font.serif']    = ['Times New Roman']\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "plotter = pendulum_plot.Anim_plotter(rp)\n",
    "\n",
    "model_cw = False\n",
    "\n",
    "model_ana = autoencoders.Analytic_transformer(rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller gains in theta-space\n",
    "Kp = torch.tensor([[100., 0.], \n",
    "\t\t\t\t   [0., 0.]]).to(device)\n",
    "Kd = torch.tensor([[40., 0.], \n",
    "\t\t\t\t   [0., 0.]]).to(device)\n",
    "\n",
    "# Controller gains in q-space\n",
    "Kp_naive = torch.tensor([[100., 50.]]).to(device)\n",
    "Kd_naive = torch.tensor([[50., 30.]]).to(device)\n",
    "\n",
    "K_naive = torch.cat((Kp_naive, Kd_naive), dim=1).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settling_time_threshold = 0.05\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 15.\n",
    "t_series = torch.arange(0, t_end, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define performance logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_performance_dict(load_performance_path):\n",
    "\tperformance_dict = torch.load(load_performance_path)#, map_location = \"cpu\")\n",
    "\tprint(f\"Loaded performance dicts from {load_performance_path}\")\n",
    "\treturn performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_performance_dict(performance_dict, save_folder, file_name):\n",
    "\n",
    "\tsave_performance_path = save_folder + \"/\" + file_name\n",
    "\n",
    "\ttorch.save(performance_dict, save_performance_path)\n",
    "\tprint(f\"Saved performance dicts to {save_performance_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define desired conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_conditions(xy_des, model):\n",
    "\tq_des = transforms.inverse_kinematics(xy_des, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "\tq_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\tis_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "\tth_des_ana = model_ana.encoder_vmap(q_des)\n",
    "\tth_d_des_ana = (model_ana.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "\tth_des_est = model.encoder_vmap(q_des)\n",
    "\tth_d_des_est = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "\tq_des_est = model.decoder_vmap(th_des_est, is_clockwise_des)\n",
    "\tq_d_des_est = (model.jacobian_dec(th_des_est, clockwise=is_clockwise_des) @ th_d_des_est.T).T\n",
    "\txy_des_est, _ = transforms.forward_kinematics(rp, q_des_est[0])\n",
    "\n",
    "\t#print(\"xy_des:\", xy_des.detach().cpu().numpy())\n",
    "\t#print(\"th_des_ana:\", th_des_ana.detach().cpu().numpy()[0])\n",
    "\n",
    "\treturn (q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\t \tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define start conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conditions(xy_start, model):\n",
    "\tq_start = transforms.inverse_kinematics(xy_start, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "\tq_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\tq_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\tis_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "\tth_start_est = model.encoder_vmap(q_start)\n",
    "\tth_d_start_est = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "\tth_start_ana = model_ana.encoder_vmap(q_start)\n",
    "\tth_d_start_ana = (model_ana.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "\tq_start_est = model.decoder_vmap(th_start_est, is_clockwise_start)\n",
    "\tq_d_start_est = (model.jacobian_dec(th_start_est, clockwise=is_clockwise_start) @ th_d_start_est.T).T\n",
    "\txy_start_est, _ = transforms.forward_kinematics(rp, q_start_est[0])\n",
    "\n",
    "\t#print(\"xy_start:\", xy_start.detach().cpu().numpy())\n",
    "\t#print(\"th_start_ana:\", th_start_ana.detach().cpu().numpy()[0])\n",
    "\n",
    "\treturn (q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\t \tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_collocated_nn(xy_start, xy_des, timestamp, model_nn, C_damp):\n",
    "\n",
    "\t(q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est) = desired_conditions(xy_des, model_nn)\n",
    "\n",
    "\t(q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est) = start_conditions(xy_start, model_nn)\n",
    "\t\n",
    "\n",
    "\tnum_steps = int(t_end / dt)\n",
    "\tth_series, th_d_series      = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tth_ana_series, th_d_ana_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tq_hat_series, q_d_hat_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tq_real_series, q_d_real_series, q_dd_real_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tu_series = torch.empty((num_steps, 1)).to(device)\n",
    "\ttau_q_series = torch.empty((num_steps, 2)).to(device)\n",
    "\n",
    "\t# Define starting conditions\n",
    "\tth = th_start_est\n",
    "\tth_d = th_d_start_est\n",
    "\n",
    "\tq_hat = q_start_est\n",
    "\tq_d_hat = q_d_start_est\n",
    "\n",
    "\tq_real, q_d_real, q_dd_real = q_start, q_d_start, q_dd_start\n",
    "\n",
    "\tis_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "\n",
    "\n",
    "\tfor i, t in enumerate(torch.arange(0, t_end, dt)):\n",
    "\t\tt_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "\t\tif torch.allclose(t, torch.floor(t)) and torch.floor(t)%5 == 0:\n",
    "\t\t\tprint(t_string)\n",
    "\n",
    "\t\tis_clockwise = transforms.check_clockwise(q_real.squeeze(0))\n",
    "\t\tif model_cw != is_clockwise:\n",
    "\t\t\tprint(\"fixing value to\", \"clockwise\" if model_cw else \"counterclockwise\")\n",
    "\t\t\tq = transforms.flip_q(rp, q_real.squeeze(0), model_cw).unsqueeze(0)\n",
    "\t\t\tq_d = transforms.flip_q_d(rp, q_real.squeeze(0), q_d_real, model_cw)\n",
    "\t\telse:\n",
    "\t\t\tq = q_real\n",
    "\t\t\tq_d = q_d_real\n",
    "\n",
    "\t\tth = model_nn.encoder_vmap(q)\n",
    "\t\tth_d = (model_nn.jacobian_enc(q) @ q_d.T).T\n",
    "\t\t\n",
    "\t\tq_hat = model_nn.decoder_vmap(th, clockwise=model_cw)\n",
    "\t\tq_d_hat = (model_nn.jacobian_dec(th) @ th_d.T).T\n",
    "\n",
    "\t\tis_clockwise = transforms.check_clockwise(q_hat.squeeze(0))\n",
    "\n",
    "\t\t\"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\t\t\n",
    "\t\tJ_h_inv = model_nn.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\t\tJ_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "\t\tM_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "\t\tA_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\n",
    "\t\t# Compute the M_th Jacobian\n",
    "\t\tcalc_M_th_partial = partial(transforms.calc_M_th_from_th, rp=rp, model=model_nn, model_cw=False)\n",
    "\t\tdM_th = torch.autograd.functional.jacobian(calc_M_th_partial, th).squeeze()\n",
    "\n",
    "\t\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\n",
    "\t\tM_th = transforms.transform_M_th(M_q_est, J_h_inv, J_h_inv_trans)\n",
    "\t\tC_th = transforms.transform_C_th(dM_th, th_d)\n",
    "\t\tG_th = transforms.transform_G_th(G_q_est, J_h_inv_trans)\n",
    "\n",
    "\t\tA_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "\n",
    "\t\tu = torch.pinverse(A_th) @ ((Kp @ (th_des_est - th).T + Kd @ (th_d_des_est - th_d).T))\n",
    "\t\tu = u + torch.pinverse(A_th) @ G_th\n",
    "\n",
    "\t\t\"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "\t\tM_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real.squeeze(0), q_d_real.squeeze(0))\n",
    "\t\tA_q_real = dynamics.input_matrix(rp, q_real.squeeze(0))\n",
    "\n",
    "\t\ttau_q_real = A_q_real * u\n",
    "\t\tq_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T) - (C_damp @ ((q_d_real).T)) - G_q_real)).T\n",
    "\t\tq_d_real = q_d_real + q_dd_real * dt\n",
    "\t\tq_real = q_real + q_d_real * dt\n",
    "\t\tq_real = transforms.wrap_to_pi(q_real)\n",
    "\t\t\n",
    "\t\tth = model_nn.encoder_vmap(q_real)\n",
    "\t\tq_hat = model_nn.decoder_vmap(th, clockwise=transforms.check_clockwise(q_real.squeeze(0)))\n",
    "\t\tq_hat = transforms.wrap_to_pi(q_hat)\n",
    "\t\tth_d = (model_nn.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "\t\tq_d_hat = (model_nn.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "\n",
    "\t\tth_ana = model_ana.encoder_vmap(q_real)\n",
    "\t\tth_d_ana = (model_ana.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "\n",
    "\n",
    "\n",
    "\t\t\"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "\t\tth_series[i] = th.detach()\n",
    "\t\tth_d_series[i] = th_d.detach()\n",
    "\n",
    "\t\tth_ana_series[i] = th_ana.detach()\n",
    "\t\tth_d_ana_series[i] = th_d_ana.detach()\n",
    "\n",
    "\t\tq_real_series[i] = q_real.detach()\n",
    "\t\tq_d_real_series[i] = q_d_real.detach()\n",
    "\t\tq_dd_real_series[i] = q_dd_real.detach()\n",
    "\n",
    "\t\tq_hat_series[i] = q_hat.detach()\n",
    "\t\tq_d_hat_series[i] = q_d_hat.detach()\n",
    "\n",
    "\t\tu_series[i] = u.detach()\n",
    "\t\ttau_q_series[i] = tau_q_real.T.detach()\n",
    "\n",
    "\n",
    "\txy_real_series = torch.empty(q_real_series.size()).to(device)\n",
    "\txy_hat_series = torch.empty(q_real_series.size()).to(device)\n",
    "\n",
    "\tfor i, (q_real, q_hat) in enumerate(zip(q_real_series, q_hat_series)):\n",
    "\t\txy_real, _ = transforms.forward_kinematics(rp, q_real)\n",
    "\t\txy_real_series[i] = xy_real.unsqueeze(0)\n",
    "\t\txy_hat, _ = transforms.forward_kinematics(rp, q_hat)\n",
    "\t\txy_hat_series[i] = xy_hat.unsqueeze(0)\n",
    "\n",
    "\tnn_sim_data = {\n",
    "\t\t\"th_s\": th_series,\n",
    "\t\t\"th_d_s\": th_d_series,\n",
    "\t\t\"th_ana_s\": th_ana_series,\n",
    "\t\t\"th_d_ana_s\": th_d_ana_series,\n",
    "\t\t\"q_real_s\": q_real_series,\n",
    "\t\t\"q_d_real_s\": q_d_real_series,\n",
    "\t\t\"q_dd_real_s\": q_dd_real_series,\n",
    "\t\t\"q_hat_s\": q_hat_series,\n",
    "\t\t\"q_d_hat_s\": q_d_hat_series,\n",
    "\t\t\"xy_real_s\": xy_real_series,\n",
    "\t\t\"xy_hat_s\": xy_hat_series,\n",
    "\t\t\"u_s\": u_series,\n",
    "\t\t\"tau_q_s\": tau_q_series\n",
    "\t}\n",
    "\n",
    "\treturn (nn_sim_data, q_des, q_start, th_des_ana, th_start_ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_collocated_ana(xy_start, xy_des, timestamp, model, C_damp):\n",
    "\n",
    "\n",
    "\t(q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est) = desired_conditions(xy_des, model_ana)\n",
    "\n",
    "\t(q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est) = start_conditions(xy_start, model_ana)\n",
    "\n",
    "\n",
    "\tnum_steps = int(t_end / dt)\n",
    "\tth_ana_series, th_d_ana_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tq_ana_series, q_d_ana_series, q_dd_ana_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tq_hat_ana_series, q_d_hat_ana_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\n",
    "\tu_ana_series = torch.empty((num_steps, 1)).to(device)\n",
    "\ttau_q_ana_series = torch.empty((num_steps, 2)).to(device)\n",
    "\n",
    "\t# Define starting angles\n",
    "\tq, q_d, q_dd = q_start, q_d_start, q_dd_start\n",
    "\n",
    "\tis_clockwise = False\n",
    "\t\n",
    "\n",
    "\tfor i, t in enumerate(torch.arange(0, t_end, dt)):\n",
    "\t\tt_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "\t\tif torch.allclose(t, torch.floor(t)) and torch.floor(t)%5 == 0:\n",
    "\t\t\tprint(t_string)\n",
    "\n",
    "\t\t\n",
    "\t\tth = model.encoder_vmap(q)\n",
    "\t\tth_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\t\n",
    "\t\t\t\n",
    "\t\tq_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "\t\tq_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "\n",
    "\n",
    "\t\t\"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\t\t\n",
    "\t\tJ_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\t\tJ_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "\t\tM_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "\t\tA_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\t\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\t\t\n",
    "\n",
    "\t\t# Compute the Jacobian\n",
    "\t\t\n",
    "\t\tcalc_M_th_partial = partial(transforms.calc_M_th_from_th, rp=rp, model=model_ana, model_cw=False)\n",
    "\t\tdM_th = torch.autograd.functional.jacobian(calc_M_th_partial, th).squeeze()\n",
    "\t\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\t\t\n",
    "\t\tM_th = transforms.transform_M_th(M_q_est, J_h_inv, J_h_inv_trans)\n",
    "\t\tC_th = transforms.transform_C_th(dM_th, th_d)\n",
    "\t\tG_th = transforms.transform_G_th(G_q_est, J_h_inv_trans)\n",
    "\n",
    "\t\tA_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "\t\t\n",
    "\t\tu = torch.pinverse(A_th) @ ((Kp @ (th_des_ana - th).T + Kd @ (th_d_des_ana - th_d).T))\n",
    "\t\tu = u + torch.pinverse(A_th) @ G_th\n",
    "\n",
    "\t\t\"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\t\t\n",
    "\t\tM_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "\t\tA_q_real = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\ttau_q_real = A_q_real * u\n",
    "\t\tq_dd = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d).T) - (C_damp @ ((q_d).T)) - G_q_real)).T\n",
    "\t\tq_d = q_d + q_dd * dt\n",
    "\t\tq = q + q_d * dt\n",
    "\t\tq = transforms.wrap_to_pi(q)\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\tth_ana = model.encoder_vmap(q)\n",
    "\t\tth_d_ana = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "\t\t\"\"\" Store data for plotting \"\"\"\n",
    "\t\t\n",
    "\t\tth_ana_series[i] = th_ana.detach()\n",
    "\t\tth_d_ana_series[i] = th_d_ana.detach()\n",
    "\n",
    "\t\tq_ana_series[i] = q.detach()\n",
    "\t\tq_d_ana_series[i] = q_d.detach()\n",
    "\t\tq_dd_ana_series[i] = q_dd.detach()\n",
    "\n",
    "\t\tq_hat_ana_series[i] = q_hat.detach()\n",
    "\t\tq_d_hat_ana_series[i] = q_d_hat.detach()\n",
    "\n",
    "\t\tu_ana_series[i] = u.detach()\n",
    "\t\ttau_q_ana_series[i] = tau_q_real.T.detach()\n",
    "\n",
    "\txy_real_series = torch.empty(q_ana_series.size()).to(device)\n",
    "\txy_hat_series = torch.empty(q_hat_ana_series.size()).to(device)\n",
    "\n",
    "\tfor i, (q_real, q_hat) in enumerate(zip(q_ana_series, q_hat_ana_series)):\n",
    "\t\txy_real, _ = transforms.forward_kinematics(rp, q_real)\n",
    "\t\txy_real_series[i] = xy_real.unsqueeze(0)\n",
    "\t\txy_hat, _ = transforms.forward_kinematics(rp, q_hat)\n",
    "\t\txy_hat_series[i] = xy_hat.unsqueeze(0)\n",
    "\n",
    "\tana_sim_data = {\n",
    "\t\t\"th_ana_s\": th_ana_series,\n",
    "\t\t\"th_d_ana_s\": th_d_ana_series,\n",
    "\t\t\"q_real_s\": q_ana_series,\n",
    "\t\t\"q_d_real_s\": q_d_ana_series,\n",
    "\t\t\"q_dd_real_s\": q_dd_ana_series,\n",
    "\t\t\"q_hat_ana_s\": q_hat_ana_series,\n",
    "\t\t\"q_d_hat_ana_s\": q_d_hat_ana_series,\n",
    "\t\t\"u_s\": u_ana_series,\n",
    "\t\t\"tau_q_ana_s\": tau_q_ana_series,\n",
    "\t\t\"xy_real_s\": xy_real_series,\n",
    "\t\t\"xy_hat_s\": xy_hat_series,\n",
    "\t}\n",
    "\n",
    "\treturn ana_sim_data\n",
    "\n",
    "\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_collocated_naive(xy_start, xy_des, timestamp, C_damp):\n",
    "\n",
    "\n",
    "\t(q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est) = desired_conditions(xy_des, model_ana)\n",
    "\n",
    "\t(q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est) = start_conditions(xy_start, model_ana)\n",
    "\n",
    "\n",
    "\tnum_steps = int(t_end / dt)\n",
    "\tth_ana_series, th_d_ana_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tth_naive_series, th_d_naive_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\tq_naive_series, q_d_naive_series, q_dd_naive_series = torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device), torch.empty((num_steps, 2)).to(device)\n",
    "\n",
    "\tnaive_des = torch.cat((q_des.T, q_d_des.T), dim = 0)\n",
    "\n",
    "\tu_naive_series = torch.empty((num_steps, 1)).to(device)\n",
    "\ttau_q_naive_series = torch.empty((num_steps, 2)).to(device)\n",
    "\n",
    "\tq, q_d, q_dd = q_start, q_d_start, q_dd_start\n",
    "\n",
    "\tis_clockwise = False\n",
    "\n",
    "\tmodel = autoencoders.Analytic_transformer(rp)\n",
    "\n",
    "\tfor i, t in enumerate(torch.arange(0, t_end, dt)):\n",
    "\t\tt_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "\t\tif torch.allclose(t, torch.floor(t)) and torch.floor(t)%5 == 0:\n",
    "\t\t\tprint(t_string)\n",
    "\n",
    "\n",
    "\t\t\"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\t\tM_q_naive, C_q_naive, G_q_naive = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "\t\tA_q_naive = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "\n",
    "\t\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\n",
    "\t\tnaive_state = torch.cat((q.T, q_d.T), dim = 0)\n",
    "\n",
    "\t\tnaive_error = naive_state - naive_des\n",
    "\t\tdelta_u = K_naive @ naive_error\n",
    "\t\tu = delta_u + torch.pinverse(A_q_naive) @ G_q_naive\n",
    "\n",
    "\t\t\"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "\n",
    "\t\ttau_q_naive = A_q_naive * u\n",
    "\t\tq_dd = (torch.pinverse(M_q_naive) @ (tau_q_naive - C_q_naive @ ((q_d).T) - (C_damp @ ((q_d).T)) - G_q_naive)).T\n",
    "\t\tq_d = q_d + q_dd * dt\n",
    "\t\tq = q + q_d * dt\n",
    "\t\tq = transforms.wrap_to_pi(q)\n",
    "\t\t\n",
    "\t\tth_naive = model.encoder_vmap(q)\n",
    "\t\tth_d_naive = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "\n",
    "\t\t\"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "\t\tth_naive_series[i] = th_naive.detach()\n",
    "\t\tth_d_naive_series[i] = th_d_naive.detach()\n",
    "\t\t\n",
    "\t\tq_naive_series[i] = q.detach()\n",
    "\t\tq_d_naive_series[i] = q_d.detach()\n",
    "\t\tq_dd_naive_series[i] = q_dd.detach()\n",
    "\n",
    "\t\tu_naive_series[i] = u.detach()\n",
    "\t\ttau_q_naive_series[i] = tau_q_naive.T.detach()\n",
    "\n",
    "\n",
    "\txy_naive_series = torch.empty(q_naive_series.size()).to(device)\n",
    "\n",
    "\tfor i, q_naive in enumerate(q_naive_series):\n",
    "\t\txy_naive, _ = transforms.forward_kinematics(rp, q_naive)\n",
    "\t\txy_naive_series[i] = xy_naive.unsqueeze(0)\n",
    "\n",
    "\tnaive_sim_data = {\n",
    "\t\t\"th_ana_s\": th_naive_series,\n",
    "\t\t\"th_d_ana_s\": th_d_naive_series,\n",
    "\t\t\"q_real_s\": q_naive_series,\n",
    "\t\t\"q_d_real_s\": q_d_naive_series,\n",
    "\t\t\"q_dd_real_s\": q_dd_naive_series,\n",
    "\t\t\"u_s\": u_naive_series,\n",
    "\t\t\"tau_q_naive_s\": tau_q_naive_series,\n",
    "\t\t\"xy_real_s\": xy_naive_series,\n",
    "\t}\n",
    "\n",
    "\treturn naive_sim_data\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance calculations for $\\theta$ (undamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_settling_time_th(th_0_abs_error_series, th_des_ana, th_start_ana, settling_time_threshold = 0.05):\n",
    "\n",
    "\t\"\"\"\n",
    "\tFunction to calculate settling time of a simulation\n",
    "\t\"\"\"\n",
    "\n",
    "\tth_distance = torch.abs(th_des_ana[0,0] - th_start_ana[0,0])\n",
    "\ttolerance = settling_time_threshold * th_distance\n",
    "\n",
    "\twithin_tolerance = th_0_abs_error_series <= tolerance\n",
    "\n",
    "\treverse_within_tolerance = within_tolerance.flip(0)\n",
    "\n",
    "\trev_cum_and = torch.cumprod(reverse_within_tolerance.to(torch.uint8), dim=0).bool()\n",
    "\tsuffix_all_true = rev_cum_and.flip(0)\n",
    "\n",
    "\tidx = torch.nonzero(suffix_all_true).squeeze()\n",
    "\n",
    "\tif idx.numel() == 0:\n",
    "\t\tprint(\"Did not reach within 5% tolerance.\")\n",
    "\t\tsettling_time = th_0_abs_error_series.size()[0] * dt\n",
    "\telse:\n",
    "\t\tsettling_idx = idx[0].item()\n",
    "\t\tsettling_time = settling_idx * dt\n",
    "\t\tprint(f\"Reached within 5% tolerance at t = {settling_time:.2f} seconds.\")\n",
    "\n",
    "\treturn settling_time, tolerance\n",
    "\n",
    "def calc_rmse_th(theta_real_series, th_des_ana, settled_index = 200):\n",
    "\n",
    "\tth0_series = theta_real_series[settled_index:, 0]\n",
    "\trmse = torch.sqrt(torch.mean((th0_series - th_des_ana[0, 0]) ** 2)).item()\n",
    "\n",
    "\treturn rmse\n",
    "\n",
    "\n",
    "\n",
    "def calc_overshoot_th(theta_real_series, th_des_ana, th_start_ana):\n",
    "\tth0_series = theta_real_series[:, 0]\n",
    "\tth0_des = th_des_ana[0, 0]\n",
    "\tth0_start = th_start_ana[0, 0]\n",
    "\tdistance = th0_des - th0_start\n",
    "\tth0_shortest = torch.min(th0_series)\n",
    "\tovershoot = torch.clamp(th0_des - th0_shortest, min = 0.)\n",
    "\tovershoot_ratio = torch.abs(overshoot/distance)\n",
    "\tovershoot_percent = overshoot_ratio * 100\n",
    "\treturn overshoot_percent.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_settling_th(th_0_error_series, tolerance, settling_time):\n",
    "\t# Time vector (same length as error series)\n",
    "\tt_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "\t# Detach if needed (for plotting outside torch computation graph)\n",
    "\terror_np = th_0_error_series.detach().cpu().numpy()\n",
    "\tt_np = t_series.cpu().numpy()\n",
    "\n",
    "\t# Plot\n",
    "\tplt.figure(figsize=(4, 3))\n",
    "\tplt.plot(t_np, error_np, label=r\"$\\bar{θ}_{0} - θ_{0}$\", color='tab:blue')\n",
    "\tplt.axhline(y=-tolerance.item(), color='tab:red', linestyle='--', label=\"-5% Tolerance\")\n",
    "\tplt.axhline(y=tolerance.item(), color='tab:red', linestyle='--', label=\"5% Tolerance\")\n",
    "\tplt.axvline(x=settling_time, color='tab:green', linestyle='--', label=\"Settling Time\")\n",
    "\n",
    "\tplt.title(\"Error of \" + r\"$θ_0$\" + \" vs Time\")\n",
    "\tplt.xlabel(\"Time [s]\")\n",
    "\tplt.ylabel(\"Error [m]\")\n",
    "\tplt.xlim(0, t_end)\n",
    "\tplt.legend()\n",
    "\tplt.grid(True)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 50\n",
    "\n",
    "x_des_min, x_des_max = rp[\"xa\"], rp[\"xa\"]\n",
    "y_des_min, y_des_max = 0.5, 1.5\n",
    "x_des_series = torch.rand(n_sims) * (x_des_max - x_des_min) + x_des_min\n",
    "y_des_series = torch.rand(n_sims) * (y_des_max - y_des_min) + y_des_min\n",
    "xy_des_series = torch.stack((x_des_series, y_des_series), dim=1).requires_grad_().to(device)\n",
    "\n",
    "x_start_min, x_start_max = 1., 3.\n",
    "y_start_min, y_start_max = -3., 0.5\n",
    "x_start_series = torch.rand(n_sims) * (x_start_max - x_start_min) + x_start_min\n",
    "y_start_series = torch.rand(n_sims) * (y_start_max - y_start_min) + y_start_min\n",
    "xy_start_series = torch.stack((x_start_series, y_start_series), dim=1).requires_grad_().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple simulations, no damping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_save_dir = \"collocated_results/performance_logs/undamped\"\n",
    "dict_save_names = [\"pdata_nn_sims_undamped_single_sim.pt\", \"pdata_ana_sims_undamped_single_sim.pt\", \"pdata_naive_sims_undamped_single_sim.pt\"]\n",
    "\n",
    "load_logs = False\n",
    "\n",
    "\n",
    "\n",
    "if load_logs:\n",
    "\tpdata_nn_sims = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[0])\n",
    "\tpdata_ana_sims = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[1])\n",
    "\tpdata_naive_sims = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[2])\n",
    "else:\n",
    "\tpdata_nn_sims = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"rmse_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_ana_sims = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"rmse_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_naive_sims = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"rmse_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_start_series = torch.tensor([[1.5071, -0.7751]]).to(device)\n",
    "xy_des_series = torch.tensor([[2.0000, 1.2936]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transforms.forward_kinematics(rp, torch.tensor([-1.7, 0.75]))[0])\n",
    "print(transforms.forward_kinematics(rp, torch.tensor([-0.5, 1.65]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_neural_net = True\n",
    "model_nn = autoencoders.Autoencoder_double(rp).to(device)\n",
    "model_location = '../Double_Pendulum/Learning/Models/NN_optimal/NN_0.pth'\n",
    "model_nn.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "sim_type = \"group\"\n",
    "stride = 2\n",
    "\n",
    "C_damp = torch.tensor([[0., 0.], [0., 0.]]).to(device)\n",
    "\n",
    "damping_value = 20\n",
    "C_damp = torch.tensor([[float(damping_value), 0.], [0., float(damping_value)]]).to(device)\n",
    "\n",
    "\n",
    "performance_data_dicts = [pdata_nn_sims]#, pdata_ana_sims, pdata_naive_sims]\n",
    "\n",
    "\n",
    "for i, (xy_des, xy_start) in enumerate(zip(xy_des_series, xy_start_series)):\n",
    "\n",
    "\tprint(\"xy_start:\", xy_start)\n",
    "\tprint(\"xy_des:\", xy_des)\n",
    "\n",
    "\ttimestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\tsave_dir = \"collocated_results/batched_sims/undamped/simulation_\" + sim_type + f\"_{timestamp}\"\n",
    "\t\n",
    "\tnns_data, q_des, q_start, th_des_ana, th_start_ana = sim_collocated_nn(xy_start, xy_des, timestamp, model_nn, C_damp)\n",
    "\n",
    "\t#anas_data = sim_collocated_ana(xy_start, xy_des, timestamp, model_ana, C_damp)\n",
    "\n",
    "\tnaives_data = sim_collocated_naive(xy_start, xy_des, timestamp, C_damp)\n",
    "\n",
    "\tsimulation_data_multi = [nns_data]#, anas_data, naives_data]\n",
    "\t\n",
    "\tplt_col.save_metadata(rp, dt, t_end, timestamp, xy_des, xy_start, Kp, Kd, sim_type, use_neural_net, model_cw, model_location, save_dir)\n",
    "\n",
    "\txy_multiseries = (None, None, None)\n",
    "\t#xy_multiseries = (nns_data[\"xy_real_s\"], anas_data[\"xy_real_s\"], naives_data[\"xy_real_s\"])\n",
    "\tq_multiseries = (nns_data[\"q_real_s\"], None, naives_data[\"q_real_s\"])#, anas_data[\"q_real_s\"], naives_data[\"q_real_s\"])\n",
    "\tth_multiseries = (nns_data[\"th_ana_s\"], None, naives_data[\"th_ana_s\"])#, anas_data[\"th_ana_s\"], naives_data[\"th_ana_s\"])\n",
    "\n",
    "\n",
    "\tplt_col.save_trajectory_plots(rp, dt, t_end, xy_des, q_des, th_des_ana, save_dir, xy_multiseries, q_multiseries, th_multiseries)\n",
    "\tplt_col.create_video(rp, dt, t_end, plotter, stride, q_multiseries, xy_des, save_dir, \"Collocated vs. naive controller\")\n",
    "\n",
    "\t\n",
    "\tfor j, (dict, data) in enumerate(zip(performance_data_dicts, simulation_data_multi)):\n",
    "\n",
    "\t\tth_0_error_series = th_des_ana[0, 0] - data[\"th_ana_s\"][:, 0]\n",
    "\t\tth_0_abs_error_series = torch.abs(th_0_error_series)\n",
    "\t\t\n",
    "\t\tsettling_time, tolerance = calc_settling_time_th(th_0_abs_error_series, th_des_ana, th_start_ana, settling_time_threshold)\n",
    "\t\trmse = calc_rmse_th(data[\"th_ana_s\"], th_des_ana, settled_index = 200)\n",
    "\t\tovershoot = calc_overshoot_th(data[\"th_ana_s\"], th_des_ana, th_start_ana)\n",
    "\t\tcontrol_effort = data[\"u_s\"]**2\n",
    "\t\tmean_control_effort = torch.mean(control_effort).item()\n",
    "\t\tdict[\"overshoot_s\"].append(overshoot)\n",
    "\t\tdict[\"settling_time_s\"].append(settling_time)\n",
    "\t\tdict[\"rmse_s\"].append(rmse)\n",
    "\t\tdict[\"control_effort_s\"].append(mean_control_effort)\n",
    "\n",
    "\t\t#plot_settling_th(th_0_error_series, tolerance, settling_time)\n",
    "\n",
    "\t\tsave_performance_dict(dict, dict_save_dir, dict_save_names[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_col.save_trajectory_plots(rp, dt, t_end, xy_des, q_des, th_des_ana, save_dir, xy_multiseries, q_multiseries, th_multiseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxplot(values_nn, values_ana, values_q, plot_title, ylabel):\n",
    "\tfig, ax = plt.subplots(figsize=(5, 2))\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(plot_title)\n",
    "\n",
    "\tboxdata = [values_nn, values_ana, values_q]\n",
    "\tcolors = [\"tab:orange\", \"tab:blue\", \"tab:green\"]\n",
    "\tlabels = [r\"$\\theta_L$\", r\"$\\theta_A$\", r\"$q$\"]\n",
    "\n",
    "\tbplot = ax.boxplot(boxdata,\n",
    "\t\t\t\t\tpatch_artist=True,  # fill with color\n",
    "\t\t\t\t\ttick_labels=labels)  # will be used to label x-ticks\n",
    "\t\n",
    "\tfor median in bplot[\"medians\"]:\n",
    "\t\tmedian.set_color(\"black\")\n",
    "\n",
    "\t# fill with colors\n",
    "\tfor patch, color in zip(bplot['boxes'], colors):\n",
    "\t\tpatch.set_facecolor(color)\n",
    "\tplt.grid(linestyle=\"--\", axis=\"y\")\n",
    "\tplt.show()\n",
    "\n",
    "def make_boxplot_double(values_nn, values_ana, values_q, plot_title, ylabel):\n",
    "\tfig, ax = plt.subplots(figsize=(5, 2))\n",
    "\tax.set_ylabel(ylabel)\n",
    "\tax.set_title(plot_title)\n",
    "\n",
    "\tboxdata = [values_nn, values_ana, values_q]\n",
    "\tcolors = [\"tab:orange\", \"tab:blue\", \"tab:green\"]\n",
    "\tlabels = [r\"$\\theta_L$\", r\"$\\theta_A$\", r\"$q$\"]\n",
    "\n",
    "\tbplot = ax.boxplot(boxdata,\n",
    "\t\t\t\t\tpatch_artist=True,  # fill with color\n",
    "\t\t\t\t\ttick_labels=labels)  # will be used to label x-ticks\n",
    "\t\n",
    "\tfor median in bplot[\"medians\"]:\n",
    "\t\tmedian.set_color(\"black\")\n",
    "\n",
    "\t# fill with colors\n",
    "\tfor patch, color in zip(bplot['boxes'], colors):\n",
    "\t\tpatch.set_facecolor(color)\n",
    "\tplt.grid(linestyle=\"--\", axis=\"y\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_boxplot(pdata_nn_sims[\"rmse_s\"], pdata_ana_sims[\"rmse_s\"], pdata_naive_sims[\"rmse_s\"], plot_title = \"Steady state error, collocated & naive controller\", ylabel=\"RMSE \" + r\"$(m)$\")\n",
    "make_boxplot(pdata_nn_sims[\"control_effort_s\"], pdata_ana_sims[\"control_effort_s\"], pdata_naive_sims[\"control_effort_s\"], plot_title = \"Control effort, collocated & naive controller\", ylabel=\"Mean control effort \" + r\"$(u^2)$\")\n",
    "make_boxplot(pdata_nn_sims[\"settling_time_s\"], pdata_ana_sims[\"settling_time_s\"], pdata_naive_sims[\"settling_time_s\"], plot_title = \"Settling time, collocated & naive controller\", ylabel=\"Settling time \" + r\"$(s)$\")\n",
    "make_boxplot(pdata_nn_sims[\"overshoot_s\"], pdata_ana_sims[\"overshoot_s\"], pdata_naive_sims[\"overshoot_s\"], plot_title = \"Overshoot, collocated & naive controller\", ylabel=\"Overshoot\" + r\"$(\\%)$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance calculations for $q$ (damped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_settling_time_q(q_abs_error_series, q_des, q_start, settling_time_threshold = 0.05):\n",
    "\n",
    "\t\"\"\"\n",
    "\tFunction to calculate settling time of a simulation\n",
    "\t\"\"\"\n",
    "\tq_distance = torch.norm(q_des - q_start)\n",
    "\n",
    "\ttolerance = settling_time_threshold * q_distance\n",
    "\n",
    "\tq_l2_error_series = torch.norm(q_abs_error_series, dim = 1)\n",
    "\n",
    "\twithin_tolerance = q_l2_error_series <= tolerance\n",
    "\treverse_within_tolerance = within_tolerance.flip(0)\n",
    "\n",
    "\trev_cum_and = torch.cumprod(reverse_within_tolerance.to(torch.uint8), dim=0).bool()\n",
    "\tsuffix_all_true = rev_cum_and.flip(0)\n",
    "\n",
    "\tidx = torch.nonzero(suffix_all_true).squeeze(0)\n",
    "\n",
    "\tif idx.numel() == 0:\n",
    "\t\tprint(\"Did not reach within 5% tolerance.\")\n",
    "\t\tsettling_time = q_abs_error_series.size()[0] * dt\n",
    "\telse:\n",
    "\t\tsettling_idx = idx[0].item()\n",
    "\t\tsettling_time = settling_idx * dt\n",
    "\t\tprint(f\"Reached within 5% tolerance at t = {settling_time:.2f} seconds.\")\n",
    "\n",
    "\treturn settling_time, tolerance\n",
    "\n",
    "def calc_final_error_q(q_real_series, q_des):\n",
    "\n",
    "\tfinal_value = q_real_series[-1].unsqueeze(0)\n",
    "\tfinal_errors = q_des - final_value\n",
    "\tfinal_error = torch.norm(final_errors)\n",
    "\n",
    "\treturn final_error.item()\n",
    "\n",
    "def calc_overshoot_q(q_real_series, q_des, q_start):\n",
    "\n",
    "\tovershoot_percents = torch.empty((2))\n",
    "\n",
    "\n",
    "\tfor i in range(q_real_series.size(1)):\n",
    "\t\tqi_series = q_real_series[:, i]\n",
    "\t\tqi_des = q_des[0, i]\n",
    "\t\tqi_start = q_start[0, i]\n",
    "\t\tdistance = qi_des - qi_start\n",
    "\n",
    "\t\tif distance >= 0: #Then that means q0 starts at a smaller angle, and ends at a larger one. We are looking for the largest value\n",
    "\t\t\tqi_largest = torch.max(qi_series)\n",
    "\t\t\tovershoot = torch.clamp(qi_des - qi_largest, max = 0.)\n",
    "\t\telif distance < 0:\n",
    "\t\t\tqi_smallest = torch.min(qi_series)\n",
    "\t\t\tovershoot = torch.clamp(qi_des - qi_smallest, min = 0.)\n",
    "\t\t\n",
    "\t\tovershoot_ratio = torch.abs(overshoot/distance)\n",
    "\t\tovershoot_percents[i] = overshoot_ratio * 100\n",
    "\n",
    "\tovershoot_percent = torch.norm(overshoot_percents)\n",
    "\t\n",
    "\treturn overshoot_percent.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_settling_q(q_l2_error_series, tolerance, settling_time):\n",
    "\t# Time vector (same length as error series)\n",
    "\tt_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "\t# Detach if needed (for plotting outside torch computation graph)\n",
    "\terror_np = q_l2_error_series.detach().cpu().numpy()\n",
    "\tt_np = t_series.cpu().numpy()\n",
    "\n",
    "\t# Plot\n",
    "\tplt.figure(figsize=(4, 3))\n",
    "\tplt.plot(t_np, error_np, label=r\"$\\bar{q}_{0} - q_{0}$\", color='tab:blue')\n",
    "\tplt.axhline(y=-tolerance.item(), color='tab:red', linestyle='--', label=\"-5% Tolerance\")\n",
    "\tplt.axhline(y=tolerance.item(), color='tab:red', linestyle='--', label=\"5% Tolerance\")\n",
    "\tplt.axvline(x=settling_time, color='tab:green', linestyle='--', label=\"Settling Time\")\n",
    "\n",
    "\tplt.title(\"Error of \" + r\"$q$\" + \" vs Time\")\n",
    "\tplt.xlabel(\"Time [s]\")\n",
    "\tplt.ylabel(\"Error [rad]\")\n",
    "\tplt.xlim(0, t_end)\n",
    "\tplt.legend()\n",
    "\tplt.grid(True)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple simulations, with damping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_value = 10\n",
    "C_damp = torch.tensor([[float(damping_value), 0.], [0., float(damping_value)]]).to(device)\n",
    "\n",
    "dict_save_dir = \"collocated_results/performance_logs/damped_c=\" + str(damping_value)\n",
    "dict_save_names = [\"pdata_nn_sims_single_sim.pt\", \"pdata_ana_sims_single_sim.pt\", \"pdata_naive_sims_single_sim.pt\"]\n",
    "\n",
    "use_neural_net = True\n",
    "model_nn = autoencoders.Autoencoder_double(rp).to(device)\n",
    "model_location = '../Double_Pendulum/Learning/Models/NN_optimal/NN_0.pth'\n",
    "model_nn.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "sim_type = \"group\"\n",
    "stride = 1\n",
    "\n",
    "\n",
    "load_logs = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if load_logs:\n",
    "\tpdata_nn_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[0])\n",
    "\tpdata_ana_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[1])\n",
    "\tpdata_naive_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[2])\n",
    "else:\n",
    "\tpdata_nn_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_ana_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_naive_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "performance_data_dicts = [pdata_nn_sims_damp, pdata_ana_sims_damp, pdata_naive_sims_damp]\n",
    "\n",
    "\n",
    "for i, (xy_des, xy_start) in enumerate(zip(xy_des_series, xy_start_series)):\n",
    "\n",
    "\tprint(\"xy_start:\", xy_start)\n",
    "\tprint(\"xy_des:\", xy_des)\n",
    "\n",
    "\ttimestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\tsave_dir = \"collocated_results/batched_sims/damped/simulation_\" + sim_type + f\"_{timestamp}\"\n",
    "\t\n",
    "\ttry:\n",
    "\t\t# Simulations\n",
    "\t\tnns_data, q_des, q_start, th_des_ana, th_start_ana = sim_collocated_nn(xy_start, xy_des, timestamp, model_nn, C_damp)\n",
    "\n",
    "\t\tanas_data = sim_collocated_ana(xy_start, xy_des, timestamp, model_ana, C_damp)\n",
    "\n",
    "\t\tnaives_data = sim_collocated_naive(xy_start, xy_des, timestamp, C_damp)\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Simulation failed at index {i} with error: {e}\")\n",
    "\t\tcontinue\n",
    "\n",
    "\tsimulation_data_multi = [nns_data, anas_data, naives_data]\n",
    "\t\n",
    "\tplt_col.save_metadata(rp, dt, t_end, timestamp, xy_des, xy_start, Kp, Kd, sim_type, use_neural_net, model_cw, model_location, save_dir)\n",
    "\n",
    "\txy_multiseries = (nns_data[\"xy_real_s\"], anas_data[\"xy_real_s\"], naives_data[\"xy_real_s\"])\n",
    "\tq_multiseries = (nns_data[\"q_real_s\"], anas_data[\"q_real_s\"], naives_data[\"q_real_s\"])\n",
    "\tth_multiseries = (nns_data[\"th_ana_s\"], anas_data[\"th_ana_s\"], naives_data[\"th_ana_s\"])\n",
    "\n",
    "\tplt_col.save_trajectory_plots(rp, dt, t_end, xy_des, q_des, th_des_ana, save_dir, xy_multiseries, q_multiseries, th_multiseries)\n",
    "\t#plt_col.create_video(rp, dt, t_end, plotter, stride, q_multiseries, xy_des, save_dir)\n",
    "\n",
    "\t\n",
    "\tfor j, (dict, data) in enumerate(zip(performance_data_dicts, simulation_data_multi)):\n",
    "\n",
    "\t\tq_error_series = q_des - data[\"q_real_s\"]\n",
    "\t\tq_l2_error_series = torch.norm(q_error_series, dim = 1)\n",
    "\t\tq_abs_error_series = torch.abs(q_error_series)\n",
    "\t\t\n",
    "\t\tsettling_time, tolerance = calc_settling_time_q(q_abs_error_series, q_des, q_start, settling_time_threshold)\n",
    "\t\tfinal_error = calc_final_error_q(data[\"q_real_s\"], q_des)\n",
    "\t\tovershoot = calc_overshoot_q(data[\"q_real_s\"], q_des, q_start)\n",
    "\n",
    "\t\tcontrol_effort = data[\"u_s\"]**2\n",
    "\t\tmean_control_effort = torch.mean(control_effort).item()\n",
    "\n",
    "\n",
    "\t\tdict[\"settling_time_s\"].append(settling_time)\n",
    "\t\tdict[\"final_error_s\"].append(final_error)\n",
    "\t\tdict[\"control_effort_s\"].append(mean_control_effort)\n",
    "\t\tdict[\"overshoot_s\"].append(overshoot)\n",
    "\n",
    "\t\tplot_settling_q(q_l2_error_series, tolerance, settling_time)\n",
    "\n",
    "\t\tsave_performance_dict(dict, dict_save_dir, dict_save_names[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_boxplot(pdata_nn_sims_damp[\"final_error_s\"], pdata_ana_sims_damp[\"final_error_s\"], pdata_naive_sims_damp[\"final_error_s\"], plot_title = \"Steady state error, different controllers, damped\", ylabel=\"RMSE \" + r\"$(rad)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"control_effort_s\"], pdata_ana_sims_damp[\"control_effort_s\"], pdata_naive_sims_damp[\"control_effort_s\"], plot_title = \"Control effort, different controllers, damped\", ylabel=\"Mean control effort \" + r\"$(u^2)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"settling_time_s\"], pdata_ana_sims_damp[\"settling_time_s\"], pdata_naive_sims_damp[\"settling_time_s\"], plot_title = \"Settling time, different controllers, damped\", ylabel=\"Settling time \" + r\"$(s)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"overshoot_s\"], pdata_ana_sims_damp[\"overshoot_s\"], pdata_naive_sims_damp[\"overshoot_s\"], plot_title = \"Overshoot, different controllers, damped\", ylabel=\"Overshoot\" + r\"$(\\%)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_value = 50\n",
    "C_damp = torch.tensor([[float(damping_value), 0.], [0., float(damping_value)]]).to(device)\n",
    "\n",
    "dict_save_dir = \"collocated_results/performance_logs/damped_c=\" + str(damping_value)\n",
    "dict_save_names = [\"pdata_nn_sims.pt_single_sim\", \"pdata_ana_sims_single_sim.pt\", \"pdata_naive_sims_single_sim.pt\"]\n",
    "\n",
    "use_neural_net = True\n",
    "model_nn = autoencoders.Autoencoder_double(rp).to(device)\n",
    "model_location = '../Double_Pendulum/Learning/Models/NN_optimal/NN_0.pth'\n",
    "model_nn.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "sim_type = \"group\"\n",
    "stride = 1\n",
    "\n",
    "\n",
    "load_logs = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if load_logs:\n",
    "\tpdata_nn_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[0])\n",
    "\tpdata_ana_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[1])\n",
    "\tpdata_naive_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[2])\n",
    "else:\n",
    "\tpdata_nn_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_ana_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\tpdata_naive_sims_damp = {\n",
    "\t\t\"settling_time_s\": [],\n",
    "\t\t\"overshoot_s\": [],\n",
    "\t\t\"final_error_s\": [],\n",
    "\t\t\"control_effort_s\": []\n",
    "\t}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "performance_data_dicts = [pdata_nn_sims_damp, pdata_ana_sims_damp, pdata_naive_sims_damp]\n",
    "\n",
    "\n",
    "for i, (xy_des, xy_start) in enumerate(zip(xy_des_series, xy_start_series)):\n",
    "\n",
    "\tprint(\"xy_start:\", xy_start)\n",
    "\tprint(\"xy_des:\", xy_des)\n",
    "\n",
    "\ttimestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\tsave_dir = \"collocated_results/batched_sims/damped/simulation_\" + sim_type + f\"_{timestamp}\"\n",
    "\t\n",
    "\ttry:\n",
    "\t\t# Simulations\n",
    "\t\tnns_data, q_des, q_start, th_des_ana, th_start_ana = sim_collocated_nn(xy_start, xy_des, timestamp, model_nn, C_damp)\n",
    "\n",
    "\t\tanas_data = sim_collocated_ana(xy_start, xy_des, timestamp, model_ana, C_damp)\n",
    "\n",
    "\t\tnaives_data = sim_collocated_naive(xy_start, xy_des, timestamp, C_damp)\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Simulation failed at index {i} with error: {e}\")\n",
    "\t\tcontinue\n",
    "\n",
    "\tsimulation_data_multi = [nns_data, anas_data, naives_data]\n",
    "\t\n",
    "\tplt_col.save_metadata(rp, dt, t_end, timestamp, xy_des, xy_start, Kp, Kd, sim_type, use_neural_net, model_cw, model_location, save_dir)\n",
    "\n",
    "\txy_multiseries = (nns_data[\"xy_real_s\"], anas_data[\"xy_real_s\"], naives_data[\"xy_real_s\"])\n",
    "\tq_multiseries = (nns_data[\"q_real_s\"], anas_data[\"q_real_s\"], naives_data[\"q_real_s\"])\n",
    "\tth_multiseries = (nns_data[\"th_ana_s\"], anas_data[\"th_ana_s\"], naives_data[\"th_ana_s\"])\n",
    "\n",
    "\tplt_col.save_trajectory_plots(rp, dt, t_end, xy_des, q_des, th_des_ana, save_dir, xy_multiseries, q_multiseries, th_multiseries)\n",
    "\t#plt_col.create_video(rp, dt, t_end, plotter, stride, q_multiseries, xy_des, save_dir)\n",
    "\n",
    "\t\n",
    "\tfor j, (dict, data) in enumerate(zip(performance_data_dicts, simulation_data_multi)):\n",
    "\n",
    "\t\tq_error_series = q_des - data[\"q_real_s\"]\n",
    "\t\tq_l2_error_series = torch.norm(q_error_series, dim = 1)\n",
    "\t\tq_abs_error_series = torch.abs(q_error_series)\n",
    "\t\t\n",
    "\t\tsettling_time, tolerance = calc_settling_time_q(q_abs_error_series, q_des, q_start, settling_time_threshold)\n",
    "\t\tfinal_error = calc_final_error_q(data[\"q_real_s\"], q_des)\n",
    "\t\tovershoot = calc_overshoot_q(data[\"q_real_s\"], q_des, q_start)\n",
    "\n",
    "\t\tcontrol_effort = data[\"u_s\"]**2\n",
    "\t\tmean_control_effort = torch.mean(control_effort).item()\n",
    "\n",
    "\n",
    "\t\tdict[\"settling_time_s\"].append(settling_time)\n",
    "\t\tdict[\"final_error_s\"].append(final_error)\n",
    "\t\tdict[\"control_effort_s\"].append(mean_control_effort)\n",
    "\t\tdict[\"overshoot_s\"].append(overshoot)\n",
    "\n",
    "\t\tplot_settling_q(q_l2_error_series, tolerance, settling_time)\n",
    "\n",
    "\t\tsave_performance_dict(dict, dict_save_dir, dict_save_names[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_boxplot(pdata_nn_sims_damp[\"final_error_s\"], pdata_ana_sims_damp[\"final_error_s\"], pdata_naive_sims_damp[\"final_error_s\"], plot_title = \"Steady state error, different controllers, damped\", ylabel=\"RMSE \" + r\"$(rad)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"control_effort_s\"], pdata_ana_sims_damp[\"control_effort_s\"], pdata_naive_sims_damp[\"control_effort_s\"], plot_title = \"Control effort, different controllers, damped\", ylabel=\"Mean control effort \" + r\"$(u^2)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"settling_time_s\"], pdata_ana_sims_damp[\"settling_time_s\"], pdata_naive_sims_damp[\"settling_time_s\"], plot_title = \"Settling time, different controllers, damped\", ylabel=\"Settling time \" + r\"$(s)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"overshoot_s\"], pdata_ana_sims_damp[\"overshoot_s\"], pdata_naive_sims_damp[\"overshoot_s\"], plot_title = \"Overshoot, different controllers, damped\", ylabel=\"Overshoot\" + r\"$(\\%)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_value = 10\n",
    "C_damp = torch.tensor([[float(damping_value), 0.], [0., float(damping_value)]]).to(device)\n",
    "\n",
    "dict_save_dir = \"collocated_results/performance_logs/damped_c=\" + str(damping_value)\n",
    "dict_save_names = [\"pdata_nn_sims.pt\", \"pdata_ana_sims.pt\", \"pdata_naive_sims.pt\"]\n",
    "\n",
    "load_logs = True\n",
    "\n",
    "\n",
    "if load_logs:\n",
    "\tpdata_nn_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[0])\n",
    "\tpdata_ana_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[1])\n",
    "\tpdata_naive_sims_damp = load_performance_dict(dict_save_dir + \"/\" + dict_save_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_boxplot(pdata_nn_sims_damp[\"final_error_s\"], pdata_ana_sims_damp[\"final_error_s\"], pdata_naive_sims_damp[\"final_error_s\"], plot_title = \"Steady state error, different controllers, damped\", ylabel=\"RMSE \" + r\"$(rad)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"control_effort_s\"], pdata_ana_sims_damp[\"control_effort_s\"], pdata_naive_sims_damp[\"control_effort_s\"], plot_title = \"Control effort, different controllers, damped\", ylabel=\"Mean control effort \" + r\"$(u^2)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"settling_time_s\"], pdata_ana_sims_damp[\"settling_time_s\"], pdata_naive_sims_damp[\"settling_time_s\"], plot_title = \"Settling time, different controllers, damped\", ylabel=\"Settling time \" + r\"$(s)$\")\n",
    "make_boxplot(pdata_nn_sims_damp[\"overshoot_s\"], pdata_ana_sims_damp[\"overshoot_s\"], pdata_naive_sims_damp[\"overshoot_s\"], plot_title = \"Overshoot, different controllers, damped\", ylabel=\"Overshoot\" + r\"$(\\%)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_col.save_trajectory_plots(rp, dt, t_end, xy_des, q_des, th_des_ana, save_dir, xy_multiseries, q_multiseries, th_multiseries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
