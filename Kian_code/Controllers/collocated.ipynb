{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "\tsys.path.insert(0, module_path)\n",
    "print(sys.path)\n",
    "\n",
    "import Double_Pendulum.Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.transforms as transforms\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Plotting.pendulum_plot as pendulum_plot\n",
    "\n",
    "\n",
    "import plot_collocated as plt_col\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family']   = 'serif'\n",
    "matplotlib.rcParams['font.serif']    = ['Times New Roman']\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "plotter = pendulum_plot.Anim_plotter(rp)\n",
    "neural_net = True\n",
    "\n",
    "model_cw = False\n",
    "\n",
    "if neural_net:\n",
    "\tmodel = autoencoders.Autoencoder_double(rp).to(device)\n",
    "\tmodel_location = '../Double_Pendulum/Learning/Models/NN_optimal/NN_0.pth'\n",
    "\tmodel.load_state_dict(torch.load(model_location, weights_only=True))\n",
    "else:\n",
    "\tmodel_location = \"N/A\"\n",
    "\tmodel = autoencoders.Analytic_transformer(rp)\n",
    "\n",
    "model_ana = autoencoders.Analytic_transformer(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When controlling on th_0\n",
    "#\"\"\"\n",
    "Kp = torch.tensor([[100., 0.], \n",
    "\t\t\t\t   [0., 0.]]).to(device)\n",
    "Kd = torch.tensor([[40., 0.], \n",
    "\t\t\t\t   [0., 0.]]).to(device)\n",
    "#\"\"\"\n",
    "\n",
    "# When controlling on th_1, just for testing\n",
    "\"\"\"\n",
    "Kp = torch.tensor([[0., 0.], \n",
    "\t\t\t\t   [0., 100.]]).to(device)\n",
    "Kd = torch.tensor([[0., 0.], \n",
    "\t\t\t\t   [0., 40.]]).to(device)\n",
    "\"\"\"\n",
    "\n",
    "# When controlling on both th_0 and th_1, just for testing\n",
    "\"\"\"\n",
    "Kp = torch.tensor([[100., 0.], \n",
    "\t\t\t\t   [0., 10.]]).to(device)\n",
    "Kd = torch.tensor([[40., 0.], \n",
    "\t\t\t\t   [0., 10.]]).to(device)\n",
    "\"\"\"\n",
    "\n",
    "#C_damp = torch.tensor([[12., 0.], [0., 12.]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define desired conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_conditions(xy_des):\n",
    "\tq_des = transforms.inverse_kinematics(xy_des, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "\tq_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\tis_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "\tth_des_ana = model_ana.encoder_vmap(q_des)\n",
    "\tth_d_des_ana = (model_ana.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "\tth_des_est = model.encoder_vmap(q_des)\n",
    "\tth_d_des_est = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "\tq_des_est = model.decoder_vmap(th_des_est, is_clockwise_des)\n",
    "\tq_d_des_est = (model.jacobian_dec(th_des_est, clockwise=is_clockwise_des) @ th_d_des_est.T).T\n",
    "\txy_des_est, _ = transforms.forward_kinematics(rp, q_des_est[0])\n",
    "\n",
    "\tprint(\"th_des_ana:\", th_des_ana.detach().cpu().numpy()[0])\n",
    "\tprint(\"th_des_est:\", th_des_est.detach().cpu().numpy()[0])\n",
    "\n",
    "\treturn (q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\t \tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define start conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conditions(xy_start):\n",
    "\tq_start = transforms.inverse_kinematics(xy_start, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "\tq_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\tq_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\tis_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "\tth_start_est = model.encoder_vmap(q_start)\n",
    "\tth_d_start_est = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "\tth_start_ana = model_ana.encoder_vmap(q_start)\n",
    "\tth_d_start_ana = (model_ana.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "\tq_start_est = model.decoder_vmap(th_start_est, is_clockwise_start)\n",
    "\tq_d_start_est = (model.jacobian_dec(th_start_est, clockwise=is_clockwise_start) @ th_d_start_est.T).T\n",
    "\txy_start_est, _ = transforms.forward_kinematics(rp, q_start_est[0])\n",
    "\n",
    "\tprint(\"th_start_ana:\", th_start_ana.detach().cpu().numpy()[0])\n",
    "\tprint(\"th_start_est:\", th_start_est.detach().cpu().numpy()[0])\n",
    "\n",
    "\treturn (q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\t \tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "t_end = 15\n",
    "t_series = torch.arange(0, t_end, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_collocated_nn(xy_start, xy_des, timestamp):\n",
    "\n",
    "\t(q_des, q_d_des, is_clockwise_des, th_des_ana, th_d_des_ana, \n",
    "\t\tth_des_est, th_d_des_est, q_des_est, q_d_des_est, xy_des_est) = desired_conditions(xy_des)\n",
    "\n",
    "\t(q_start, q_d_start, q_dd_start, is_clockwise_start, th_start_est, th_d_start_est, \n",
    "\t\tth_start_ana, th_d_start_ana, q_start_est, q_d_start_est, xy_start_est) = start_conditions(xy_start)\n",
    "\t\n",
    "\n",
    "\n",
    "\tth_series, th_d_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\tq_hat_series, q_d_hat_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\tq_real_series, q_d_real_series, q_dd_real_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\tu_series = torch.empty((0,1)).to(device)\n",
    "\ttau_q_series = torch.empty((0,2)).to(device)\n",
    "\n",
    "\tth = th_start_est\n",
    "\tth_d = th_d_start_est\n",
    "\n",
    "\tq_hat = q_start_est\n",
    "\tq_d_hat = q_d_start_est\n",
    "\n",
    "\tq_real, q_d_real, q_dd_real = q_start, q_d_start, q_dd_start\n",
    "\n",
    "\tis_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "\n",
    "\tfor t in torch.arange(0, t_end, dt):\n",
    "\t\tt_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "\t\tif torch.allclose(t, torch.floor(t)) and torch.floor(t)%5 == 0:\n",
    "\t\t\tprint(t_string)\n",
    "\n",
    "\t\tis_clockwise = transforms.check_clockwise(q_real.squeeze(0))\n",
    "\t\tif model_cw != is_clockwise:\n",
    "\t\t\tprint(\"fixing value to\", \"clockwise\" if model_cw else \"counterclockwise\")\n",
    "\t\t\tq = transforms.flip_q(rp, q_real.squeeze(0), model_cw).unsqueeze(0)\n",
    "\t\t\tq_d = transforms.flip_q_d(rp, q_real.squeeze(0), q_d_real, model_cw)\n",
    "\t\telse:\n",
    "\t\t\tq = q_real\n",
    "\t\t\tq_d = q_d_real\n",
    "\n",
    "\t\tth = model.encoder_vmap(q)\n",
    "\t\tth_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\t\t\n",
    "\t\tq_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "\t\tq_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "\n",
    "\t\tis_clockwise = transforms.check_clockwise(q_hat.squeeze(0))\n",
    "\n",
    "\t\t\"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\t\t\n",
    "\t\tJ_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\t\tJ_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "\t\tM_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "\t\tA_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\n",
    "\t\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\n",
    "\t\tM_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "\t\tA_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "\n",
    "\t\tu = torch.pinverse(A_th) @ ((Kp @ (th_des_est - th).T + Kd @ (th_d_des_est - th_d).T))\n",
    "\t\tu = u + torch.pinverse(A_th) @ G_th\n",
    "\n",
    "\t\t\"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "\t\tM_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real.squeeze(0), q_d_real.squeeze(0))\n",
    "\t\tA_q_real = dynamics.input_matrix(rp, q_real.squeeze(0))\n",
    "\n",
    "\t\ttau_q_real = A_q_real * u\n",
    "\t\tq_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T)- G_q_real)).T\n",
    "\t\tq_d_real = q_d_real + q_dd_real * dt\n",
    "\t\tq_real = q_real + q_d_real * dt\n",
    "\t\tq_real = transforms.wrap_to_pi(q_real)\n",
    "\t\t\n",
    "\t\tth = model.encoder_vmap(q_real)\n",
    "\t\tq_hat = model.decoder_vmap(th, clockwise=transforms.check_clockwise(q_real.squeeze(0)))\n",
    "\t\tq_hat = transforms.wrap_to_pi(q_hat)\n",
    "\t\tth_d = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "\t\tq_d_hat = (model.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "\n",
    "\n",
    "\t\t\"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "\t\tth_series = torch.cat((th_series, th.detach()), dim=0)\n",
    "\t\tth_d_series = torch.cat((th_d_series, th_d.detach()), dim=0)\n",
    "\t\t\n",
    "\t\tq_real_series = torch.cat((q_real_series, q_real.detach()), dim=0)\n",
    "\t\tq_d_real_series = torch.cat((q_d_real_series, q_d_real.detach()), dim=0)\n",
    "\t\tq_dd_real_series = torch.cat((q_dd_real_series, q_dd_real.detach()), dim=0)\n",
    "\n",
    "\t\tq_hat_series = torch.cat((q_hat_series, q_hat.detach()), dim=0)\n",
    "\t\tq_d_hat_series = torch.cat((q_d_hat_series, q_d_hat.detach()), dim=0)\n",
    "\n",
    "\t\tu_series = torch.cat((u_series, u.detach()), dim=0)\n",
    "\t\ttau_q_series = torch.cat((tau_q_series, tau_q_real.T.detach()), dim=0)\n",
    "\n",
    "\txy_real_series = torch.empty(q_real_series.size()).to(device)\n",
    "\txy_hat_series = torch.empty(q_real_series.size()).to(device)\n",
    "\ttheta_real_series = torch.empty((q_real_series.size())).to(device)\n",
    "\n",
    "\tfor i, (q_real, q_hat) in enumerate(zip(q_real_series, q_hat_series)):\n",
    "\t\txy_real, _ = transforms.forward_kinematics(rp, q_real)\n",
    "\t\txy_real_series[i] = xy_real.unsqueeze(0)\n",
    "\t\txy_hat, _ = transforms.forward_kinematics(rp, q_hat)\n",
    "\t\txy_hat_series[i] = xy_hat.unsqueeze(0)\n",
    "\t\ttheta_real = transforms.analytic_theta(rp, q_real)\n",
    "\t\ttheta_real_series[i] = theta_real\n",
    "\n",
    "\treturn ((th_series, th_d_series, q_real_series, q_d_real_series, q_dd_real_series, q_hat_series,\n",
    "\t\t\tq_d_hat_series, u_series, tau_q_series, xy_real_series, xy_hat_series, theta_real_series), th_des_ana, th_start_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 2\n",
    "\n",
    "settling_time_thsims = torch.empty(n_sims).to(device)\n",
    "rmse_thsims = torch.empty(n_sims).to(device)\n",
    "work_thsims = torch.empty(n_sims).to(device)\n",
    "\n",
    "for i in range(n_sims):\n",
    "\n",
    "\ttimestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\txy_des = torch.tensor([2., -2.]).requires_grad_().to(device)\n",
    "\txy_start = torch.tensor([0., -4.]).requires_grad_().to(device)\n",
    "\t\n",
    "\t((th_series, th_d_series, q_real_series, q_d_real_series, q_dd_real_series, q_hat_series,\n",
    "\t\t\tq_d_hat_series, u_series, tau_q_series, xy_real_series, xy_hat_series, theta_real_series),\n",
    "\t\t\tth_des_ana, th_start_ana) = sim_collocated_nn(xy_start, xy_des, timestamp)\n",
    "\t\n",
    "\t\n",
    "\n",
    "\tth_distance = torch.abs(th_des_ana[0,0] - th_start_ana[0,0])\n",
    "\tsettling_time_threshold = 0.05\n",
    "\ttolerance = settling_time_threshold * th_distance\n",
    "\n",
    "\tprint(\"Tolerance distance from th_des:\", round(tolerance.item(), 5), \"[m]\")\n",
    "\n",
    "\tth_0_abs_error_series = torch.abs(theta_real_series[:, 0] - th_des_ana[0, 0])\n",
    "\n",
    "\twithin_tolerance = th_0_abs_error_series <= tolerance\n",
    "\tfirst_match_idx = torch.nonzero(within_tolerance).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\tif first_match_idx.numel() > 0:\n",
    "\t\tfirst_time_idx = first_match_idx[0].item()\n",
    "\t\ttime_to_reach = first_time_idx * dt\n",
    "\t\tsettled_theta = theta_real_series[3*first_time_idx:, 0]\n",
    "\t\trmse = torch.sqrt(torch.mean((settled_theta - th_des_ana[0, 0]) ** 2))\n",
    "\t\tprint(f\"Reached within 5% tolerance at t = {time_to_reach:.2f} seconds.\")\n",
    "\t\tprint(f\"RMSE after 3x settling time: {rmse.item():.6f} [m]\")\n",
    "\telse:\n",
    "\t\tprint(\"Did not reach within 5% tolerance.\")\n",
    "\t\ttime_to_reach = torch.inf\n",
    "\t\trmse = torch.inf\n",
    "\n",
    "\n",
    "\tjoint_power_series = tau_q_series * q_d_real_series\n",
    "\tpower_series = torch.sum(joint_power_series, dim = 1)\n",
    "\ttotal_work = torch.sum(power_series)\n",
    "\n",
    "\tsettling_time_thsims[i] = time_to_reach\n",
    "\trmse_thsims[i] = rmse\n",
    "\twork_thsims[i] = total_work\n",
    "\n",
    "\t\n",
    "\n",
    "\t# Time vector (same length as error series)\n",
    "\tt_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "\t# Detach if needed (for plotting outside torch computation graph)\n",
    "\terror_np = th_0_abs_error_series.detach().cpu().numpy()\n",
    "\tt_np = t_series.cpu().numpy()\n",
    "\n",
    "\t# Plot\n",
    "\tplt.figure(figsize=(4, 3))\n",
    "\tplt.plot(t_np, error_np, label=r\"$|θ_{0} - θ_{0_{des}}|$\", color='tab:blue')\n",
    "\tplt.axhline(y=tolerance.item(), color='tab:red', linestyle='--', label=\"5% Tolerance\")\n",
    "\tplt.axvline(x=time_to_reach, color='tab:green', linestyle='--', label=\"Settling Time\")\n",
    "\n",
    "\tplt.title(\"Absolute Error of \" + r\"$θ_0$\" + \" vs Time\")\n",
    "\tplt.xlabel(\"Time [s]\")\n",
    "\tplt.ylabel(\"Absolute Error [m]\")\n",
    "\tplt.xlim(0, t_end)\n",
    "\tplt.legend()\n",
    "\tplt.grid(True)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(settling_time_thsims)\n",
    "print(rmse_thsims)\n",
    "print(work_thsims)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('Settling time [s]')\n",
    "\n",
    "boxdata = [settling_time_thsims.cpu(), rmse_thsims.cpu().detach()]\n",
    "colors = [\"tab:orange\", \"tab:blue\"]\n",
    "labels = [\"hi\", \"ho\"]\n",
    "\n",
    "bplot = ax.boxplot(boxdata,\n",
    "\t\t\t\t   patch_artist=True,  # fill with color\n",
    "\t\t\t\t   tick_labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "# fill with colors\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "\tpatch.set_facecolor(color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"collocated_results/simulation_{timestamp}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(xy_start[1])\n",
    "print(Kp[0,0].item())\n",
    "metadata = {\n",
    "\t\"timestamp\": timestamp,\n",
    "\t\"Learned transform\": neural_net,\n",
    "\t\"Model location\": model_location,\n",
    "\t\"Model clockwise\": model_cw, \n",
    "\t\"PD gains\": {\n",
    "\t\t\"Kp\": [[Kp[0,0].item(), Kp[0,1].item()], \n",
    "\t\t\t   [Kp[1,0].item(), Kp[1,1].item()]],  \n",
    "\t\t\"Kd\": [[Kd[0,0].item(), Kd[0,1].item()], \n",
    "\t\t\t   [Kd[1,0].item(), Kd[1,1].item()]]   \n",
    "\t},\n",
    "\t\"Actuator location\": {\"x_a\": rp[\"xa\"], \"y_a\": rp[\"ya\"]},\n",
    "\t\"xy start\": {\"x\": xy_start[0].item(), \"y\": xy_start[1].item()},\n",
    "\t\"Time step\": dt,\n",
    "\t\"Sim time\": t_end,\n",
    "}\n",
    "\n",
    "metadata[\"PD gains\"][\"Kp\"] = str(metadata[\"PD gains\"][\"Kp\"])\n",
    "metadata[\"PD gains\"][\"Kd\"] = str(metadata[\"PD gains\"][\"Kd\"])\n",
    "\n",
    "metadata_path = os.path.join(save_dir, \"metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "\tjson.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 1\n",
    "pos_end_q_real, pos_elbow_q_real = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_real_series[::stride])\n",
    "pos_end_q_est, pos_elbow_q_est = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_est_series[::stride])\n",
    "#pos_end_q_naive, pos_elbow_q_naive = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_naive_series[::stride])\n",
    "\n",
    "frames_q_real = plotter.frame_pendulum(pos_end_q_real, pos_elbow_q_real)\n",
    "frames_q_est = plotter.frame_pendulum(pos_end_q_est, pos_elbow_q_est)\n",
    "#frames_q_naive = plotter.frame_pendulum(pos_end_q_naive, pos_elbow_q_naive)\n",
    "\n",
    "data_real = {\n",
    "\t\"frames\": frames_q_real,\n",
    "\t\"times\": dt,\n",
    "\t\"name\": \"q_real\", \n",
    "\t\"arm_color\": \"tab:blue\",\n",
    "\t\"act_color\": \"tab:cyan\"\n",
    "}\n",
    "\n",
    "data_est = {\n",
    "\t\"frames\": frames_q_est,\n",
    "\t\"times\": dt,\n",
    "\t\"name\": \"q_est\",\n",
    "\t\"arm_color\": \"tab:orange\", \n",
    "\t\"act_color\": \"tab:red\"\n",
    "} \n",
    "\n",
    "\"\"\"\n",
    "data_naive = {\n",
    "\t\"frames\": frames_q_naive,\n",
    "\t\"times\": dt,\n",
    "\t\"name\": \"q_naive\",\n",
    "\t\"arm_color\": \"tab:green\", \n",
    "\t\"act_color\": \"tab:olive\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "ref_pos_real = {\n",
    "\t\"pos\": xy_des,\n",
    "\t\"name\": \"real\",\n",
    "\t\"color\": \"tab:blue\"\n",
    "}\n",
    "\n",
    "ref_pos_est = {\n",
    "\t\"pos\": xy_des_est,\n",
    "\t\"name\": \"est\",\n",
    "\t\"color\": \"tab:orange\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "ref_pos_naive = {\n",
    "\t\"pos\": xy_des,\n",
    "\t\"name\": \"naive\",\n",
    "\t\"color\": \"tab:green\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "ref_poss = [ref_pos_real]#, ref_pos_est]#, ref_pos_naive]\n",
    "\n",
    "frames_data = [data_real, data_est]#, data_naive]\n",
    "#frames_data = [data_est]\n",
    "#frames_data = [data_real]\n",
    "\n",
    "name_rp = \"RP:(\" + str(rp[\"xa\"]) + \",\" + str(rp[\"ya\"]) + \")_\"\n",
    "name_ref = \"ref:(\" + str(xy_des[0].item()) + \",\" + str(xy_des[1].item()) + \")_\"\n",
    "\n",
    "if neural_net:\n",
    "\tmodel_type = \"NN\"\n",
    "else:\n",
    "\tmodel_type = \"AL\"\n",
    "\n",
    "file_name = \"t_end:[\" + str(t_end) + \"]_dt:[\" + str(dt) + \"]_stride:[\" + str(stride) + \"]_0.mp4\"\n",
    "file_counter = 0\n",
    "\n",
    "output_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "while os.path.isfile(output_path):\n",
    "\tprint(\"file name already exists\")\n",
    "\tfile_counter += 1\n",
    "\tfile_name = file_name[:-6] + \"_\" + str(file_counter) + \".mp4\"\n",
    "\toutput_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "plotter.animate_pendulum(frames_data, ref_poss=ref_poss, plot_actuator=True, save_path=output_path, fps = 1/(dt*stride), dt = dt*stride)\n",
    "#plotter.animate_pendulum(frames_data, ref_pos=None, plot_actuator=False, file_name=file_name, fps = 1/(dt*stride), dt = dt*stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_q = [\n",
    "\t#{\n",
    "\t#    \"name\": \"est\",\n",
    "\t#    \"values\": q_est_series.cpu().detach().numpy(),\n",
    "\t#    \"color\": \"tab:orange\"\n",
    "\t#},\n",
    "\t{\n",
    "\t\t\"name\": \"real\",\n",
    "\t\t\"values\": q_real_series.cpu().detach().numpy(),\n",
    "\t\t\"color\": \"tab:blue\"\n",
    "\t}#,\n",
    "\t#{\n",
    "\t#    \"name\": \"naive\",\n",
    "\t#    \"values\": q_naive_series.cpu().detach().numpy(),\n",
    "\t#    \"color\": \"tab:green\"\n",
    "\t#}\n",
    "]\n",
    "datasets_th = [\n",
    "\t{\n",
    "\t\t\"name\": \"est\",\n",
    "\t\t\"values\": th_series.cpu().detach().numpy(),\n",
    "\t\t\"color\": \"tab:orange\"\n",
    "\t}#,56\n",
    "\t#{\n",
    "\t#    \"name\": \"ana\",\n",
    "\t#    \"values\": th_\n",
    "\t#    \"color\": \"tab:blue\"\n",
    "\t#}\n",
    "]\n",
    "\n",
    "datasets_xy = [\n",
    "\t#{\n",
    "\t#    \"name\": \"est\",\n",
    "\t#    \"values\": xy_est_series.cpu().detach().numpy(),\n",
    "\t#    \"color\": \"tab:orange\"\n",
    "\t#},\n",
    "\t{\n",
    "\t\t\"name\": \"real\",\n",
    "\t\t\"values\": xy_real_series.cpu().detach().numpy(),\n",
    "\t\t\"color\": \"tab:blue\"\n",
    "\t}#,\n",
    "\t#{\n",
    "\t#    \"name\": \"naive\",\n",
    "\t#    \"values\": xy_naive_series.cpu().detach().numpy(),\n",
    "\t#    \"color\": \"tab:green\"\n",
    "\t#}\n",
    "]\n",
    "\n",
    "# Common labels for the plots.\n",
    "name_q = \"q trajectory\"\n",
    "name_th = \"th trajectory\"\n",
    "name_xy = \"xy trajectory\"\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "# Create an instance of ErrorPlotter.\n",
    "ep = pendulum_plot.Error_plotter(rp)\n",
    "\n",
    "# Prepare plot datasets for each column.\n",
    "# Each call groups a set of datasets to be drawn in one subplot column.\n",
    "column1 = ep.create_plot_dataset(t=t_series, datasets=datasets_q, reference=q_des, name=name_q)\n",
    "column2 = ep.create_plot_dataset(t=t_series, datasets=datasets_th, reference=th_des, name=name_th)\n",
    "column3 = ep.create_plot_dataset(t=t_series, datasets=datasets_xy, reference=xy_des.unsqueeze(0), name=name_xy)\n",
    "plot_datasets = [column1, column2, column3]\n",
    "\n",
    "file_name = \"Error plot.png\"\n",
    "file_counter = 0\n",
    "\n",
    "output_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "# Pass the list of columns (plot_dataset objects) to plot_multi.\n",
    "ep.plot_multi(plot_datasets=plot_datasets, save_path=output_path, axes_names = [\"q\", \"th\", \"xy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "th_ana_series, th_d_ana_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_ana_series, q_d_ana_series, q_dd_ana_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "u_ana_series = torch.empty((0,1)).to(device)\n",
    "tau_q_ana_series = torch.empty((0,2)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 15\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "th = th_start_ana\n",
    "th_d = th_d_start_ana\n",
    "\n",
    "\n",
    "q_ana, q_d_ana, q_dd_ana = q_start, q_d_start, q_dd_start\n",
    "\n",
    "is_clockwise = False\n",
    "\n",
    "model = autoencoders.Analytic_transformer(rp)\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "\tt_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "\tprint(t_string)\n",
    "\n",
    "\n",
    "\tq_ana\n",
    "\tq_d_ana\n",
    "\n",
    "\tth_ana = model.encoder_vmap(q_ana)\n",
    "\tth_d_ana = (model.jacobian_enc(q_ana) @ q_d_ana.T).T\n",
    "\t\n",
    "\tq_hat_ana = model.decoder_vmap(th_ana, clockwise=model_cw)\n",
    "\tq_d_hat_ana = (model.jacobian_dec(th_ana) @ th_d_ana.T).T\n",
    "\n",
    "\t\"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\t\n",
    "\tJ_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "\tJ_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "\tM_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat_ana.squeeze(0), q_d_hat_ana.squeeze(0))\n",
    "\tA_q_est = dynamics.input_matrix(rp, q_hat_ana.squeeze(0))\n",
    "\n",
    "\n",
    "\t\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "\n",
    "\tM_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th_ana, th_d_ana, J_h_inv, J_h_inv_trans)\n",
    "\tA_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "\n",
    "\tu = torch.pinverse(A_th) @ ((Kp @ (th_des - th_ana).T + Kd @ (th_d_des - th_d_ana).T))\n",
    "\tu = u + torch.pinverse(A_th) @ G_th\n",
    "\n",
    "\t\"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "\tM_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_ana.squeeze(0), q_d_ana.squeeze(0))\n",
    "\tA_q_real = dynamics.input_matrix(rp, q_ana.squeeze(0))\n",
    "\n",
    "\ttau_q_real = A_q_real * u\n",
    "\tq_dd_ana = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_ana).T)- G_q_real)).T  #  - C_damp @ ((q_d_real).T) \n",
    "\tq_d_ana = q_d_ana + q_dd_ana * dt\n",
    "\tq_ana = q_ana + q_d_ana * dt\n",
    "\tq_ana = transforms.wrap_to_pi(q_ana)\n",
    "\t\n",
    "\tth_ana = model.encoder_vmap(q_ana)\n",
    "\tth_d_ana = (model.jacobian_enc(q_ana) @ q_d_ana.T).T\n",
    "\n",
    "\n",
    "\t\"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "\tth_ana_series = torch.cat((th_ana_series, th_ana.detach()), dim=0)\n",
    "\tth_d_ana_series = torch.cat((th_d_ana_series, th_d_ana.detach()), dim=0)\n",
    "\t\n",
    "\tq_ana_series = torch.cat((q_ana_series, q_ana.detach()), dim=0)\n",
    "\tq_d_ana_series = torch.cat((q_d_ana_series, q_d_ana.detach()), dim=0)\n",
    "\tq_dd_ana_series = torch.cat((q_dd_ana_series, q_dd_ana.detach()), dim=0)\n",
    "\n",
    "\tu_ana_series = torch.cat((u_ana_series, u.detach()), dim=0)\n",
    "\ttau_q_ana_series = torch.cat((tau_q_ana_series, tau_q_real.T.detach()), dim=0)\n",
    "\n",
    "\tprint(\"\")\n",
    "\n",
    "\t\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
