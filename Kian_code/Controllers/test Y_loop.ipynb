{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "import Double_Pendulum.Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Double_Pendulum.transforms as transforms\n",
    "\n",
    "import Double_Pendulum.normal_form as normal_form\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "rp[\"m0\"] = 0.\n",
    "print(rp)\n",
    "model = autoencoders.Analytic_transformer(rp)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cw = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_vs_time(single_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (single_list.shape[0] - 1) * dt, single_list.shape[0]).numpy()\n",
    "    single_np = single_list.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, single_np, label=ylabel)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_double_vs_time(double_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (double_list.shape[0] - 1) * dt, double_list.shape[0]).numpy()\n",
    "    double_np = double_list.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, double_np[:, 0], label=ylabel+\"0\")\n",
    "    plt.plot(time, double_np[:, 1], label=ylabel+\"1\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_quad_vs_time(quad_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (quad_list.shape[0] - 1) * dt, quad_list.shape[0]).numpy()\n",
    "    quad_np = quad_list.cpu().numpy()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, quad_np[:, 0], label=\"Y\")\n",
    "    plt.plot(time, quad_np[:, 1], label=\"Y'\")\n",
    "    plt.plot(time, quad_np[:, 2], label=\"Y''\")\n",
    "    plt.plot(time, quad_np[:, 3], label=\"Y'''\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1., 10., 10., 10.]]).to(device)\n",
    "k_spring = 0.5\n",
    "if normal_form.check_stable_gains(K):\n",
    "    print(\"Gains are stable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define desired conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FOLLOWING COORDINATES RESULT IN STABLE Y_DES FOR k_spring = 0.5\n",
    "xy_des_real = torch.tensor([1.9218631, -2.5156569]).requires_grad_().to(device)\n",
    "q_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "q_des = transforms.inverse_kinematics(xy_des_real, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "is_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "th_des = model.encoder_vmap(q_des)\n",
    "th_d_des = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "# Use this if you want to directly define a desired th_des\n",
    "#th_des = torch.tensor([[7.5160644,  1.5604]]).requires_grad_().to(device)\n",
    "#th_d_des = torch.tensor([[0.,  0.]]).requires_grad_().to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(\"xy_des:\", xy_des_real)\n",
    "print(\"q_des:\", q_des)\n",
    "print(\"th_des\", th_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate desired dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_h_inv_des = model.jacobian_dec(th_des, is_clockwise_des).squeeze(0)\n",
    "J_h_inv_trans_des = torch.transpose(J_h_inv_des, 0, 1)\n",
    "\n",
    "q_hat_des = model.decoder_vmap(th_des, is_clockwise_des)\n",
    "q_d_hat_des = (model.jacobian_dec(th_des, clockwise=is_clockwise_des) @ th_d_des.T).T\n",
    "#xy_des_est, _ = transforms.forward_kinematics(rp, q_hat_des[0])\n",
    "\n",
    "M_q_des, C_q_des, G_q_des = dynamics.dynamical_matrices(rp, q_hat_des.squeeze(0), q_d_hat_des.squeeze(0))\n",
    "G_q_des = dynamics.add_spring_force_G_q(rp, q_hat_des, G_q_des, k_spring)\n",
    "A_q_des = dynamics.input_matrix(rp, q_des.squeeze(0))\n",
    "\n",
    "_, _, G_th_des = transforms.transform_dynamical_from_inverse(M_q_des, C_q_des, G_q_des, th_des, th_d_des, J_h_inv_des, J_h_inv_trans_des)\n",
    "M_th_des = torch.tensor([[rp[\"m1\"], 0.], [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "M_th_des = M_th_des * th_des/th_des\n",
    "A_th_des = transforms.transform_input_matrix_from_inverse_trans(A_q_des, J_h_inv_trans_des)\n",
    "\n",
    "Y_des_u = normal_form.calculate_Y(th_des, th_d_des, M_th_des, G_th_des, device)\n",
    "Y_des = torch.tensor([[Y_des_u[0,0]], [0], [0], [0]]).to(device)\n",
    "\n",
    "print(\"M_th des:\\n\", M_th_des)\n",
    "print(\"G_th des:\\n\", G_th_des)\n",
    "\n",
    "print(\"Y_des_u:\\n\", Y_des_u)\n",
    "print(\"Y_des:\\n\", Y_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define start conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xy_start = torch.tensor([2, -1.9]).requires_grad_().to(device)\n",
    "xy_start = xy_des_real * 1.001\n",
    "q_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "q_start = transforms.inverse_kinematics(xy_start, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "is_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "th_start = model.encoder_vmap(q_start)\n",
    "th_d_start = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "print(\"xy_start:\", xy_start)\n",
    "print(\"q_start:\", q_start)\n",
    "print(\"th_start:\", th_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate starting dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_h_inv_start = model.jacobian_dec(th_start, is_clockwise_start).squeeze(0)\n",
    "J_h_inv_trans_start = torch.transpose(J_h_inv_start, 0, 1)\n",
    "\n",
    "q_hat_start = model.decoder_vmap(th_start, is_clockwise_start)\n",
    "q_d_hat_start = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "\n",
    "M_q_start, C_q_start, G_q_start = dynamics.dynamical_matrices(rp, q_hat_start.squeeze(0), q_d_hat_start.squeeze(0))\n",
    "G_q_start = dynamics.add_spring_force_G_q(rp, q_hat_start, G_q_start, k_spring)\n",
    "A_q_start = dynamics.input_matrix(rp, q_hat_start.squeeze(0))\n",
    "\n",
    "_, _, G_th_start = transforms.transform_dynamical_from_inverse(M_q_start, C_q_start, G_q_start, th_start, th_d_start, J_h_inv_start, J_h_inv_trans_start)\n",
    "M_th_start = torch.tensor([[rp[\"m1\"], 0.], [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "M_th_start = M_th_start * th_start/th_start\n",
    "A_th_start = transforms.transform_input_matrix_from_inverse_trans(A_q_start, J_h_inv_trans_start)\n",
    "\n",
    "Y_start = normal_form.calculate_Y(th_start, th_d_start, M_th_start, G_th_start, device)\n",
    "v_start = normal_form.calculate_v(Y_start, Y_des, K)\n",
    "alpha_start, beta_start = normal_form.calculate_alpha_beta(th_start, th_d_start, M_th_start, G_th_start, A_th_start, Y_start)\n",
    "u_start = normal_form.calculate_u(alpha_start, beta_start, v_start)\n",
    "y_iv_start = normal_form.calculate_y_iv(alpha_start, beta_start, u_start)\n",
    "\n",
    "print(\"v_start:\", v_start)\n",
    "print(\"u_start:\", u_start)\n",
    "print(\"yiv_start:\", y_iv_start)\n",
    "\n",
    "print(\"M_th start:\\n\", M_th_start)\n",
    "print(\"G_th start:\\n\", G_th_start)\n",
    "print(\"A_th start:\\n\", A_th_start)\n",
    "\n",
    "print(\"Y_start:\", Y_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim in $\\theta$-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "th_series_thsim, th_d_series_thsim, th_dd_series_thsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_series_thsim, q_d_series_thsim, q_dd_series_thsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "Y_series_thsim = torch.empty((0,4)).to(device)\n",
    "v_series_thsim = torch.empty((0,1)).to(device)\n",
    "u_series_thsim = torch.empty((0,1)).to(device)\n",
    "alpha_beta_series_thsim = torch.empty((0,2)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 10\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "th = th_start\n",
    "th_d = th_d_start\n",
    "\n",
    "is_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    t_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "    print(t_string, end='\\r', flush=True)\n",
    "\n",
    "    #print(\"th:\", th)\n",
    "    #print(\"th_d:\", th_d)\n",
    "\n",
    "    q_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "    q_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "    \n",
    "    \"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "    G_q_est = dynamics.add_spring_force_G_q(rp, q_hat, G_q_est, k_spring)\n",
    "    A_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\n",
    "    \"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "    _, _, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "    M_th = torch.tensor([[rp[\"m1\"], 0.], \n",
    "                         [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "    M_th = M_th * th/th\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "    #A_th = torch.tensor([[1], [0]]).to(device)\n",
    "\n",
    "    Y = normal_form.calculate_Y(th, th_d, M_th, G_th, device)\n",
    "    alpha, beta = normal_form.calculate_alpha_beta(th, th_d, M_th, G_th, A_th, Y)\n",
    "\n",
    "    v = normal_form.calculate_v(Y, Y_des, K)\n",
    "    u = normal_form.calculate_u(alpha, beta, v)\n",
    "\n",
    "    if True:\n",
    "        print(\"t: t\")\n",
    "        print(\"q_hat:\", q_hat[0,0].item(), q_hat[0,1].item())\n",
    "        print(\"th:\", th[0,0].item(), th[0,1].item())\n",
    "        print(\"th_d:\", th_d[0,0].item(), th_d[0,1].item())\n",
    "        print(\"Y:\", Y)\n",
    "        print(\"v:\", v.item())\n",
    "        print(\"u:\", u.item())\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    \n",
    "    tau_th = A_th * u\n",
    "    th_dd = (torch.pinverse(M_th) @ (tau_th - G_th)).T\n",
    "    th_d = th_d + th_dd * dt\n",
    "    th = th + th_d * dt\n",
    "\n",
    "    if th[0,0] < 0:\n",
    "        th[0,0] = -th[0,0]\n",
    "        th[0,1] += torch.pi\n",
    "    \n",
    "    if th[0,1] > torch.pi:\n",
    "        th[0,1] -= 2*torch.pi\n",
    "    if th[0,1] < -torch.pi:\n",
    "        th[0,1] += 2*torch.pi\n",
    "\n",
    "    q_est = model.decoder_vmap(th, clockwise=is_clockwise)\n",
    "    q_est = transforms.wrap_to_pi(q_est)\n",
    "    q_d_est = (model.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series_thsim = torch.cat((th_series_thsim, th.detach()), dim=0)\n",
    "    th_d_series_thsim = torch.cat((th_d_series_thsim, th_d.detach()), dim=0)\n",
    "    th_dd_series_thsim = torch.cat((th_dd_series_thsim, th_dd.detach()), dim=0)\n",
    "\n",
    "    q_series_thsim = torch.cat((q_series_thsim, q_est.detach()), dim=0)\n",
    "    q_d_series_thsim = torch.cat((q_d_series_thsim, q_d_est.detach()), dim=0)\n",
    "\n",
    "    v_series_thsim = torch.cat((v_series_thsim, v.detach()), dim=0)\n",
    "    u_series_thsim = torch.cat((u_series_thsim, u.detach()), dim=0)\n",
    "    Y_series_thsim = torch.cat((Y_series_thsim, Y.detach().T))\n",
    "    alpha_beta_series_thsim = torch.cat((alpha_beta_series_thsim, torch.tensor([[alpha, beta]]).to(device)))\n",
    "    #print(\"\")\n",
    "\n",
    "    if torch.isnan(th[0,0]):\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim in q-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "th_series_qsim, th_d_series_qsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_series_qsim, q_d_series_qsim, q_dd_series_qsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "Y_series_qsim = torch.empty((0,4)).to(device)\n",
    "v_series_qsim = torch.empty((0,1)).to(device)\n",
    "u_series_qsim = torch.empty((0,1)).to(device)\n",
    "alpha_beta_series_qsim = torch.empty((0,2)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 5\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "q_real = q_start\n",
    "q_d_real = q_d_start\n",
    "\n",
    "is_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "fix_q = True\n",
    "model_shifting = True\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    t_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "    print(t_string, end='\\r', flush=True)\n",
    "\n",
    "    is_clockwise = transforms.check_clockwise(q_real.squeeze(0))\n",
    "    if fix_q and model_cw != is_clockwise:\n",
    "        print(\"fixing value to\", \"clockwise\" if model_cw else \"counterclockwise\")\n",
    "        q = transforms.flip_q(rp, q_real.squeeze(0), model_cw).unsqueeze(0)\n",
    "        q_d = transforms.flip_q_d(rp, q_real.squeeze(0), q_d_real, model_cw)\n",
    "    else:\n",
    "        q = q_real\n",
    "        q_d = q_d_real\n",
    "\n",
    "    if model_shifting:\n",
    "        q = transforms.shift_q(q, clockwise=model_cw)\n",
    "    th = model.encoder_vmap(q)\n",
    "    th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "    \n",
    "    q = model.decoder_vmap(th, clockwise=model_cw)\n",
    "    q_d = (model.jacobian_dec(th) @ th_d.T).T\n",
    "    \n",
    "    \"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "    G_q_est = dynamics.add_spring_force_G_q(rp, q, G_q_est, k_spring)\n",
    "    A_q_est = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "    _, _, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "    M_th = torch.tensor([[rp[\"m1\"], 0.], \n",
    "                         [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "    M_th = M_th * th/th\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "    A_th = torch.tensor([[1], [0]]).to(device)\n",
    "\n",
    "    Y = normal_form.calculate_Y(th, th_d, M_th, G_th, device)\n",
    "    alpha, beta = normal_form.calculate_alpha_beta(th, th_d, M_th, G_th, A_th, Y)\n",
    "\n",
    "    v = normal_form.calculate_v(Y, Y_des, K)\n",
    "    u = normal_form.calculate_u(alpha, beta, v)\n",
    "    #y_iv = normal_form.calculate_y_iv(alpha, beta, u)\n",
    "    #print(\"y_iv:\", y_iv.item())\n",
    "\n",
    "    if True:\n",
    "        print(\"t: t\")\n",
    "        print(\"q_est:\", q[0,0].item(), q[0,1].item())\n",
    "        print(\"th:\", th[0,0].item(), th[0,1].item())\n",
    "        print(\"th_d:\", th_d[0,0].item(), th_d[0,1].item())\n",
    "        print(\"Y:\", Y)\n",
    "        #print(\"Y_des:\", Y_des)\n",
    "        print(\"v:\", v.item())\n",
    "        print(\"u:\", u.item())\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    \n",
    "    M_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real.squeeze(0), q_d_real.squeeze(0))\n",
    "    G_q_real = dynamics.add_spring_force_G_q(rp, q_real, G_q_real, k_spring)\n",
    "    A_q_real = dynamics.input_matrix(rp, q_real.squeeze(0))\n",
    "\n",
    "    tau_q_real = A_q_real * u\n",
    "    q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T)- G_q_real)).T  #  - C_damp @ ((q_d_real).T) \n",
    "    q_d_real = q_d_real + q_dd_real * dt\n",
    "    q_real = q_real + q_d_real * dt\n",
    "    q_real = transforms.wrap_to_pi(q_real)\n",
    "\n",
    "    #q_real_shifted = transforms.shift_q(q_real, clockwise=model_cw)\n",
    "    th = model.encoder_vmap(q_real)#_shifted)\n",
    "    q_est = model.decoder_vmap(th, clockwise=transforms.check_clockwise(q_real.squeeze(0)))\n",
    "    q_est = transforms.wrap_to_pi(q_est)\n",
    "    th_d = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "    q_d_est = (model.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series_qsim = torch.cat((th_series_qsim, th.detach()), dim=0)\n",
    "    th_d_series_qsim = torch.cat((th_d_series_qsim, th_d.detach()), dim=0)\n",
    "\n",
    "    q_series_qsim = torch.cat((q_series_qsim, q_est.detach()), dim=0)\n",
    "    q_d_series_qsim = torch.cat((q_d_series_qsim, q_d_est.detach()), dim=0)\n",
    "\n",
    "    v_series_qsim = torch.cat((v_series_qsim, v.detach()), dim=0)\n",
    "    u_series_qsim = torch.cat((u_series_qsim, u.detach()), dim=0)\n",
    "    Y_series_qsim = torch.cat((Y_series_qsim, Y.detach().T))\n",
    "    alpha_beta_series_qsim = torch.cat((alpha_beta_series_qsim, torch.tensor([[alpha, beta]]).to(device)))\n",
    "    #print(\"\")\n",
    "\n",
    "    if torch.isnan(th[0,0]):\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim in Y-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y_series_Ysim = torch.empty((0,4)).to(device)\n",
    "v_series_Ysim = torch.empty((0,1)).to(device)\n",
    "\n",
    "Y = normal_form.calculate_Y(th_start, th_d_start, M_th_start, G_th_start, device)\n",
    "#print(Y)\n",
    "t_end = 30.\n",
    "dt = 0.01\n",
    "\n",
    "Y_A = torch.tensor([[0., 1., 0., 0.],\n",
    "                    [0., 0., 1., 0.],\n",
    "                    [0., 0., 0., 1.],\n",
    "                    [0., 0., 0., 0.]]).to(device)\n",
    "\n",
    "Y_B = torch.tensor([[0.], [0.], [0.], [1.]]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    print(\"t:\", t.item())\n",
    "    v = normal_form.calculate_v(Y, Y_des, K)\n",
    "\n",
    "    Y_series_Ysim = torch.cat((Y_series_Ysim, Y.detach().T))\n",
    "    Y_dot = Y_A @ Y + Y_B * v\n",
    "    Y = Y + Y_dot * dt\n",
    "    \n",
    "    v_series_Ysim = torch.cat((v_series_Ysim, v.detach()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_thsim = True\n",
    "show_Ysim = True\n",
    "show_diff = True\n",
    "\n",
    "if show_thsim:\n",
    "    plot_quad_vs_time(Y_series_thsim[:175], dt, \"Y_thsim\", \"Y_thsim vs time\", ylim=(1.5, 1.6))\n",
    "    plot_quad_vs_time(Y_series_thsim[:175], dt, \"Y_thsim\", \"Y_thsim vs time\", ylim=(-0.1, 0.1))\n",
    "    #plot_single_vs_time(v_series_thsim[:175], dt, \"v_thsim\", \"v_thsim vs time\", ylim=(-0.1, 0.2))\n",
    "    #plot_single_vs_time(u_series_thsim[:175], dt, \"u_thsim\", \"u_thsim vs time\", ylim=(-50, 50))\n",
    "    \n",
    "    #plot_double_vs_time(th_series_thsim[:175], dt, \"th_thsim\", \"th_thsim vs time\")#, (1.5, 1.6))\n",
    "    #plot_double_vs_time(th_d_series_thsim[:175], dt, \"th_d_thsim\", \"th_d_thsim vs time\", (-2, 2))\n",
    "    #plot_double_vs_time(th_dd_series_thsim[:175], dt, \"th_dd_thsim\", \"th_dd_thsim vs time\", (-10, 2))\n",
    "    \n",
    "    #plot_single_vs_time(alpha_beta_series_thsim[:200, 0], dt, \"alpha\", \"alpha vs time\", (-2, 10))\n",
    "    #plot_single_vs_time(alpha_beta_series_thsim[:200, 1], dt, \"beta\", \"beta vs time\", (0.07, 0.14))\n",
    "\n",
    "\n",
    "\n",
    "if show_Ysim:\n",
    "    plot_quad_vs_time(Y_series_Ysim[:175], dt, \"Y_Ysim\", \"Y_Ysim vs time\", ylim=(1.5, 1.6))\n",
    "    plot_quad_vs_time(Y_series_Ysim[:175], dt, \"Y_Ysim\", \"Y_Ysim vs time\", ylim=(-0.1, 0.1))\n",
    "    plot_single_vs_time(v_series_Ysim[:175], dt, \"v_Ysim\", \"v_Ysim vs time\", ylim=(-0.1, 0.2))\n",
    "    pass\n",
    "\n",
    "if show_diff:\n",
    "    plot_quad_vs_time(Y_series_thsim[:175] - Y_series_Ysim[:175], dt, \"Y_diff\", \"Y_diff vs time\", ylim=(-0.002, 0.002))\n",
    "    plot_single_vs_time(v_series_thsim[:175] - v_series_Ysim[:175], dt, \"v_diff\", \"v_diff vs time\")#, ylim=(-0.1, 0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Y as a function of $\\theta_0$, with $\\theta_1 = \\bar{\\theta}_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_th_min, plot_th_max = 1, 9\n",
    "th0_range = torch.linspace(plot_th_min, plot_th_max, 200).unsqueeze(1).to(device)\n",
    "th1_range = (torch.ones(th0_range.size(0)).to(device) * th_des[0, 1]).unsqueeze(1)\n",
    "th_des_range = torch.cat((th0_range, th1_range), dim=1)\n",
    "\n",
    "y_plot_list = torch.empty(4,0).to(device)\n",
    "G_th_1_list = torch.empty(0).to(device)\n",
    "\n",
    "for th_des_plot in th_des_range:\n",
    "    is_clockwise_des_plot = False\n",
    "    \n",
    "    th_des_plot = th_des_plot.unsqueeze(0)\n",
    "    q_hat_des_plot = model.decoder_vmap(th_des_plot, is_clockwise_des_plot)\n",
    "    q_d_hat_des_plot = (model.jacobian_dec(th_des_plot, clockwise=is_clockwise_des_plot) @ th_d_des.T).T\n",
    "\n",
    "    J_h_inv_des = model.jacobian_dec(th_des_plot, is_clockwise_des_plot).squeeze(0)\n",
    "    J_h_inv_trans_des = torch.transpose(J_h_inv_des, 0, 1)\n",
    "\n",
    "    M_q_des, C_q_des, G_q_des = dynamics.dynamical_matrices(rp, q_hat_des_plot.squeeze(0), q_d_hat_des_plot.squeeze(0))\n",
    "    G_q_des = dynamics.add_spring_force_G_q(rp, q_hat_des_plot, G_q_des, k_spring)\n",
    "    G_th_des = J_h_inv_trans_des @ G_q_des\n",
    "    #_, _, G_th_des = transforms.transform_dynamical_from_inverse(M_q_des, C_q_des, G_q_des, th_des_plot, th_d_des, J_h_inv_des, J_h_inv_trans_des)\n",
    "    M_th_des = torch.tensor([[rp[\"m1\"], 0.], [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "    M_th_des = M_th_des * th_des_plot/th_des_plot\t\n",
    "    \n",
    "    \n",
    "    Y_des = normal_form.calculate_Y(th_des_plot, th_d_des, M_th_des, G_th_des, device)\n",
    "    y_plot_list = torch.cat((y_plot_list, Y_des), dim = -1)\n",
    "    G_th_1_list = torch.cat((G_th_1_list, G_th_des[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the resulting Y as a function of $\\theta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sympy import symbols, Eq, solve\n",
    "\n",
    "# Circle parameters\n",
    "r = rp[\"l0\"] + rp[\"l1\"]\n",
    "\n",
    "# Points on the line\n",
    "x1, y1 = xy_des_real[0].item(), xy_des_real[1].item()# 1.9219, -2.5157\n",
    "x2, y2 = rp[\"xa\"], rp[\"ya\"]\n",
    "\n",
    "# Line direction vector\n",
    "dx = x2 - x1\n",
    "dy = y2 - y1\n",
    "\n",
    "# Parametric line: x = x1 + t*dx, y = y1 + t*dy\n",
    "t = symbols('t')\n",
    "x = x1 + t * dx\n",
    "y = y1 + t * dy\n",
    "\n",
    "# Equation of the circle: x^2 + y^2 = r^2\n",
    "circle_eq = Eq(x**2 + y**2, r**2)\n",
    "\n",
    "# Solve for t\n",
    "solutions = solve(circle_eq, t)\n",
    "\n",
    "# Find the coordinates of the intersection points\n",
    "intersection_points = [(x1 + float(sol) * dx, y1 + float(sol) * dy) for sol in solutions]\n",
    "\n",
    "# Calculate angle of the line with respect to horizontal in radians\n",
    "angle_radians = math.atan2(dy, dx)\n",
    "\n",
    "# Compute distances from point A to each intersection point\n",
    "distances = [math.hypot(x2 - px, y2 - py) for px, py in intersection_points]\n",
    "\n",
    "for i, distance in enumerate(distances):\n",
    "    distances[i] = round(distance, 4)\n",
    "\n",
    "short_distance = min(distances)\n",
    "long_distance = max(distances)\n",
    "\n",
    "rounded_points = []\n",
    "for intersection in intersection_points:\n",
    "    intx = round(intersection[0], 4)\n",
    "    inty = round(intersection[1], 4)\n",
    "    rounded_points.append((intx, inty))\n",
    "    \n",
    "\n",
    "#print(\"Intersection points th1 and circle:\", rounded_points)\n",
    "#print(\"Angle (th1) in radians:\", round(angle_radians, 4))\n",
    "#print(\"Distances between intersection points and actuator point:\\n\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3))\n",
    "plt.plot(th0_range.squeeze(0).cpu().numpy(), y_plot_list[0].cpu().numpy(), label=\"y\")\n",
    "plt.plot(th0_range.squeeze(0).cpu().numpy(), y_plot_list[1].cpu().numpy(), label=\"y'\")\n",
    "plt.plot(th0_range.squeeze(0).cpu().numpy(), y_plot_list[2].cpu().numpy(), label=\"y''\")\n",
    "plt.plot(th0_range.squeeze(0).cpu().numpy(), y_plot_list[3].cpu().numpy(), label=\"y'''\")\n",
    "plt.xlabel(\"th0\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.title(\"Y vs th0, for constant th1\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(th0_range.squeeze(0).cpu().numpy(), G_th_1_list.detach().cpu().numpy())\n",
    "plt.hlines(0, plot_th_min, plot_th_max, colors=\"k\", linestyles=\"--\")\n",
    "vline_min = torch.min(torch.min((y_plot_list[i]), torch.tensor(-2))).cpu().numpy()\n",
    "vline_max = torch.max(torch.max((y_plot_list[i]), torch.tensor(2))).cpu().numpy()\n",
    "plt.vlines(0, vline_min, vline_max, colors=\"k\", linestyles=\"--\")\n",
    "plt.vlines(short_distance, vline_min, vline_max, colors=\"r\", linestyles=\"--\")\n",
    "plt.vlines(long_distance, vline_min, vline_max, colors=\"r\", linestyles=\"--\")\n",
    "\n",
    "plt.title(\"G1 vs th0, for constant th1\")\n",
    "plt.xlim(0, 10)    \n",
    "plt.ylim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate $\\alpha$, $\\beta$ for varying $\\{\\theta_0, \\theta_1, \\dot{\\theta}_0, \\dot{\\theta}_1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_th_0_min, plot_th_0_max = 4, 6\n",
    "plot_th_1_min, plot_th_1_max = 1, 3\n",
    "\n",
    "plot_th_d_0_min, plot_th_d_0_max = -0.03, 0.03\n",
    "plot_th_d_1_min, plot_th_d_1_max = -4, -2\n",
    "\n",
    "th_0_range = torch.linspace(plot_th_0_min, plot_th_0_max, 5).unsqueeze(1).to(device)\n",
    "th_1_range = torch.linspace(plot_th_1_min, plot_th_1_max, 5).unsqueeze(1).to(device)\n",
    "#th_plot_range = torch.cat((th_0_range, th_1_range), dim=1)\n",
    "\n",
    "th_d_0_range = torch.linspace(plot_th_d_0_min, plot_th_d_0_max, 5).unsqueeze(1).to(device)\n",
    "th_d_1_range = torch.linspace(plot_th_d_1_min, plot_th_d_1_max, 2).unsqueeze(1).to(device)\n",
    "#th_d_plot_range = torch.cat((th_d_0_range, th_d_1_range), dim=1)\n",
    "\n",
    "alphas = torch.ones(len(th_d_0_range), len(th_d_1_range),\n",
    "                     len(th_0_range),   len(th_1_range),\n",
    "                     device='cpu')  # move final values to CPU for plotting\n",
    "\n",
    "print(alphas.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, th_0 in enumerate(th_d_0_range):\n",
    "    for j, th_1 in enumerate(th_d_1_range):\n",
    "        for k, th_d_0 in enumerate(th_0_range):\n",
    "            for l, th_d_1 in enumerate(th_1_range):\n",
    "                is_clockwise_plot = False\n",
    "                th_plot = torch.cat((th_0, th_1), dim=0).unsqueeze(0).requires_grad_()\n",
    "                th_d_plot = torch.cat((th_d_0, th_d_1), dim=0).unsqueeze(0).requires_grad_()\n",
    "\n",
    "                q_hat_plot = model.decoder_vmap(th_plot, is_clockwise_plot)\n",
    "                q_d_hat_plot = (model.jacobian_dec(th_plot, clockwise=is_clockwise_plot) @ th_d_plot.T).T\n",
    "\n",
    "                J_h_inv_plot = model.jacobian_dec(th_plot, is_clockwise_plot).squeeze(0)\n",
    "                J_h_inv_trans_plot = torch.transpose(J_h_inv_plot, 0, 1)\n",
    "\n",
    "                M_q_plot, C_q_plot, G_q_plot = dynamics.dynamical_matrices(rp, q_hat_plot.squeeze(0), q_d_hat_plot.squeeze(0))\n",
    "                A_q_plot = dynamics.input_matrix(rp, q_hat_plot.squeeze(0))\n",
    "                G_q_plot = dynamics.add_spring_force_G_q(rp, q_hat_plot, G_q_plot, k_spring)\n",
    "                G_th_plot = J_h_inv_trans_plot @ G_q_plot\n",
    "                #_, _, G_th_des = transforms.transform_dynamical_from_inverse(M_q_des, C_q_des, G_q_des, th_des_plot, th_d_des, J_h_inv_des, J_h_inv_trans_des)\n",
    "                M_th_plot = torch.tensor([[rp[\"m1\"], 0.], [0., rp[\"m1\"]]]).to(device).requires_grad_(True)\n",
    "                M_th_plot = M_th_plot * th_plot/th_plot   \n",
    "                A_th_plot = transforms.transform_input_matrix_from_inverse_trans(A_q_plot, J_h_inv_trans_plot)\n",
    "\n",
    "                Y_plot = normal_form.calculate_Y(th_plot, th_d_plot, M_th_plot, G_th_plot, device)\n",
    "                #alpha_plot, beta_plot = normal_form.calculate_alpha_beta(th_plot, th_d_plot, M_th_plot, G_th_plot, A_th_plot, Y_plot)   \n",
    "                alpha, _ = normal_form.calculate_alpha_beta(th_plot, th_d_plot, M_th_plot, G_th_plot, A_th_plot, Y_plot)   \n",
    "                alphas[i, j, k, l] = alpha.item()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "th0_vals = th_0_range.squeeze().cpu()   # shape (3,)\n",
    "th1_vals = th_1_range.squeeze().cpu()   # shape (3,)\n",
    "\n",
    "T0, T1 = torch.meshgrid(th0_vals, th1_vals, indexing='ij')\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(th_d_0_range),\n",
    "    ncols=len(th_d_1_range),\n",
    "    figsize=(12, 12),\n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "for i, thd0 in enumerate(th_d_0_range.cpu().numpy()):\n",
    "    for j, thd1 in enumerate(th_d_1_range.cpu().numpy()):\n",
    "        ax = axes[i, j]\n",
    "        A_flat = alphas[i, j].reshape(-1)\n",
    "        sc = ax.scatter(\n",
    "            T0.reshape(-1),\n",
    "            T1.reshape(-1),\n",
    "            c=A_flat,\n",
    "            s=100,\n",
    "            cmap='viridis'\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(sc, ax=ax)\n",
    "\n",
    "        ax.set_title(f\"th'0={thd0.item():.2f}, th'1={thd1.item():.2f}\")\n",
    "        if i == len(th_d_0_range) - 1:\n",
    "            ax.set_xlabel(\"th0\")\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"th1\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
