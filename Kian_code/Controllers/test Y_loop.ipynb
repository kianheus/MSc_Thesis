{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/kian/Documents/Thesis/ICS_fork/ics-pa-sv/Kian_code', '/home/kian/anaconda3/envs/thesis2/lib/python311.zip', '/home/kian/anaconda3/envs/thesis2/lib/python3.11', '/home/kian/anaconda3/envs/thesis2/lib/python3.11/lib-dynload', '', '/home/kian/anaconda3/envs/thesis2/lib/python3.11/site-packages', '/home/kian/anaconda3/envs/thesis2/lib/python3.11/site-packages/setuptools/_vendor', '/tmp/tmp_r29kzko']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "print(sys.path)\n",
    "\n",
    "import Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Double_Pendulum.transforms as transforms\n",
    "\n",
    "import Double_Pendulum.normal_form as normal_form\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "rp[\"m1\"] = 0.\n",
    "model = autoencoders.Analytic_transformer(rp)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_start = torch.tensor([4., -1.9]).requires_grad_().to(device)\n",
    "q_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\n",
    "xy_des_real = torch.tensor([2.1, -2.]).requires_grad_().to(device)\n",
    "q_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_spring = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8498,  0.2159]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "q_start = transforms.inverse_kinematics(xy_start, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "is_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "q_des = transforms.inverse_kinematics(xy_des_real, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "th_start = model.encoder_vmap(q_start)\n",
    "th_d_start = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "th_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Obtain accelerations in thetas. Do I care?\n",
    "\n",
    "is_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "th_des = model.encoder_vmap(q_des)\n",
    "th_d_des = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "\n",
    "q_des_hat = model.decoder_vmap(th_des, is_clockwise_des)\n",
    "q_d_des_hat = (model.jacobian_dec(th_des, clockwise=is_clockwise_des) @ th_d_des.T).T\n",
    "xy_des_est, _ = transforms.forward_kinematics(rp, q_des_hat[0])\n",
    "\n",
    "print(q_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_des_u:\n",
      " tensor([[ 1.5851],\n",
      "        [ 0.0000],\n",
      "        [-0.0218],\n",
      "        [ 0.0000]], device='cuda:0')\n",
      "Y_des:\n",
      " tensor([[1.5851],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "J_h_inv_des = model.jacobian_dec(th_des, is_clockwise_des).squeeze(0)\n",
    "J_h_inv_trans_des = torch.transpose(J_h_inv_des, 0, 1)\n",
    "\n",
    "M_q_des, C_q_des, G_q_des = dynamics.dynamical_matrices(rp, q_des_hat.squeeze(0), q_d_des_hat.squeeze(0))\n",
    "G_q_des = dynamics.add_spring_force_G_q(rp, q_des_hat, G_q_des, k_spring)\n",
    "M_th_des, C_th_des, G_th_des = transforms.transform_dynamical_from_inverse(M_q_des, C_q_des, G_q_des, th_des, th_d_des, J_h_inv_des, J_h_inv_trans_des)\n",
    "\n",
    "K = torch.tensor([[10., 100., 100., 100.]]).to(device)\n",
    "Y_des_u = normal_form.calculate_Y(th_des, th_d_des, M_th_des, C_th_des, G_th_des, device)\n",
    "Y_des = torch.tensor([[Y_des_u[0,0]], [0], [0], [0]]).to(device)\n",
    "print(\"Y_des_u:\\n\", Y_des_u)\n",
    "print(\"Y_des:\\n\", Y_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: [0.0/5.0]\n",
      "q: tensor([[-0.8498,  0.2159]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "q_d: tensor([[0., 0.]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "q_hat: tensor([[-0.8498,  0.2159]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[0., 0.]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.1840, 1.8529]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[0., 0.]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1769, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(202.9712, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0055, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3357, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-58.9920, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(-0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(-0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([79.6916], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3998.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1307.0471], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9085], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8529],\n",
      "        [  0.0000],\n",
      "        [-19.6979],\n",
      "        [  0.0000]], device='cuda:0')\n",
      "v: tensor([[1967.1119]], device='cuda:0')\n",
      "u: tensor([[-726.5036]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.01/5.0]\n",
      "q: tensor([[-0.8505,  0.2280]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0668,  1.2104]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8505,  0.2280]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0668,  1.2104]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.1607, 1.8529]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-2.3294, -0.0079]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[ 0.0000e+00, -1.1921e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(-1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1754, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(202.3148, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0057, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3364, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-58.7828, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-3.5585e-21, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([5.5751e-08], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(1.4925e-14, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(-1.8584e-08, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-19.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-1.6066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(-7.0124e-11, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-2.6389e-17, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.0001], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(-1.0519e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(1.1068e-10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-4.5931e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.1716], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3971.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1297.8564], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9084], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[ 1.8529e+00],\n",
      "        [-7.9413e-03],\n",
      "        [-1.9630e+01],\n",
      "        [ 6.8836e+00]], device='cuda:0')\n",
      "v: tensor([[1272.8064]], device='cuda:0')\n",
      "u: tensor([[27.5767]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.02/5.0]\n",
      "q: tensor([[-0.8511,  0.2392]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0624,  1.1135]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8511,  0.2392]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0624,  1.1135]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.1393, 1.8528]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-2.1430, -0.0112]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-2.9802e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-2.3842e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1728, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(201.7132, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0059, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3371, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-58.5830, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-17.5142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-2.2598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-1.8779e-15, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.3087], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3945.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1289.4695], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9081], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[ 1.8528e+00],\n",
      "        [-1.1203e-02],\n",
      "        [-1.9566e+01],\n",
      "        [ 6.5913e+00]], device='cuda:0')\n",
      "v: tensor([[1295.8821]], device='cuda:0')\n",
      "u: tensor([[-7.0616]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.03/5.0]\n",
      "q: tensor([[-0.8517,  0.2500]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0622,  1.0775]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8517,  0.2500]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0622,  1.0775]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.1186, 1.8526]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-2.0722, -0.0149]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[2.9802e-08, 0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-2.3842e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1692, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(201.1337, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0060, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3385, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-58.3807, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-9.8647e-14, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-16.9281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-2.9975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([7.7446e-10], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-3.8724e-10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-2.5815e-10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.4725], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3921.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1281.1947], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9077], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[ 1.8526e+00],\n",
      "        [-1.4903e-02],\n",
      "        [-1.9500e+01],\n",
      "        [ 6.6419e+00]], device='cuda:0')\n",
      "v: tensor([[1284.6713]], device='cuda:0')\n",
      "u: tensor([[-3.8301]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.04/5.0]\n",
      "q: tensor([[-0.8523,  0.2603]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0628,  1.0367]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8523,  0.2603]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0628,  1.0367]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0987, 1.8525]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.9906, -0.0186]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[2.9802e-08, 0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1645, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(200.5798, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0062, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3400, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-58.1771, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(1.9207e-13, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-16.2525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-3.7327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([-1.2035e-09], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(6.0176e-10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(4.0117e-10, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.6067], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3897.2065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1273.1072], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9072], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[ 1.8525e+00],\n",
      "        [-1.8610e-02],\n",
      "        [-1.9435e+01],\n",
      "        [ 6.6617e+00]], device='cuda:0')\n",
      "v: tensor([[1276.4976]], device='cuda:0')\n",
      "u: tensor([[-3.7373]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.05/5.0]\n",
      "q: tensor([[-0.8530,  0.2703]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0643,  0.9965]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8530,  0.2703]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0643,  0.9965]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0796, 1.8523]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.9088, -0.0224]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[ 0.0000e+00, -1.1921e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(-1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1587, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(200.0512, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0064, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3418, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-57.9737, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-7.9360e-20, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([1.5484e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(-5.1612e-08, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-15.5732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-4.4718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(-1.9739e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-2.0630e-16, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.0001], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(-2.9608e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-7.4405e-15, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-4.4704e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.7158], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3873.6038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1265.2026], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9065], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8523],\n",
      "        [ -0.0224],\n",
      "        [-19.3690],\n",
      "        [  6.6817]], device='cuda:0')\n",
      "v: tensor([[1268.2933]], device='cuda:0')\n",
      "u: tensor([[-3.4094]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.06/5.0]\n",
      "q: tensor([[-0.8536,  0.2799]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0666,  0.9565]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8536,  0.2799]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0666,  0.9565]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0613, 1.8520]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.8259, -0.0261]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-5.9605e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0.0000e+00, 1.1921e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1518, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(199.5479, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0066, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3440, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-57.7698, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-1.2675e-19, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-1.8037e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(1.0632e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(6.0124e-08, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-14.8841, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-5.2139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(2.3072e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-2.8092e-16, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([-0.0001], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(3.4609e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(2.3565e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(4.4398e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.7986], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3850.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1257.4821], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9058], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8520],\n",
      "        [ -0.0261],\n",
      "        [-19.3028],\n",
      "        [  6.6993]], device='cuda:0')\n",
      "v: tensor([[1260.2931]], device='cuda:0')\n",
      "u: tensor([[-3.1035]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.07/5.0]\n",
      "q: tensor([[-0.8543,  0.2890]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0697,  0.9166]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8543,  0.2890]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0697,  0.9166]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0439, 1.8517]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.7419, -0.0299]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(1.7881e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1438, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(199.0705, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0067, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3465, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-57.5654, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-2.3979e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-14.1859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-5.9589, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([9.2462e-09], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-4.6231e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-3.0821e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.8543], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3827.9924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1249.9508], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9049], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8517],\n",
      "        [ -0.0299],\n",
      "        [-19.2365],\n",
      "        [  6.7149]], device='cuda:0')\n",
      "v: tensor([[1252.4836]], device='cuda:0')\n",
      "u: tensor([[-2.7991]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.08/5.0]\n",
      "q: tensor([[-0.8551,  0.2978]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0737,  0.8768]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8551,  0.2978]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0737,  0.8768]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0273, 1.8514]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.6570, -0.0338]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-2.9802e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0.0000e+00, 1.1921e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-1.7881e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1347, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(198.6196, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0069, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3492, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-57.3604, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-2.7351e-19, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-2.3148e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(3.4416e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(7.7160e-08, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-13.4790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-6.7063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(2.9815e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-4.6589e-16, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([-0.0001], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(4.4723e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(5.8620e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(4.3785e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.8823], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3806.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1242.6112], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9039], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8514],\n",
      "        [ -0.0338],\n",
      "        [-19.1699],\n",
      "        [  6.7284]], device='cuda:0')\n",
      "v: tensor([[1244.8621]], device='cuda:0')\n",
      "u: tensor([[-2.4903]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.09/5.0]\n",
      "q: tensor([[-0.8559,  0.3062]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0784,  0.8369]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8559,  0.3062]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0784,  0.8369]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[7.0116, 1.8510]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.5710, -0.0376]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1244, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(198.1952, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0070, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3524, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-57.1554, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(1.5866e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-12.7635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-7.4559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([-4.8342e-09], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(2.4172e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(1.6114e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.8817], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3784.5667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1235.4644], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9027], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8510],\n",
      "        [ -0.0376],\n",
      "        [-19.1032],\n",
      "        [  6.7398]], device='cuda:0')\n",
      "v: tensor([[1237.4403]], device='cuda:0')\n",
      "u: tensor([[-2.1889]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.1/5.0]\n",
      "q: tensor([[-0.8567,  0.3141]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0838,  0.7971]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8567,  0.3141]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0838,  0.7971]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9968, 1.8506]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.4840, -0.0415]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-2.9802e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0.0000e+00, 2.3842e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(2.3842e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(-1.7881e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(3.5763e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1131, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(197.7974, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0072, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3559, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-56.9499, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-2.0306e-18, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-5.6498e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(6.3876e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(1.8833e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-12.0399, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-8.2075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(7.3282e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-2.7948e-15, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([-0.0003], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(1.0992e-09, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(8.7918e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(8.6338e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.8518], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3763.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1228.5126], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9015], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8506],\n",
      "        [ -0.0415],\n",
      "        [-19.0363],\n",
      "        [  6.7491]], device='cuda:0')\n",
      "v: tensor([[1230.2146]], device='cuda:0')\n",
      "u: tensor([[-1.8881]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.11/5.0]\n",
      "q: tensor([[-0.8576,  0.3217]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0899,  0.7572]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8576,  0.3217]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0899,  0.7572]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9828, 1.8502]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.3960, -0.0454]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[2.9802e-08, 0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.1005, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(197.4267, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0073, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3595, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-56.7451, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-11.3084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-8.9606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(1.2646e-13, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.7919], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3743.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1221.7562], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.9001], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8502],\n",
      "        [ -0.0454],\n",
      "        [-18.9693],\n",
      "        [  6.7563]], device='cuda:0')\n",
      "v: tensor([[1223.1836]], device='cuda:0')\n",
      "u: tensor([[-1.5859]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.12/5.0]\n",
      "q: tensor([[-0.8586,  0.3289]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.0966,  0.7173]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8586,  0.3289]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.0966,  0.7173]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9698, 1.8497]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.3070, -0.0493]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-2.9802e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[ 0.0000e+00, -1.1921e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(-1.1921e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-1.7881e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.0869, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(197.0835, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0074, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3637, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-56.5397, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-8.5106e-19, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([3.3322e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-3.5696e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(-1.1107e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-10.5693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-9.7149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(-4.3528e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-9.7909e-16, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.0001], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(-6.5292e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-4.1069e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-4.2555e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.7017], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3723.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1215.2010], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.8985], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8497],\n",
      "        [ -0.0493],\n",
      "        [-18.9021],\n",
      "        [  6.7614]], device='cuda:0')\n",
      "v: tensor([[1216.3553]], device='cuda:0')\n",
      "u: tensor([[-1.2846]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.13/5.0]\n",
      "q: tensor([[-0.8596,  0.3356]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.1040,  0.6772]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8596,  0.3356]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.1040,  0.6772]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9576, 1.8492]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.2169, -0.0532]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3.0000, 0.0000],\n",
      "        [0.0000, 3.0000]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[ 0.0000e+00, -2.3842e-07]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(-2.3842e-07, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(-5.9605e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.0721, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(196.7679, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0076, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3682, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-56.3331, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-4.2822e-18, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([7.1685e-07], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-4.4902e-12, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(-2.3895e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-9.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-10.4703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(-9.3975e-10, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(-4.5473e-15, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.0003], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(-1.4096e-09, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(-4.7683e-09, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(-8.4498e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.5802], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3704.4338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1208.8480], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.8969], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8492],\n",
      "        [ -0.0532],\n",
      "        [-18.8349],\n",
      "        [  6.7644]], device='cuda:0')\n",
      "v: tensor([[1209.7306]], device='cuda:0')\n",
      "u: tensor([[-0.9840]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.14/5.0]\n",
      "q: tensor([[-0.8607,  0.3420]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.1120,  0.6369]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8607,  0.3420]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.1120,  0.6369]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9463, 1.8486]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.1258, -0.0571]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "M_th: tensor([[3., 0.],\n",
      "        [0., 3.]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Hello (tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>),)\n",
      "C_th: tensor([[0., 0.],\n",
      "        [0., 0.]], device='cuda:0', requires_grad=True)\n",
      "dM0dthfull: tensor([[-2.9802e-08,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM1dthfull: tensor([[0., 0.]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dM0dth0: tensor(-2.9802e-08, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dM1dth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddM1ddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dddM1dddth1: tensor(0., device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth0: tensor(8.0562, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "dG1dth1: tensor(196.4802, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth0: tensor(-0.0077, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1dth0dth1: tensor(28.3729, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "ddG1ddth1: tensor(-56.1281, device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "BIG ALPHA\n",
      "AA tensor(0.1111, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "BB tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "CC tensor([-0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "DD tensor(0.3333, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "EE tensor(-0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "FF tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "GG tensor(-9.0698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "HH tensor(-11.2263, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "dAAdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dBBdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dCCdt tensor([0.], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dDDdt tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "dEEdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dFFdt tensor(0., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dGGdt tensor([80.4267], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "dHHdt tensor(-3685.8369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "alpha: tensor([1202.6985], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "beta: tensor([-0.8951], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Y: tensor([[  1.8486],\n",
      "        [ -0.0571],\n",
      "        [-18.7677],\n",
      "        [  6.7654]], device='cuda:0')\n",
      "v: tensor([[1203.3096]], device='cuda:0')\n",
      "u: tensor([[-0.6827]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "Time: [0.15/5.0]\n",
      "q: tensor([[-0.8619,  0.3480]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "q_d: tensor([[-0.1205,  0.5965]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "q_hat: tensor([[-0.8619,  0.3480]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "q_d_hat: tensor([[-0.1205,  0.5965]], device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "th: tensor([[6.9360, 1.8480]], device='cuda:0', grad_fn=<StackBackward0>)\n",
      "th_d: tensor([[-1.0337, -0.0611]], device='cuda:0', grad_fn=<PermuteBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m A_q_est \u001b[38;5;241m=\u001b[39m dynamics\u001b[38;5;241m.\u001b[39minput_matrix(rp, q_hat\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m M_th, C_th, G_th \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_dynamical_from_inverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM_q_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_q_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_q_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_h_inv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_h_inv_trans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m M_th \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[rp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m0.\u001b[39m], [\u001b[38;5;241m0.\u001b[39m, rp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;241m*\u001b[39mth[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]]])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m M_th \u001b[38;5;241m=\u001b[39m M_th \u001b[38;5;241m*\u001b[39m th \u001b[38;5;241m/\u001b[39mth\n",
      "File \u001b[0;32m~/Documents/Thesis/ICS_fork/ics-pa-sv/Kian_code/Double_Pendulum/transforms.py:39\u001b[0m, in \u001b[0;36mtransform_dynamical_from_inverse\u001b[0;34m(M_q, C_q, G_q, theta, theta_d, J_h_inv, J_h_inv_trans)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(C_th\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     38\u001b[0m     M_th_dot_ijk \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(M_th[i,j], theta, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,k]\n\u001b[0;32m---> 39\u001b[0m     M_th_dot_ikj \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM_th\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,j]\n\u001b[1;32m     40\u001b[0m     M_th_dot_jki \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(M_th[j,k], theta, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,i]\n\u001b[1;32m     41\u001b[0m     C_th[i, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (M_th_dot_ijk \u001b[38;5;241m+\u001b[39m M_th_dot_ikj \u001b[38;5;241m-\u001b[39m M_th_dot_jki) \u001b[38;5;241m*\u001b[39m theta_d[\u001b[38;5;241m0\u001b[39m, k]\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis2/lib/python3.11/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    493\u001b[0m         grad_outputs_\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    509\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis2/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "th_series, th_d_series, th_dd_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_est_series, q_d_est_series, q_dd_est_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_real_series, q_d_real_series, q_dd_real_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "Y_series = torch.empty((0,4)).to(device)\n",
    "u_series = torch.empty((0,1)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 5\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "th = th_start\n",
    "th_d = th_d_start\n",
    "th_dd = th_dd_start\n",
    "\n",
    "q_est = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "q_d_est = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "q_dd_est = torch.zeros((1,2))\n",
    "\n",
    "q_real, q_d_real, q_dd_real = q_start, q_d_start, q_dd_start\n",
    "\n",
    "is_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    t_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "    print(t_string)\n",
    "\n",
    "    q = q_real\n",
    "    q_d = q_d_real\n",
    "\n",
    "    th = model.encoder_vmap(q)\n",
    "    th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "    q_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "    q_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "    \n",
    "    \"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\n",
    "    is_clockwise = transforms.check_clockwise(q_hat.squeeze(0))\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "    G_q_est = dynamics.add_spring_force_G_q(rp, q_hat, G_q_est, k_spring)\n",
    "    A_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\n",
    "    \"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "    M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "    M_th = torch.tensor([[rp[\"m2\"], 0.], [0., rp[\"m2\"]]]).to(device).requires_grad_(True)\n",
    "    M_th = M_th * th/th\n",
    "    C_th = torch.tensor([[0, 0.], [0., 0.]]).to(device).requires_grad_(True)\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans, device)\n",
    "\n",
    "    Y = normal_form.calculate_Y(th, th_d, M_th, C_th, G_th, device)\n",
    "    alpha, beta = normal_form.calculate_alpha_beta(th, th_d, M_th, C_th, G_th, A_th, Y)\n",
    "\n",
    "    print(\"alpha:\", alpha)\n",
    "    print(\"beta:\", beta)\n",
    "    v = normal_form.calculate_v(Y, Y_des, K)\n",
    "    u = normal_form.calculate_u(alpha, beta, v)\n",
    "    print(\"Y:\", Y)\n",
    "    print(\"v:\", v)\n",
    "    print(\"u:\", u)\n",
    "\n",
    "    \"\"\" Recalculate \"real system\" based on modified matrices in theta-space. \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    M_q_real, C_q_real, G_q_real = dynamics.dynamical_matrices(rp, q_real.squeeze(0), q_d_real.squeeze(0))\n",
    "    G_q_real = dynamics.add_spring_force_G_q(rp, q_real, G_q_real, k_spring)\n",
    "    A_q_real = dynamics.input_matrix(rp, q_real.squeeze(0))\n",
    "\n",
    "    tau_q_real = A_q_real * u\n",
    "    q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T)- G_q_real)).T  #  - C_damp @ ((q_d_real).T) \n",
    "    q_d_real = q_d_real + q_dd_real * dt\n",
    "    q_real = q_real + q_d_real * dt\n",
    "    q_real = transforms.wrap_to_pi(q_real)\n",
    "    \n",
    "\n",
    "    q_real_shifted = transforms.shift_q(q_real, clockwise=model_cw)\n",
    "    th = model.encoder_vmap(q_real_shifted)\n",
    "    q_est = model.decoder_vmap(th, clockwise=transforms.check_clockwise(q_real.squeeze(0)))\n",
    "    q_est = transforms.wrap_to_pi(q_est)\n",
    "    th_d = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "    q_d_est = (model.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "    q_dd_est = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Implement with Jacobian derivative\n",
    "\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series = torch.cat((th_series, th.detach()), dim=0)\n",
    "    th_d_series = torch.cat((th_d_series, th_d.detach()), dim=0)\n",
    "    th_dd_series = torch.cat((th_dd_series, th_dd.detach()), dim=0)\n",
    "    \n",
    "    q_real_series = torch.cat((q_real_series, q_real.detach()), dim=0)\n",
    "    q_d_real_series = torch.cat((q_d_real_series, q_d_real.detach()), dim=0)\n",
    "    q_dd_real_series = torch.cat((q_dd_real_series, q_dd_real.detach()), dim=0)\n",
    "\n",
    "    q_est_series = torch.cat((q_est_series, q_est.detach()), dim=0)\n",
    "    q_d_est_series = torch.cat((q_d_est_series, q_d_est.detach()), dim=0)\n",
    "    q_dd_est_series = torch.cat((q_dd_est_series, q_dd_est.detach()), dim=0) \n",
    "\n",
    "    u_series = torch.cat((u_series, u.detach()), dim=0)\n",
    "    Y_series = torch.cat((Y_series, Y.detach().T))\n",
    "    print(\"\")\n",
    "\n",
    "    if torch.isnan(q[0,0]):\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
