{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "\n",
    "import Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Double_Pendulum.transforms as transforms\n",
    "\n",
    "import Double_Pendulum.normal_form as normal_form\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "rp = robot_parameters.LUMPED_PARAMETERS\n",
    "rp[\"m1\"] = 0.\n",
    "model = autoencoders.Analytic_transformer(rp)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cw = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_vs_time(single_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (single_list.shape[0] - 1) * dt, single_list.shape[0]).numpy()\n",
    "    single_np = single_list.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, single_np, label=ylabel)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_double_vs_time(double_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (double_list.shape[0] - 1) * dt, double_list.shape[0]).numpy()\n",
    "    double_np = double_list.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, double_np[:, 0], label=ylabel+\"0\")\n",
    "    plt.plot(time, double_np[:, 1], label=ylabel+\"1\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_quad_vs_time(quad_list, dt, ylabel, title, ylim = None, log = False):\n",
    "    time = torch.linspace(0, (quad_list.shape[0] - 1) * dt, quad_list.shape[0]).numpy()\n",
    "    quad_np = quad_list.cpu().numpy()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.plot(time, quad_np[:, 0], label=\"Y\")\n",
    "    plt.plot(time, quad_np[:, 1], label=\"Y'\")\n",
    "    plt.plot(time, quad_np[:, 2], label=\"Y''\")\n",
    "    plt.plot(time, quad_np[:, 3], label=\"Y'''\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)\n",
    "    if log:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_start = torch.tensor([4., -1.9]).requires_grad_().to(device)\n",
    "q_start = transforms.inverse_kinematics(xy_start, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "q_d_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "q_dd_start = torch.tensor([[0., 0.]]).requires_grad_().to(device)\n",
    "\n",
    "\n",
    "xy_des_real = torch.tensor([1.9262, -2.1004]).requires_grad_().to(device)\n",
    "q_des = transforms.inverse_kinematics(xy_des_real, rp, is_clockwise=model_cw).unsqueeze(0)\n",
    "q_d_des = torch.tensor([[0., 0.]]).requires_grad_().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[10., 100., 100., 100.]]).to(device)\n",
    "k_spring = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_clockwise_start = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "\n",
    "th_start = model.encoder_vmap(q_start)\n",
    "th_d_start = (model.jacobian_enc(q_start) @ q_d_start.T).T\n",
    "\n",
    "is_clockwise_des = transforms.check_clockwise(q_des.squeeze(0))\n",
    "\n",
    "th_des = model.encoder_vmap(q_des)\n",
    "th_d_des = (model.jacobian_enc(q_des) @ q_d_des.T).T\n",
    "\n",
    "#th_des = torch.tensor([[6.1008,  1.558694425]]).requires_grad_().to(device)\n",
    "#th_d_des = torch.tensor([[0.,  0.]]).requires_grad_().to(device)\n",
    "\n",
    "\n",
    "q_des_hat = model.decoder_vmap(th_des, is_clockwise_des)\n",
    "q_d_des_hat = (model.jacobian_dec(th_des, clockwise=is_clockwise_des) @ th_d_des.T).T\n",
    "xy_des_est, _ = transforms.forward_kinematics(rp, q_des_hat[0])\n",
    "\n",
    "print(\"th_start:\", th_start)\n",
    "print(\"th_d_start:\", th_d_start)\n",
    "print(\"th_des\", th_des)\n",
    "print(\"q_des_hat\", q_des_hat)\n",
    "print(\"xy_des_est\", xy_des_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_h_inv_des = model.jacobian_dec(th_des, is_clockwise_des).squeeze(0)\n",
    "J_h_inv_trans_des = torch.transpose(J_h_inv_des, 0, 1)\n",
    "\n",
    "M_q_des, C_q_des, G_q_des = dynamics.dynamical_matrices(rp, q_des_hat.squeeze(0), q_d_des_hat.squeeze(0))\n",
    "G_q_des = dynamics.add_spring_force_G_q(rp, q_des_hat, G_q_des, k_spring)\n",
    "M_th_des, C_th_des, G_th_des = transforms.transform_dynamical_from_inverse(M_q_des, C_q_des, G_q_des, th_des, th_d_des, J_h_inv_des, J_h_inv_trans_des)\n",
    "\n",
    "\n",
    "Y_des_u = normal_form.calculate_Y(th_des, th_d_des, M_th_des, G_th_des, device)\n",
    "Y_des = torch.tensor([[Y_des_u[0,0]], [0], [0], [0]]).to(device)\n",
    "print(\"Y_des_u:\\n\", Y_des_u)\n",
    "print(\"Y_des:\\n\", Y_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim in q-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "th_series_qsim, th_d_series_qsim, th_dd_series_qsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_est_series_qsim, q_d_est_series_qsim, q_dd_est_series_qsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "q_real_series_qsim, q_d_real_series_qsim, q_dd_real_series_qsim = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "Y_series_qsim = torch.empty((0,4)).to(device)\n",
    "u_series_qsim = torch.empty((0,1)).to(device)\n",
    "\n",
    "\n",
    "dt = 0.01\n",
    "t_end = 5\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "th = th_start\n",
    "th_d = th_d_start\n",
    "\n",
    "th_thsim = th_start\n",
    "th_d_thsim = th_d_start\n",
    "\n",
    "q_est = model.decoder(th_start, clockwise=is_clockwise_start)\n",
    "q_d_est = (model.jacobian_dec(th_start, clockwise=is_clockwise_start) @ th_d_start.T).T\n",
    "q_dd_est = torch.zeros((1,2))\n",
    "\n",
    "q_real, q_d_real, q_dd_real = q_start, q_d_start, q_dd_start\n",
    "\n",
    "is_clockwise = transforms.check_clockwise(q_start.squeeze(0))\n",
    "\n",
    "for t in torch.arange(0, t_end, dt):\n",
    "    t_string = \"Time: [\" + str(t.item().__round__(3)) + \"/\" + str(t_end) + \".0]\"\n",
    "    print(t_string)\n",
    "\n",
    "    q = q_real\n",
    "    q_d = q_d_real\n",
    "\n",
    "    th = model.encoder_vmap(q)\n",
    "    th_d = (model.jacobian_enc(q) @ q_d.T).T\n",
    "\n",
    "    q_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "    q_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "    \n",
    "    \"\"\" Obtain Jacobian, dynamical matrices\"\"\"\n",
    "\n",
    "    is_clockwise = transforms.check_clockwise(q_hat.squeeze(0))\n",
    "    \n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_q_est, C_q_est, G_q_est = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "    G_q_est = dynamics.add_spring_force_G_q(rp, q_hat, G_q_est, k_spring)\n",
    "    A_q_est = dynamics.input_matrix(rp, q_hat.squeeze(0))\n",
    "\n",
    "\n",
    "    \"\"\" Feed-forward simulation of the system, not on real dynamics \"\"\"\n",
    "    M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_est, C_q_est, G_q_est, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "    M_th = torch.tensor([[rp[\"m2\"], 0.], [0., rp[\"m2\"]]]).to(device).requires_grad_(True)\n",
    "    M_th = M_th * th/th\n",
    "    C_th = torch.tensor([[0, 0.], [0., 0.]]).to(device).requires_grad_(True)\n",
    "    A_th = transforms.transform_input_matrix_from_inverse_trans(A_q_est, J_h_inv_trans)\n",
    "\n",
    "    Y = normal_form.calculate_Y(th, th_d, M_th, G_th, device)\n",
    "    alpha, beta = normal_form.calculate_alpha_beta(th, th_d, M_th, G_th, A_th, Y)\n",
    "\n",
    "    #print(\"alpha:\", alpha)\n",
    "    #print(\"beta:\", beta)\n",
    "    v = normal_form.calculate_v(Y, Y_des, K)\n",
    "    u = normal_form.calculate_u(alpha, beta, v)\n",
    "    #print(\"Y:\", Y)\n",
    "    #print(\"v:\", v)\n",
    "    #print(\"u:\", u)\n",
    "\n",
    "    \"\"\" Recalculate \"real system\" based on modified matrices in theta-space. \"\"\"\n",
    "\n",
    "    J_h = model.jacobian_enc(q_hat)\n",
    "    J_h_trans = torch.transpose(J_h, 0, 1)\n",
    "\n",
    "    \"\"\" Update the real system and apply latent control input. \"\"\"\n",
    "\n",
    "    M_q_real, C_q_real, G_q_real = transforms.transform_dynamical_from_inverse(M_th, C_th, G_th, q_hat, q_d_hat, J_h, J_h_trans)\n",
    "    A_q_real = transforms.transform_input_matrix_from_inverse_trans(A_th, J_h_trans)    \n",
    "\n",
    "    tau_q_real = A_q_real * u\n",
    "    q_dd_real = (torch.pinverse(M_q_real) @ (tau_q_real - C_q_real @ ((q_d_real).T)- G_q_real)).T \n",
    "    q_d_real = q_d_real + q_dd_real * dt\n",
    "    q_real = q_real + q_d_real * dt\n",
    "    q_real = transforms.wrap_to_pi(q_real)\n",
    "    \n",
    "\n",
    "    q_real_shifted = transforms.shift_q(q_real, clockwise=model_cw)\n",
    "    th = model.encoder_vmap(q_real_shifted)\n",
    "    q_est = model.decoder_vmap(th, clockwise=transforms.check_clockwise(q_real.squeeze(0)))\n",
    "    q_est = transforms.wrap_to_pi(q_est)\n",
    "    th_d = (model.jacobian_enc(q_real) @ q_d_real.T).T\n",
    "    q_d_est = (model.jacobian_dec(th, clockwise=is_clockwise) @ th_d.T).T\n",
    "    q_dd_est = torch.tensor([[0., 0.]]).requires_grad_().to(device) #TODO: Implement with Jacobian derivative\n",
    "\n",
    "\n",
    "    \"\"\" Store data for plotting \"\"\"\n",
    "\n",
    "    th_series_qsim = torch.cat((th_series_qsim, th.detach()), dim=0)\n",
    "    th_d_series_qsim = torch.cat((th_d_series_qsim, th_d.detach()), dim=0)\n",
    "    th_dd_series_qsim = torch.cat((th_dd_series_qsim, th_dd.detach()), dim=0)\n",
    "    \n",
    "    q_real_series_qsim = torch.cat((q_real_series_qsim, q_real.detach()), dim=0)\n",
    "    q_d_real_series_qsim = torch.cat((q_d_real_series_qsim, q_d_real.detach()), dim=0)\n",
    "    q_dd_real_series_qsim = torch.cat((q_dd_real_series_qsim, q_dd_real.detach()), dim=0)\n",
    "\n",
    "    q_est_series_qsim = torch.cat((q_est_series_qsim, q_est.detach()), dim=0)\n",
    "    q_d_est_series_qsim = torch.cat((q_d_est_series_qsim, q_d_est.detach()), dim=0)\n",
    "    q_dd_est_series_qsim = torch.cat((q_dd_est_series_qsim, q_dd_est.detach()), dim=0) \n",
    "\n",
    "    u_series_qsim = torch.cat((u_series_qsim, u.detach()), dim=0)\n",
    "    Y_series_qsim = torch.cat((Y_series_qsim, Y.detach().T))\n",
    "    print(\"\")\n",
    "\n",
    "    if torch.isnan(q[0,0]):\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim in $\\theta$-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
