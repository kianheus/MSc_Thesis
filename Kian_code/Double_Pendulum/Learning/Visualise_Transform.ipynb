{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to visualise training and performance of Learn Transform.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import autoencoders\n",
    "import learning_plotters as lp\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import training_data as training_data\n",
    "\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family']   = 'serif'\n",
    "matplotlib.rcParams['font.serif']    = ['Times New Roman']\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "rp = robot_parameters.LUMPED_PARAMETERS.copy()\n",
    "rp[\"m0\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_counter = 0\n",
    "train_clockwise = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"NN_full-q\"\n",
    "#dir_name = \"NN_202505141642(half-q)\"\n",
    "\n",
    "dir_path = os.path.join(os.getcwd(), \"Models\", dir_name)\n",
    "nn_filename = \"NN\" + \"_0.pth\"\n",
    "nn_filepath = os.path.join(dir_path, nn_filename)\n",
    "\n",
    "model_path = nn_filepath\n",
    "model = autoencoders.Autoencoder_double(rp).to(device)  # Initialize model architecture\n",
    "model.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))  # Load weights\n",
    "\n",
    "model_ana = autoencoders.Analytic_transformer(rp)\n",
    "\n",
    "models = [model_ana, model]\n",
    "model_names = [\"Analytic\", \"Learned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(load_loss_path):\n",
    "\tlosses_dict = torch.load(load_loss_path, map_location = \"cpu\", weights_only=True)\n",
    "\treturn losses_dict[\"train\"], losses_dict[\"val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize loss plot, single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_losses_path = \"Models/\" + dir_name + \"/losses.pt\"\n",
    "train_loss, val_loss = load_loss(single_losses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.plot_loss(train_loss, val_loss, file_counter, log = True, save_folder = dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_points(q0_split, clockwise = False, q1_margin = 0.):\n",
    "\n",
    "\t\"\"\"\n",
    "\tReturns a set of [q0, q1] points based on \"q0_split\" limits on q0 and q1.\n",
    "\tThe limits on q1 depend on whether a clockwise or counterclockwise dataset is selected.\n",
    "\t\"\"\"   \n",
    "\n",
    "\t# Retrieve training points\n",
    "\tpoints = training_data.points.to(device)\n",
    "\t\n",
    "\t# Mask to retrieve only the counterclockwise points\n",
    "\twidth_mask = (points[:,0] >= q0_split[0]) & (points[:,0] <= q0_split[1])\n",
    "\tccw_mask = ((points[:,1] >= points[:,0] + q1_margin) & \n",
    "\t\t\t\t  (points[:,1] <= points[:,0] + torch.pi - q1_margin))\n",
    "\t\n",
    "\t# Mask to retrieve only the clockwise points\n",
    "\tcw_mask = ((points[:,1] >= points[:,0] - torch.pi + q1_margin) & (points[:,1] <= points[:,0] - q1_margin))\n",
    "\n",
    "\tif clockwise:\n",
    "\t\tfinal_mask = width_mask & cw_mask\n",
    "\telse:\n",
    "\t\tfinal_mask = width_mask & ccw_mask\n",
    "\t\n",
    "\tpoints = points[final_mask]\n",
    "\tpoints = points[0:6000]\n",
    "\n",
    "\tif points.size(0) < 6000:\n",
    "\t\tprint(\"Warning: Only\", points.size(0), \"points in dataset.\")\n",
    "\n",
    "\treturn(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(points):\n",
    "\n",
    "\t\"\"\"\n",
    "\tCompute mass- and input matrix of all training points to reduce load in training.\n",
    "\tReturns TensorDataset of (q, M_q, A_q). \n",
    "\t\"\"\"\n",
    "\n",
    "\tdata_pairs = []\n",
    "\tfor point in points:\n",
    "\t\tMq_point, _, _ = dynamics.dynamical_matrices(rp, point, point)\n",
    "\t\tAq_point = dynamics.input_matrix(rp, point)\n",
    "\t\tdata_pairs.append((point, Mq_point, Aq_point))\n",
    "\n",
    "\tpoints_tensor = torch.stack([pair[0] for pair in data_pairs])           # Tensor of all points\n",
    "\tmass_matrices_tensor = torch.stack([pair[1] for pair in data_pairs])   # Tensor of all mass matrices\n",
    "\tinput_matrices_tensor = torch.stack([pair[2] for pair in data_pairs])  # Tensor of all input matrices\n",
    "\n",
    "\t# Create TensorDataset\n",
    "\tdataset = TensorDataset(points_tensor, mass_matrices_tensor, input_matrices_tensor)\n",
    "\treturn(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_dataloader(dataset, stride = 1):\n",
    "\n",
    "\t\"\"\"\n",
    "\tTakes the training dataset and returns a dataloader of every 10th point\n",
    "\tto reduce visual clutter. \n",
    "\t\"\"\"\n",
    "\n",
    "\tpoints_tensor, mass_matrices_tensor, input_matrices_tensor = dataset.tensors\n",
    "\t\n",
    "\tplot_sampled = points_tensor[::stride]\n",
    "\tmass_sampled = mass_matrices_tensor[::stride]\n",
    "\tinput_sampled = input_matrices_tensor[::stride]\n",
    "\n",
    "\tplot_dataset = TensorDataset(plot_sampled, mass_sampled, input_sampled)\n",
    "\tplot_dataloader = DataLoader(plot_dataset, batch_size=len(plot_dataset), shuffle=False, num_workers=0)\n",
    "\n",
    "\treturn(plot_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_split = (-torch.pi, torch.pi)\n",
    "q1_margin = 0.2\n",
    "\n",
    "plt.ion()\n",
    "plot_points = mask_points(q0_split, clockwise = train_clockwise, q1_margin = q1_margin)\n",
    "plot_dataset = make_dataset(plot_points)\n",
    "plot_dataloader = make_plot_dataloader(plot_dataset, stride = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.plot_model_performance(model, model_ana, plot_dataloader, dir_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss for multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_paths = [\n",
    "    \"Models/NN_202505221832/losses.pt\",\n",
    "    \"Models/NN_202505221839/losses.pt\",\n",
    "    \"Models/NN_202505221919/losses.pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses   = []\n",
    "\n",
    "for loss_path in loss_paths:\n",
    "\ttrain_loss, val_loss = load_loss(loss_path)\n",
    "\ttrain_losses.append(train_loss)\n",
    "\tval_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.plot_losses_vs_epoch(train_losses, val_losses, save_folder = dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Yin-Yang for $\\theta$ vs $x, y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of grid points along each dimension.\n",
    "n_points = 200\n",
    "\n",
    "lp.plot_yinyang(n_points, q0_split, dir_path, file_counter, train_clockwise, models, model_names, rp, device) #TODO: Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
