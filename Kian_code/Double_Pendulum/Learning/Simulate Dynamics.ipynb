{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File used to generate unforced trajectories, for comparison between learned and true dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "\tsys.path.insert(0, module_path)\n",
    "print(sys.path)\n",
    "\n",
    "import Double_Pendulum.Learning.autoencoders as autoencoders\n",
    "import Double_Pendulum.robot_parameters as robot_parameters\n",
    "import Double_Pendulum.transforms as transforms\n",
    "import Double_Pendulum.dynamics as dynamics\n",
    "import Plotting.pendulum_plot as pendulum_plot\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = robot_parameters.LUMPED_PARAMETERS.copy()\n",
    "#rp[\"m0\"] = 0.\n",
    "plotter = pendulum_plot.Anim_plotter(rp)\n",
    "neural_net = False\n",
    "model_cw = False\n",
    "model_shifting = True\n",
    "print(rp[\"m0\"])\n",
    "print(rp)\n",
    "\n",
    "armlen = rp[\"l0\"] + rp[\"l1\"]\n",
    "\n",
    "q0_max = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 0.\n",
    "t_end = 3.\n",
    "dt = 0.01\n",
    "\n",
    "model = autoencoders.Autoencoder_double(rp).to(device)\n",
    "model_location = 'Models/NN_202505141642(half-q)/NN_202505141642_0.pth'\n",
    "model.load_state_dict(torch.load(model_location, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ik_fn(xy):\n",
    "\treturn transforms.inverse_kinematics(xy, rp, model_cw).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate $q$-space trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_q(t_start, t_end, dt, q_start, q_d_start, u):\n",
    "\tq = q_start\n",
    "\tq_d = q_d_start\n",
    "\tqs_ana = []\n",
    "\tq_ds_ana = []\n",
    "\n",
    "\n",
    "\tn_steps = int((t_end - t_start) / dt)\n",
    "\n",
    "\tfor _ in range(n_steps):\n",
    "\t\t\n",
    "\t\tM_q, C_q, G_q = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "\t\tA_q = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "\t\ttau_q = A_q * u\n",
    "\t\tq_dd = (torch.pinverse(M_q) @ (tau_q - C_q @ q_d.T - G_q)).T\n",
    "\t\tq_d = q_d + q_dd * dt\n",
    "\t\tq = q + q_d * dt\n",
    "\t\t\n",
    "\t\tqs_ana.append(q.squeeze(0).detach())\n",
    "\t\tq_ds_ana.append(q_d.squeeze(0).detach())\n",
    "\t\n",
    "\treturn torch.stack(qs_ana,  dim=0), torch.stack(q_ds_ana, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_q_old(t_start, t_end, dt, q_start, q_d_start, u):\n",
    "\tq = q_start\n",
    "\tq_d = q_d_start\n",
    "\n",
    "\tq_ana_series, q_d_ana_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\n",
    "\tn_steps = int((t_end - t_start) / dt)\n",
    "\n",
    "\tfor t in torch.arange(t_start, t_end, dt):\n",
    "\n",
    "\t\tM_q, C_q, G_q = dynamics.dynamical_matrices(rp, q.squeeze(0), q_d.squeeze(0))\n",
    "\t\tA_q = dynamics.input_matrix(rp, q.squeeze(0))\n",
    "\n",
    "\t\ttau_q = A_q * u\n",
    "\t\tq_dd = (torch.pinverse(M_q) @ (tau_q - C_q @ q_d.T - G_q)).T\n",
    "\t\tq_d = q_d + q_dd * dt\n",
    "\t\tq = q + q_d * dt\n",
    "\n",
    "\t\tq_ana_series = torch.cat((q_ana_series, q.detach()), dim=0)\n",
    "\t\tq_d_ana_series = torch.cat((q_d_ana_series, q_d.detach()), dim=0)\n",
    "\n",
    "\t\n",
    "\treturn q_ana_series, q_d_ana_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate $\\hat{q}$-space trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_alt = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "q_nn = q_start\n",
    "q_d_nn = q_d_start\n",
    "\n",
    "th = model.encoder_vmap(q_nn)\n",
    "th_d = (model.jacobian_enc(q_nn) @ q_d_nn.T).T\n",
    "\n",
    "q_nn_series, q_d_nn_series = torch.empty((0,2)).to(device), torch.empty((0,2)).to(device)\n",
    "\n",
    "for t in torch.arange(t_start, t_end, dt):\n",
    "\n",
    "    is_clockwise = transforms.check_clockwise(q_nn.squeeze(0))\n",
    "\n",
    "    if model_shifting:\n",
    "            q_nn = transforms.shift_q(q_nn, clockwise=model_cw)\n",
    "\n",
    "\n",
    "\n",
    "    q_hat = model.decoder_vmap(th, clockwise=model_cw)\n",
    "    q_d_hat = (model.jacobian_dec(th) @ th_d.T).T\n",
    "\n",
    "    M_q_hat, C_q_hat, G_q_hat = dynamics.dynamical_matrices(rp, q_hat.squeeze(0), q_d_hat.squeeze(0))\n",
    "\n",
    "    J_h_inv = model.jacobian_dec(th, is_clockwise).squeeze(0)\n",
    "    J_h_inv_trans = torch.transpose(J_h_inv, 0, 1)\n",
    "\n",
    "    M_th, C_th, G_th = transforms.transform_dynamical_from_inverse(M_q_hat, C_q_hat, G_q_hat, th, th_d, J_h_inv, J_h_inv_trans)\n",
    "\n",
    "    th_dd = (torch.pinverse(M_th) @ (-C_th @ th_d.T - G_th)).T\n",
    "    th_d = th_d + th_dd * dt\n",
    "    th = th + th_d * dt\n",
    "\n",
    "    q_nn = model.decoder_vmap(th)\n",
    "    q_d_nn = (model.jacobian_dec(th) @ th_d.T).T\n",
    "\n",
    "    q_nn_series = torch.cat((q_nn_series, q_nn.detach()), dim = 0)\n",
    "    q_d_nn_series = torch.cat((q_d_nn_series, q_d_nn.detach()), dim = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_ana_series = torch.empty((0,2)).to(device)\n",
    "xy_nn_series = torch.empty((0,2)).to(device)\n",
    "\n",
    "for q_ana, q_nn in zip(q_ana_series, q_nn_series):\n",
    "\txy_ana, _ = transforms.forward_kinematics(rp, q_ana)\n",
    "\txy_ana_series = torch.cat((xy_ana_series, xy_ana.unsqueeze(0)))\n",
    "\txy_nn, _ = transforms.forward_kinematics(rp, q_nn)\n",
    "\txy_nn_series = torch.cat((xy_nn_series, xy_nn.unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"Performance_Sims/simulation_{timestamp}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "metadata = {\n",
    "\t\"timestamp\": timestamp,\n",
    "\t\"Learned transform\": False,\n",
    "\t\"Model location\": None,\n",
    "\t\"Model clockwise\": None,\n",
    "\t\"Model shifting\": None, \n",
    "\t\"xy start\": {\"x\": xy_start[0].item(), \"y\": xy_start[1].item()},\n",
    "\t\"Time step\": dt,\n",
    "\t\"Sim time\": t_end,\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(save_dir, \"metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "\tjson.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 3\n",
    "pos_end_q_ana, pos_elbow_q_ana = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_ana_series[::stride])\n",
    "pos_end_q_nn, pos_elbow_q_nn = torch.vmap(transforms.forward_kinematics, in_dims=(None, 0))(rp, q_nn_series[::stride])\n",
    "\n",
    "frames_q_ana = plotter.frame_pendulum(pos_end_q_ana, pos_elbow_q_ana)\n",
    "frames_q_nn = plotter.frame_pendulum(pos_end_q_nn, pos_elbow_q_nn)\n",
    "\n",
    "data_ana = {\n",
    "\t\"frames\": frames_q_ana,\n",
    "\t\"times\": dt,\n",
    "\t\"name\": \"q_ana\", \n",
    "\t\"arm_color\": \"tab:blue\",\n",
    "\t\"act_color\": \"tab:cyan\"\n",
    "}\n",
    "\n",
    "data_nn = {\n",
    "\t\"frames\": frames_q_nn,\n",
    "\t\"times\": dt,\n",
    "\t\"name\": \"q_est\",\n",
    "\t\"arm_color\": \"tab:orange\", \n",
    "\t\"act_color\": \"tab:red\"\n",
    "} \n",
    "\n",
    "\n",
    "frames_data = [data_ana, data_nn]\n",
    "\n",
    "name_rp = \"RP:(\" + str(rp[\"xa\"]) + \",\" + str(rp[\"ya\"]) + \")_\"\n",
    "\n",
    "\n",
    "if neural_net:\n",
    "\tmodel_type = \"NN\"\n",
    "else:\n",
    "\tmodel_type = \"AL\"\n",
    "\n",
    "file_name = \"t_end:[\" + str(t_end) + \"]_dt:[\" + str(dt) + \"]_stride:[\" + str(stride) + \"]_0.mp4\"\n",
    "file_counter = 0\n",
    "\n",
    "output_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "while os.path.isfile(output_path):\n",
    "\tprint(\"file name already exists\")\n",
    "\tfile_counter += 1\n",
    "\tfile_name = file_name[:-6] + \"_\" + str(file_counter) + \".mp4\"\n",
    "\toutput_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "plotter.animate_pendulum(frames_data, ref_poss=None, plot_actuator=False, save_path=output_path, fps = 1/(dt*stride), dt = dt*stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_q = [\n",
    "\t{\n",
    "\t    \"name\": \"nn\",\n",
    "\t    \"values\": q_nn_series.cpu().detach().numpy(),\n",
    "\t    \"color\": \"tab:orange\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"name\": \"ana\",\n",
    "\t\t\"values\": q_ana_series.cpu().detach().numpy(),\n",
    "\t\t\"color\": \"tab:blue\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "datasets_xy = [\n",
    "\t{\n",
    "\t    \"name\": \"nn\",\n",
    "\t    \"values\": xy_nn_series.cpu().detach().numpy(),\n",
    "\t    \"color\": \"tab:orange\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"name\": \"ana\",\n",
    "\t\t\"values\": xy_ana_series.cpu().detach().numpy(),\n",
    "\t\t\"color\": \"tab:blue\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "\n",
    "# Common labels for the plots.\n",
    "name_q = \"q trajectory\"\n",
    "name_xy = \"xy trajectory\"\n",
    "t_series = torch.arange(0, t_end, dt)\n",
    "\n",
    "# Create an instance of ErrorPlotter.\n",
    "ep = pendulum_plot.Error_plotter(rp)\n",
    "\n",
    "# Prepare plot datasets for each column.\n",
    "# Each call groups a set of datasets to be drawn in one subplot column.\n",
    "q_dataset = ep.create_plot_dataset(t=t_series, datasets=datasets_q, reference=None, name=name_q)\n",
    "xy_dataset = ep.create_plot_dataset(t=t_series, datasets=datasets_xy, reference=None, name=name_xy)\n",
    "\n",
    "\n",
    "plot_datasets = [q_dataset, xy_dataset]\n",
    "plot_colormaps = [\"Oranges\", \"Blues\", \"Greens\"]\n",
    "\n",
    "file_name = \"Error plot.png\"\n",
    "file_counter = 0\n",
    "\n",
    "output_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "# Pass the list of columns (plot_dataset objects) to plot_multi.\n",
    "#ep.plot_multi(plot_datasets=plot_datasets, save_path=output_path, axes_names = [\"q\", \"th\", \"xy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot $q$-space error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "for i, cmap in zip(range(2), plot_colormaps):\n",
    "\tt = q_dataset[\"x\"]                      # shape (N,)\n",
    "\tq1 = q_dataset[\"data\"][i][\"y1\"]         # shape (N,)\n",
    "\tq2 = q_dataset[\"data\"][i][\"y2\"]         # shape (N,)\n",
    "\tsc = ax.scatter(q1, q2, c=t, cmap=cmap, s=20)\n",
    "\n",
    "\t# optionally connect points in order\n",
    "\tax.plot(q1, q2, lw=0.5, color='gray', alpha=0.5)\n",
    "\n",
    "# labels and colorbar\n",
    "ax.set_xlabel('$q_0$')\n",
    "ax.set_ylabel('$q_1$')\n",
    "ax.grid()\n",
    "#ax.set_xlim(-torch.pi, torch.pi)\n",
    "#ax.set_ylim(-torch.pi, torch.pi)\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label('time')\n",
    "\n",
    "ax.set_title('Trajectory in $(q_0,q_1)$ colored by time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "for i, cmap in zip(range(2), plot_colormaps):\n",
    "\tt = xy_dataset[\"x\"]                      # shape (N,)\n",
    "\tq1 = xy_dataset[\"data\"][i][\"y1\"]         # shape (N,)\n",
    "\tq2 = xy_dataset[\"data\"][i][\"y2\"]         # shape (N,)\n",
    "\tsc = ax.scatter(q1, q2, c=t, cmap=cmap, s=20)\n",
    "\n",
    "\t# optionally connect points in order\n",
    "\tax.plot(q1, q2, lw=0.5, color='gray', alpha=0.5)\n",
    "\n",
    "armlen = rp[\"l0\"] + rp[\"l1\"]\n",
    "circ = plt.Circle((0, 0), armlen, color=\"gray\", fill=False, linestyle=\"dashed\", alpha=0.8)\n",
    "ax.add_patch(circ)\n",
    "# labels and colorbar\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.grid()\n",
    "ax.set_xlim(-armlen, armlen)\n",
    "ax.set_ylim(-armlen, armlen)\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label('time')\n",
    "\n",
    "ax.set_title('Trajectory in $(x,y)$ colored by time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
